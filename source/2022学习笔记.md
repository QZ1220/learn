# 2022学习笔记


---

* [携程最终一致和强一致性缓存实践](#携程最终一致和强一致性缓存实践)
   * [最终一致性分布式缓存场景](#最终一致性分布式缓存场景)
      * [场景描述](#场景描述)
      * [整体方案](#整体方案)
      * [数据准确性设计](#数据准确性设计)
         * [并发控制](#并发控制)
         * [基于updateTime的更新顺序控制](#基于updatetime的更新顺序控制)
      * [数据完整性设计](#数据完整性设计)
      * [系统可用性保证](#系统可用性保证)
* [IM系统](#im系统)
* [图像识别](#图像识别)


# 携程最终一致和强一致性缓存实践

- https://mp.weixin.qq.com/s/E-chAZyHtaZOdA19mW59-Q

文章主要分为两个方面（最终一致性分布式缓存场景、强一致性分布式缓存场景）来讲解携程是如何使用缓存（redis）来降低mysql等db层面的查询压力的。

## 最终一致性分布式缓存场景

### 场景描述

经过几年演进，携程金融形成了自顶向下的多层次系统架构，如业务层、平台层、基础服务层等，其中用户信息、产品信息、订单信息等基础数据由基础平台等底层系统产生，服务于所有的金融系统，对这部分基础数据我们引入了统一的缓存服务（系统名utag），缓存数据有三大特点：**全量、准实时、永久有效**，在数据实时性要求不高的场景下，业务系统可直接调用统一的缓存查询接口。

我们的典型使用场景有：风控流程、APP入口信息提示等，而对数据一致性要求高的场景依然需要走实时的业务接口查询。引入缓存前后系统架构对比如下：

![1](1.png)

由于引入了缓存，势必会带来以下一些好处：查询的效率显著提高，查询接口层面可以做到统一，缓解底层基础服务的查询压力。

但是，也因为引入了缓存会增加系统的整体复杂度以及数据一致性问题。接下来主要从如下三个方面来讨论。

- 数据准确性：DB中单条数据的更新一定要准确同步到缓存服务。
- 数据完整性：将对应DB表的全量数据进行缓存且永久有效，从而可以替代对应的DB查询。
- 系统可用性：我们多个产品线的多个核心服务都已经接入，utag的高可用性显的尤为关键。

接下来先说明统一缓存服务的整体方案，再逐一介绍此三个关键特性的设计实现方案。

### 整体方案

简单来说就是，缓存集群服务多地部署，并且缓存更新的触发源存在多个，实现互补。缓存的更新通过mq通知到各集群。如下图所示：

![2](2.png)

### 数据准确性设计

从上图我们，可以知道触发源存在多个。不同的触发源，对缓存更新过程是一样的，整个更新步骤可抽象为4步：

- step1：触发更新，查询DB中的新数据，并发送统一的MQ
- step2：接收MQ，查询缓存中的老数据
- step3：新老数据对比，判断是否需要更新
- step4：若需要，则更新缓存

由于我们业务的大部分核心系统和所有的DB都在A地机房，所以触发源（如binlog的消费、业务MQ的接收、扫表任务的执行）都在A侧，触发更新后，第一步查询DB数据也只能在A侧查询（避免跨网络专线的数据库连接，影响性能）。查询到新数据后，发送更新缓存的MQ，两地机房的utag服务进行消费，之后进行统一的缓存更新流程。总体的缓存更新方案如下图所示：

![3](3.png)

由于有多个触发源，不同的触发源之间可能会对同一条数据的缓存更新请求出现并发，此外可能出现同一条数据在极短时间内（如1秒内）更新多次，无法区分数据更新顺序，因此需要做两方面的操作来确保数据更新的准确性。

#### 并发控制

若一条DB数据出现了多次更新，且刚好被不同的触发源触发，更新缓存时候若未加控制，可能出现数据更新错乱，如下图所示：

![4](4.png)

需要将图中的第2、3、4步进行加锁，是的缓存操作串行化。由于utag本身就依赖了redis，此处我们的分布式锁就基于redis实现。

#### 基于updateTime的更新顺序控制

携程的mysql规范要求db层面的表必须包含updateTime字段，并且设置了ON UPDATE CURRENT_TIMESTAMP。但是并没有控制updateTime的精度，大多都是秒级别。因此很可能存在一条数据存在并发更新的可能，从而导致缓存数据更新出现一致性问题。

针对，这个问题，因为我们讨论的是「最终一致性」，因此这里引入了延迟消息的概念。即，对于同一秒更新的数据，在更新缓存成功以后，再发送一个延迟1秒的缓存更新触发消息。再次更新缓存。

举个例子：假设同一秒内同一条数据出现了两次更新，value=1和value=2，期望最终缓存中的数据是value=2。若这两次更新后的数据被先后触发，分两种情况：

- case1：若value=1先更新，value=2后更新，（两者都可更新到缓存中，因为虽然是同一秒，但是值不相等）则缓存中最终数据为value=2。
- case2：若value=2先更新，value=1后更新，则第一轮更新后缓存数据为value=1，不是期望数据，之后对比发现是同一秒数据后会通过消息触发二次更新，重新查询DB数据为value=2，可以更新到缓存中。如下图所示：

![5](5.png)

- 为什么需要延迟消息？

其实不用延迟消息也是可以的，毕竟DB数据的更新时间是不变的，但是考虑到出现同一秒更新的可能是高频更新场景，若直接发消息，然后立即消费并触发二次更新，可能依然查到同一秒内更新的其他数据，为减少此种情况下的多次循环更新，延迟几秒再刷新可作为一种优化策略。

- 不支持db的删除操作

因为删除操作和update操作无法进行数据对比，无法确定操作的先后顺序，进而可能导致更新错乱。而在数据异常宝贵的时代，一般的业务系统中也没有物理删除的逻辑。





### 数据完整性设计

### 系统可用性保证



# IM系统
- https://xie.infoq.cn/article/19e95a78e2f5389588debfb1c
- http://www.52im.net/thread-2848-1-1.html
- https://mp.weixin.qq.com/s/fMF_FjcdLiXc_JVmf4fl0w


# Spring IOC容器是什么样的数据结构

Spring IOC容器并不是一种特定的数据结构，而是一种管理对象的容器。它的核心思想是通过反射和依赖注入来实现对象的创建、组装和管理。

在Spring的IOC容器中，通常使用Map、List等数据结构来存储对象。具体来说，Spring提供了不同类型的IOC容器，如BeanFactory、ApplicationContext等，它们在底层使用了不同的数据结构来管理对象。

常见的IOC容器实现类如下：

- DefaultListableBeanFactory：它是Spring IOC容器的默认实现类，底层使用了HashMap来存储对象和BeanDefinition的注册信息。
- AnnotationConfigApplicationContext：它是基于注解的IOC容器实现类，底层使用了ConcurrentHashMap来存储bean的定义和实例化信息。
- ClassPathXmlApplicationContext：它是基于XML配置文件的IOC容器实现类，底层使用了HashMap和ConcurrentHashMap来存储bean的定义和实例化信息。
无论是基于注解还是基于XML配置的IOC容器，其主要的数据结构都是基于HashMap或ConcurrentHashMap。这些数据结构通过键-值对的方式存储对象的定义和实例。

需要注意的是，Spring的IOC容器并不仅限于使用单一的数据结构，它还包含了一系列解析配置文件、管理对象生命周期的功能，因此，IOC容器可以视作是一种高度封装和抽象化的对象管理机制，而数据结构只是其中的一部分实现方式。

# Spring如何防止bean重复加载

Spring通过Bean的定义和注册机制来避免Bean的重复加载。当Spring容器初始化时，会根据配置文件或注解等方式，将Bean的定义注册到容器中。在注册过程中，Spring会对Bean的名称或其他限定符进行校验，确保Bean的唯一性。

具体来说，Spring采用了以下机制来防止Bean的重复加载：

- Bean的命名规范：Spring要求每个Bean都有一个唯一的名称，可以通过XML配置文件中的id属性、注解中的@Component("beanName")等方式指定。如果存在重复的名称，Spring容器在注册Bean时会抛出异常，提示冲突。
- Bean的作用域：Spring提供了多种Bean的作用域，如Singleton（单例）、Prototype（原型）等。默认情况下，Bean的作用域为Singleton，即在容器中只有一个实例。如果尝试重复加载同一个Singleton Bean，Spring容器会直接返回已存在的实例，而不会重新创建。
- 检查已注册的Bean定义：在注册Bean时，Spring会先检查是否已经存在相同名称或相同类型的Bean定义。如果发现重复的定义，容器将会抛出异常，避免重复加载。
- 使用注解方式的扫描：Spring支持使用注解（如@Component、@Service、@Controller等）进行自动扫描和Bean的注册。在注解扫描过程中，Spring会检查并跳过已经注册过的Bean，避免重复加载。
- 使用延迟初始化（Lazy Initialization）：Spring提供了延迟初始化的功能，即在需要使用某个Bean时才进行实例化。这样可以避免在容器启动时一次性加载所有Bean，减少重复加载的可能性。
通过以上机制和策略，Spring能够有效地防止Bean的重复加载，从而确保容器中的Bean是唯一且正确的。

# 什么是CSRF攻击

CSRF（Cross-Site Request Forgery，跨站请求伪造）攻击是一种常见的网络安全攻击方式，它利用被攻击用户在已认证过的网站上的身份，通过跨站点请求来执行未经授权的操作。

攻击者通常利用以下步骤执行CSRF攻击：

1. 攻击者创建一个恶意网站，并在其中包含一个针对被攻击网站的请求（比如提交表单、发送请求等）。
2. 攻击者诱使用户访问恶意网站。这可以通过发送诱导邮件、社交媒体诱导、钓鱼网站等方式进行。
3. 用户在浏览器中登陆了被攻击网站，该网站的身份认证信息（比如Cookie）被保存在用户的浏览器中。
4. 在用户未登出被攻击网站的情况下，攻击者的恶意请求会自动触发用户的浏览器发出该请求。
5. 用户的浏览器会自动发送携带被攻击网站身份认证信息的请求给被攻击网站。
6. 被攻击网站会认为该请求是合法的，然后执行攻击者设定的操作，比如修改用户密码、转账、删除数据等。

CSRF攻击的危害在于，攻击者可以在不知情的情况下利用受害者的身份进行操作，被攻击的用户可能无法察觉到攻击的存在。攻击者可以通过各种手段获取用户在被攻击网站上的权限或敏感信息，破坏用户的数据完整性和安全性。

为了有效防止CSRF攻击，常见的防护手段包括：

- 在关键操作上使用验证码或其他身份验证机制，增强用户操作的可靠性。
- 在关键操作或敏感数据访问上使用双因素身份认证。
- 在请求中增加验证机制，比如使用Token或自定义请求头，确保请求的合法性。
- 设置Cookie属性为SameSite属性，限制仅在同站点访问时发送请求。
- 定期更新密码，避免遭受攻击后长时间保持同一密码。


通过采用这些防护措施，可以有效减轻并防止CSRF攻击的风险。

# 对于http协议，服务端如何知道客户端的请求数据已经发送完成

在HTTP协议中，服务端无法直接知道客户端的请求数据是否已经发送完成。HTTP是基于请求-响应模型的，客户端发送请求，服务端返回响应。客户端发送完请求后，会等待服务端的响应，而服务端也在接收到请求后开始处理，并在处理完后发送响应。

服务端通常会通过以下方式来判断请求数据已经发送完成：

- Content-Length 头信息：客户端在请求中可以添加Content-Length头信息，用于指定请求体的长度。服务端通过读取Content-Length的值，来判断请求体的大小是否与实际接收到的数据一致。当服务端读取到请求体大小与Content-Length的值相等时，可以认为请求数据已经发送完成。

- Transfer-Encoding 头信息：客户端可以使用Transfer-Encoding头信息来指定数据传输的编码方式，如chunked。在使用chunked编码时，客户端会在请求中将请求体拆分成多个块(chunk)进行发送。服务端在接收到每个块后，可以立即开始处理数据，而不需要等待整个请求体发送完成。

- Connection 头信息：在HTTP/1.1中，默认使用持久连接(Connection: keep-alive)，即同一个TCP连接可以传输多个请求-响应对。当服务端接收到一个请求后，可以通过Connection头信息来判断客户端是否会发送后续的请求。如果客户端不再发送请求，服务端可以认为请求数据已经发送完成。

需要注意的是，上述方式只是服务端根据HTTP协议规范进行的处理判断，服务端无法确切知道客户端是否发送完所有数据。因此，在特定应用场景下，开发者可能需要采用其他手段，如自定义协议或在应用层进行数据完整性的验证，来确保请求数据的完整性和准确性。

# mysql联合索引的数据结构是什么

MySQL中的联合索引是由多列组合而成的索引，也称为复合索引或多列索引。它是一种特殊类型的索引，通过对多个列进行索引来加快查询的速度。

联合索引的数据结构可以通过B+树来表示。B+树是一种常见的自平衡搜索树数据结构，适用于范围查询和按序访问等操作。对于联合索引，MySQL使用B+树的变体来组织索引数据。

在B+树中，根节点包含一个或多个索引项，每个索引项由键值（索引列的值）和指针组成。叶子节点存储真实的数据行，每个数据行包含联合索引的所有列值。叶子节点之间通过指针连接形成双向链表，方便范围查询的快速定位。

对于联合索引，B+树的构建方式会考虑多个列值的顺序。在B+树的内部节点中，存储了每个索引键的前缀，这样可以在搜索时参与索引键的比较，以快速定位对应的叶子节点。

使用联合索引时，查询语句可以利用各个索引列的顺序去匹配索引节点，从而快速定位到叶子节点，降低了磁盘I/O的开销，提升了查询性能。

需要注意的是，联合索引的顺序对查询的效果有影响。联合索引中的列顺序应该根据查询的频率和条件进行选择，将经常一起使用的列放在联合索引的前面，这样可以提高查询的效率。

总结起来，MySQL中的联合索引数据结构是基于B+树的，通过多列组合构建索引，提供高效的查询性能。

# mysql join操作底层原理

在MySQL中，JOIN操作是用于将多个表的数据按照特定条件进行关联查询的操作。JOIN操作的底层原理可以简单概括为以下几个步骤：

1. 语法解析与查询优化：MySQL首先解析查询语句，生成查询语法树，并进行查询优化，确定最优的查询执行计划。

2. 表的连接顺序：MySQL通过查询优化器确定表的连接顺序。根据表的大小、索引情况、查询条件等因素，决定在什么顺序下进行连接操作。

3. 连接算法：MySQL使用多种连接算法执行JOIN操作，常见的有以下几种：

- 嵌套循环连接（Nested Loop Join）：对于每个左表的记录，都会在右表中进行查找匹配的记录。这是一种简单的连接算法，但对于大型数据集和无索引的情况下，性能可能较差。

- 哈希连接（Hash Join）：MySQL会先将较小的表构建一个哈希表，然后遍历另一个较大的表，通过查找哈希表中的值来进行连接操作。哈希连接适用于数据量大且可以完全载入内存的情况。

- 排序合并连接（Merge Join）：MySQL会对连接参与的两个表按照连接条件进行排序，然后通过扫描有序数据集进行匹配操作。排序合并连接适用于有序数据集或索引的情况。

- 索引连接（Index Join）：如果JOIN操作可以使用索引覆盖，MySQL会使用索引连接。索引连接避免了对表的全表扫描，效率较高。

4. 数据读取与返回：根据连接算法，在连接过程中，MySQL会同时读取两个表的数据，并进行匹配操作。匹配成功后，返回匹配的结果集给用户。

需要注意的是，MySQL的查询优化器会根据表的结构、数据分布、统计信息等动态选择使用哪种连接算法。不同的连接操作和数据场景下，其底层原理和实现方式可能有所不同。此外，优化表结构、合理使用索引、避免跨表查询等方法也可以提升JOIN操作的性能。



