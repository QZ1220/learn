# 2018学习笔记一

标签（空格分隔）： 笔记

 * [collection与collections的区别](#collection与collections的区别)
  * [hashmap对于重复key的处理](#hashmap对于重复key的处理)
  * [JDK1.8HashMap的红黑树](#jdk18hashmap的红黑树)
  * [java中length,length(),size()](#java中lengthlengthsize)
  * [进程与线程](#进程与线程)
    * [进程间通信方式](#进程间通信方式)
  * [多线程之生产者消费者](#多线程之生产者消费者)
    * [借助Object类方法](#借助object类方法)
    * [借助BlockingQueue](#借助blockingqueue)
  * [Java中的访问控制符号](#java中的访问控制符号)
  * [Java中set的底层实现](#java中set的底层实现)
  * [为什么需要重写hashcode方法与equals方法](#为什么需要重写hashcode方法与equals方法)
  * [Java的深复制浅复制](#java的深复制浅复制)
    * [浅复制](#浅复制)
    * [深复制](#深复制)
  * [string类的源码分析，为什么是不可变的](#string类的源码分析为什么是不可变的)
  * [springMVC集成quartz](#springmvc集成quartz)
  * [任务调度的机制](#任务调度的机制)
  * [Mysql优化](#mysql优化)
    * [navicat查看mysql执行计划各参数意义](#navicat查看mysql执行计划各参数意义)
  * [数据库事务](#数据库事务)
    * [四个基本要素](#四个基本要素)
      * [原子性](#原子性)
      * [一致性](#一致性)
      * [隔离性](#隔离性)
      * [持久性](#持久性)
    * [数据库事务等级](#数据库事务等级)
      * [Read uncommitted（读未提交，存在脏读）](#read-uncommitted读未提交存在脏读)
      * [Read committed（读已提交，存在不可重复读）](#read-committed读已提交存在不可重复读)
      * [Repeatable read （可重复读，存在幻读）](#repeatable-read-可重复读存在幻读)
      * [Serializable（序列化，性能低）](#serializable序列化性能低)
  * [MVCC（Multi-Version Concurrency Control 多版本并发控制 ）](#mvccmulti-version-concurrency-control-多版本并发控制-)
    * [Spring事务的传播特性和隔离级别](#spring事务的传播特性和隔离级别)
  * [Servlet的作用，生命周期，如何创建、配置Servlet](#servlet的作用生命周期如何创建配置servlet)
  * [常用设计模式](#常用设计模式)
    * [单例模式](#单例模式)
    * [工厂方法](#工厂方法)
    * [代理模式(Proxy)](#代理模式proxy)
    * [命令模式(Command)](#命令模式command)
    * [策略模式(Strategy)](#策略模式strategy)
    * [门面模式(Facade)](#门面模式facade)
    * [桥接模式(Bridge)](#桥接模式bridge)
    * [观察者模式(Observer)](#观察者模式observer)
  * [I/O中涉及到的设计模式](#io中涉及到的设计模式)
    * [装饰者模式](#装饰者模式)
    * [适配器模式](#适配器模式)
  * [浅析classloader](#浅析classloader)
    * [classloader](#classloader)
    * [自定义classloader](#自定义classloader)
    * [自定义classloader实际用途](#自定义classloader实际用途)
    * [classloader的双亲委派机制](#classloader的双亲委派机制)
    * [为什么需要双亲委派机制](#为什么需要双亲委派机制)
  * [类的初始化过程](#类的初始化过程)
    * [类的初始化](#类的初始化)
      * [类的加载](#类的加载)
      * [类的链接](#类的链接)
    * [类初始化](#类初始化)
  * [ClassLoader的loadClass和Class.forName的区别](#classloader的loadclass和classforname的区别)
  * [main函数执行所发生的一系列动作](#main函数执行所发生的一系列动作)
  * [GC回收算法](#gc回收算法)
  * [引用类型](#引用类型)
  * [concurrentHashMap的底层实现](#concurrenthashmap的底层实现)
      * [首先是get方法：](#首先是get方法)
      * [然后是put方法：](#然后是put方法)
      * [然后是remove方法](#然后是remove方法)
  * [分布式的基本知识](#分布式的基本知识)
    * [CAP](#cap)
    * [BASE](#base)
  * [SpringMVC框架执行步骤（SpringMVC使用Servlet嵌入）：](#springmvc框架执行步骤springmvc使用servlet嵌入)
  * [spring bean的生命周期](#spring-bean的生命周期)
  * [ArrayList的底层实现](#arraylist的底层实现)
  * [Java Array和Arrays](#java-array和arrays)
  * [分布式如何实现session共享](#分布式如何实现session共享)
  * [Java中的Lock和synchronized两种锁定机制的对比](#java中的lock和synchronized两种锁定机制的对比)
  * [Spring中ApplicationContext和beanfactory区别](#spring中applicationcontext和beanfactory区别)
  * [设计模式之六大原则](#设计模式之六大原则)
  * [linux中可以同时查看一个文件的前几行和末尾几行](#linux中可以同时查看一个文件的前几行和末尾几行)
  * [linux文本内容查找](#linux文本内容查找)
  * [java并发相关](#java并发相关)
    * [java内存模型](#java内存模型)
    * [原子性、可见性、有序性](#原子性可见性有序性)
    * [violatile关键字及原理](#violatile关键字及原理)
    * [synchronized关键字及原理](#synchronized关键字及原理)
  * [jvm性能分析](#jvm性能分析)
    * [JVM性能瓶颈定位（CPU占用异常高、但内存使用正常）](#jvm性能瓶颈定位cpu占用异常高但内存使用正常)
    * [jvm内存泄漏检测（CPU使用正常，但是内存占用持续增高）](#jvm内存泄漏检测cpu使用正常但是内存占用持续增高)
  * [Redis、Memcache和MongoDB的区别](#redismemcache和mongodb的区别)
    * [Memcached](#memcached)
    * [Redis](#redis)
    * [Redis、Memcache和MongoDB的区别](#redismemcache和mongodb的区别-1)
  * [Java的threadlocal类](#java的threadlocal类)
  * [JDK动态代理与CGLIB动态代理](#jdk动态代理与cglib动态代理)
    * [jdk动态代理](#jdk动态代理)
    * [CGLIB动态代理](#cglib动态代理)
  * [为什么spring的DAO只使用接口就可以调用mybatis的xml文件](#为什么spring的dao只使用接口就可以调用mybatis的xml文件)
  * [什么是restful架构](#什么是restful架构)
  * [http的get、post、delete、put](#http的getpostdeleteput)
  * [hash索引和BTree索引和位图索引](#hash索引和btree索引和位图索引)
    * [为什么mysql使用B+Tree而不是Btree来实现索引](#为什么mysql使用btree而不是btree来实现索引)
  * [String类的hashcode()是怎么实现的？](#string类的hashcode是怎么实现的)
  * [spring的AOP使用了什么设计模式](#spring的aop使用了什么设计模式)
  * [spring的filter使用了什么设计模式](#spring的filter使用了什么设计模式)
  * [drools中的有状态session和无状态的session](#drools中的有状态session和无状态的session)
  * [nginx负载均衡](#nginx负载均衡)
  * [Java锁的类型](#java锁的类型)
    * [公平锁/非公平锁](#公平锁非公平锁)
    * [可重入锁](#可重入锁)
    * [独享锁/共享锁](#独享锁共享锁)
    * [互斥锁/读写锁](#互斥锁读写锁)
    * [乐观锁/悲观锁](#乐观锁悲观锁)
    * [分段锁](#分段锁)
    * [自旋锁](#自旋锁)
  * [java实现冒泡排序和快速排序](#java实现冒泡排序和快速排序)
  * [java中基本类型变量存在哪里](#java中基本类型变量存在哪里)
  * [在JVM中，主内存究竟在哪里](#在jvm中主内存究竟在哪里)
  * [CMS和G1](#cms和g1)
  * [jdk1.8舍去了永久区](#jdk18舍去了永久区)
  * [String.intern方法](#stringintern方法)
  * [java的finalize方法](#java的finalize方法)
  * [self-introduction](#self-introduction)
  * [Java中的Error能不能被Catch](#java中的error能不能被catch)
  * [Hbase](#hbase)
    * [HBase中WAL(Write-Ahead-Log)](#hbase中walwrite-ahead-log)
  * [hadoop简介](#hadoop简介)
  * [storm简介](#storm简介)
  * [分布式事务一致性](#分布式事务一致性)
  * [分布式锁](#分布式锁)
  * [java移位运算符](#java移位运算符)
  * [jsp的内置对象](#jsp的内置对象)
    * [jsp中的charset和pageEncoding的区别](#jsp中的charset和pageencoding的区别)
  * [Http协议与TCP协议简单理解](#http协议与tcp协议简单理解)
  * [cookie 和session 的区别详解](#cookie-和session-的区别详解)
  * [前端垮域问题](#前端垮域问题)
  * [JavaScript中的null、undefined](#javascript中的nullundefined)
  * [redis如何建立集群](#redis如何建立集群)
  * [查询出student表中选课数大于3的人学号及课程总分](#查询出student表中选课数大于3的人学号及课程总分)
  * [linux运维知识](#linux运维知识)
  * [Integer包装类](#integer包装类)
  * [HashMap插入null的具体操作](#hashmap插入null的具体操作)
  * [stringbuffer和stringbuilder的扩容函数的具体实现](#stringbuffer和stringbuilder的扩容函数的具体实现)
  * [统计出某个log文件中ip出现次数最多的ip](#统计出某个log文件中ip出现次数最多的ip)
  * [ps命令、netstat命令](#ps命令netstat命令)
  * [找到当前系统的最大的文件](#找到当前系统的最大的文件)
  * [Linux du命令和df命令区别](#linux-du命令和df命令区别)
  * [java线程池](#java线程池)
    * [newFixedThreadPool](#newfixedthreadpool)
    * [newCachedThreadPool](#newcachedthreadpool)
    * [newSingleThreadExecutor](#newsinglethreadexecutor)
    * [newScheduledThreadPool](#newscheduledthreadpool)
    * [newWorkStealingPool（JDK1.8新增）](#newworkstealingpooljdk18新增)
    * [自定义线程池](#自定义线程池)
    * [Executor相关](#executor相关)
  * [接口的幂等性的概念](#接口的幂等性的概念)
  * [java8的lambda表达式](#java8的lambda表达式)
  * [Java8的optional类](#java8的optional类)
  * [mock测试springMVC的controller](#mock测试springmvc的controller)
  * [redis哨兵模式](#redis哨兵模式)
  * [ServiceLoader作用及原理](#serviceloader作用及原理)
  * [Java中的锁](#java中的锁)
  * [java中的happen before原则](#java中的happen-before原则)
  * [java并发控制机制](#java并发控制机制)
    * [AQS底层原理](#aqs底层原理)
    * [信号量Semaphore](#信号量semaphore)
    * [CountDownLatch](#countdownlatch)
    * [CyclicBarrier](#cyclicbarrier)
  * [Exchanger](#exchanger)
  * [调试利器-SSH隧道](#调试利器-ssh隧道)
  * [限流](#限流)
    * [单机](#单机)
      * [计数器限流算法](#计数器限流算法)
      * [漏桶算法](#漏桶算法)
      * [令牌桶算法](#令牌桶算法)
    * [分布式限流](#分布式限流)
      * [redis+lua分布式限流](#redislua分布式限流)
      * [Nginx+Lua实现限流：](#nginxlua实现限流)
    * [Nginx限流原理](#nginx限流原理)
    * [springcloud限流](#springcloud限流)
      * [基于springcloud-gateway的Filter限流](#基于springcloud-gateway的filter限流)
      * [基于Sentinel的限流](#基于sentinel的限流)
  * [Callable、Future和FutureTask](#callablefuture和futuretask)
  * [java 几种任务调度方法(框架)原理及对比](#java-几种任务调度方法框架原理及对比)
  * [Java Timer和TimerTask](#java-timer和timertask)
  * [springBoot的@Scheduled原理](#springboot的scheduled原理)
  * [session cookie token](#session-cookie-token)
    * [cookie](#cookie)
    * [session](#session)
    * [token](#token)




## collection与collections的区别
首先，Collection是接口，Collections是类。
Collection是set和list的父接口，需要注意的是map也是一个接口，它和collection没有继承派生的关系。
Collections是针对集合类的一个工具类，提供了操作集合的工具方法：一系列静态方法实现对各种集合的搜索、排序、线程安全化(比如Collections.synchronizedList使链表安全)等操作。它通过将**构造函数私有化**来避免创建对象。

java集合架构图如下所示：

![此处输入图片的描述][1]

## hashmap对于重复key的处理

首先看一篇参考笔记：

- https://blog.csdn.net/hefenglian/article/details/79763634

文章写的很好，以JDK1.8为例，详细的讲述了hashmap中几个重要的函数，get\put\resize等。

hashmap的key重复的话，那么必然会导致记得得到的hash（key）重复，存储的位置也会相同，所以是value会产生**覆盖**的效果。

hashmap的所有节点元素都是一个Node<k,v>，Node节点的源代码（链接上的哥们儿给的注释，挺详细的）如下所示：
```java
    //Node是单向链表，它实现了Map.Entry接口
    static class Node<k,v> implements Map.Entry<k,v> {
        final int hash; K key;
        V value;
        Node<k,v> next;
        //构造函数Hash值 键 值 下一个节点
        Node(int hash, K key, V value, Node<k,v> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
     
        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + = + value; }
     
        public final int hashCode() {
            return Objects.hashCode(key) ^ Objects.hashCode(value);
        }
     
        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }
        //判断两个node是否相等,若key和value都相等，返回true。可以与自身比较为true
        public final boolean equals(Object o) {
            if (o == this)
                return true;
            if (o instanceof Map.Entry) {
                Map.Entry<!--?,?--> e = (Map.Entry<!--?,?-->)o;
                if (Objects.equals(key, e.getKey()) &&
                    Objects.equals(value, e.getValue()))
                    return true;
            }
            return false;
        }
```
hashmap的构造函数可以指定初始容量（注意不一定要是2的幂次，是基数也可以，但是tableSizeFor函数会自动调整为最近的2的幂次），也可以不指定，此时大小为默认值16，也可以指定hahmap的装载比，源码如下：
```java
//构造函数1
public HashMap(int initialCapacity, float loadFactor) {
    //指定的初始容量非负
    if (initialCapacity < 0)
        throw new IllegalArgumentException(Illegal initial capacity:  +
                                           initialCapacity);
    //如果指定的初始容量大于最大容量,置为最大容量
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    //填充比为正
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException(Illegal load factor:  +
                                           loadFactor);
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);//新的扩容临界值
}
 
//构造函数2
public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}
 
//构造函数3
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}
 
//构造函数4用m的元素初始化散列映射
public HashMap(Map<? extends K, ? extends V> m) {
    this.loadFactor = DEFAULT_LOAD_FACTOR;
    putMapEntries(m, false);
}
```
hashmap获取value的机制：使用hash（key）和n-1（n=tab.length）进行位与操作，避免出现越界的情况。

取元素的时候，首先根据hash（key）定位元素的位置，然后首个元素是不是需要的元素（判断的原则是hash值相等，且key相等），如果不是就继续取元素，取的时候分为链表遍历和红黑树遍历。
```java
public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }
	  /**
     * Implements Map.get and related methods
     *
     * @param hash hash for key
     * @param key the key
     * @return the node, or null if none
     */
	final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab;//Entry对象数组
	Node<K,V> first,e; //在tab数组中经过散列的第一个位置
	int n;
	K k;
	/*找到插入的第一个Node，方法是hash值和n-1相与，tab[(n - 1) & hash]*/
	//也就是说在一条链上的hash值相同的
        if ((tab = table) != null && (n = tab.length) > 0 &&(first = tab[(n - 1) & hash]) != null) {
	/*检查第一个Node是不是要找的Node*/
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))//判断条件是hash值要相同，key值要相同
                return first;
	  /*检查first后面的node*/
            if ((e = first.next) != null) {
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
				/*遍历后面的链表，找到key值和hash值都相同的Node*/
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }
```
hashmap存储Node的机制：

下面是源码。

put的时候首先判断hash表是否创建了，没有就创建一个；

然后使用hash（key）&（n-1）来确定该put的位置，如果要put的位置没有元素，那么直接put；

否则，如果key相同，那么就执行替换操作；

如果不同，且是treeNode，那么就按照红黑树的put方式放入元素；
若是链表，就在链表的尾部put元素。

需要注意HashMap是允许key为null的情况的，若key为null，那么久放在tab数组的0位置处，那为什么null为key的元素会放在这个位置，因为hash函数计算hash就这么算的。
```java
public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
	 /**
     * Implements Map.put and related methods
     *
     * @param hash hash for key
     * @param key the key
     * @param value the value to put
     * @param onlyIfAbsent if true, don't change existing value
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none 注意这个返回值情况，因为在set的add方法中会调用这个putval方法，并且通过返回值来判断是否加入成功的
     * putval函数会在执行完put操作以后进行判断，是否需要扩容resize
     */
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; 
	Node<K,V> p; 
	int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
	/*如果table的在（n-1）&hash的值是空，就新建一个节点插入在该位置*/
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
	/*表示有冲突,开始处理冲突*/
        else {
            Node<K,V> e; 
	    K k;
	/*检查第一个Node，p是不是要找的值*/
            if (p.hash == hash &&((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                for (int binCount = 0; ; ++binCount) {
		/*指针为空就挂在后面*/
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
		       //如果冲突的节点数已经达到8个，看是否需要改变冲突节点的存储结构，　　　　　　　　　　　　　
　　　　　　　　　　　　//treeifyBin首先判断当前hashMap的长度，如果不足64，只进行
                        //resize，扩容table，如果达到64，那么将冲突的存储结构为红黑树
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
		/*如果有相同的key值就结束遍历*/
                    if (e.hash == hash &&((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
	/*就是链表上有相同的key值*/
            if (e != null) { // existing mapping for key，就是key的Value存在
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;//返回存在的Value值
            }
        }
        ++modCount;
     /*如果当前大小大于门限，门限原本是初始容量*0.75*/
        if (++size > threshold)
            resize();//扩容两倍
        afterNodeInsertion(evict);
        return null;
    }
```
hash函数
```java
    /**
     * Computes key.hashCode() and spreads (XORs) higher bits of hash
     * to lower.  Because the table uses power-of-two masking, sets of
     * hashes that vary only in bits above the current mask will
     * always collide. (Among known examples are sets of Float keys
     * holding consecutive whole numbers in small tables.)  So we
     * apply a transform that spreads the impact of higher bits
     * downward. There is a tradeoff between speed, utility, and
     * quality of bit-spreading. Because many common sets of hashes
     * are already reasonably distributed (so don't benefit from
     * spreading), and because we use trees to handle large sets of
     * collisions in bins, we just XOR some shifted bits in the
     * cheapest possible way to reduce systematic lossage, as well as
     * to incorporate impact of the highest bits that would otherwise
     * never be used in index calculations because of table bounds.
     */
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```

hashmap的resize()函数

构造hash表时，如果不指明初始大小，默认大小为16（即Node数组大小16），如果Node[]数组中的元素达到（填充比*Node.length）重新调整HashMap大小 变为原来2倍大小，**扩容很耗时**
resize函数不仅仅要完成map的扩容，还要完成hash表元素位置的迁移。
resize的时候，可能有2种情况。

一是hash表本就是空的，且门限值thresHold>0,此时需要将 
```java
newCap = oldThr;  
```
如果门限值thresHold<=0,需要按照默认大小进行hash表的创建

二是hash表不为空，此时需要进行2倍扩容和Node元素存储位置更改，元素位置的移动要参考[这里](http://www.importnew.com/20386.html)，注意其中resize的部分

下面是resize函数的源码：
```java
  /**
     * Initializes or doubles table size.  If null, allocates in
     * accord with initial capacity target held in field threshold.
     * Otherwise, because we are using power-of-two expansion, the
     * elements from each bin must either stay at same index, or move
     * with a power of two offset in the new table.
     *
     * @return the table
     */
    final Node<K,V>[] resize() {
        Node<K,V>[] oldTab = table;
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        int oldThr = threshold;
        int newCap, newThr = 0;
		
	/*如果旧表的长度不是空*/
        if (oldCap > 0) {
            if (oldCap >= MAXIMUM_CAPACITY) {
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
	/*把新表的长度设置为旧表长度的两倍，newCap=2*oldCap*/
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)
	      /*把新表的门限设置为旧表门限的两倍，newThr=oldThr*2*/
                newThr = oldThr << 1; // double threshold
        }
     /*如果旧表的长度的是0，就是说第一次初始化表*/
        else if (oldThr > 0) // initial capacity was placed in threshold
            newCap = oldThr;
        else {               // zero initial threshold signifies using defaults
            newCap = DEFAULT_INITIAL_CAPACITY;
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
		
		
		
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;//新表长度乘以加载因子
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
	/*下面开始构造新表，初始化表中的数据*/
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        table = newTab;//把新表赋值给table
        if (oldTab != null) {//原表不是空要把原表中数据移动到新表中	
            /*遍历原来的旧表*/		
            for (int j = 0; j < oldCap; ++j) {
                Node<K,V> e;
                if ((e = oldTab[j]) != null) {
                    oldTab[j] = null;
                    if (e.next == null)//说明这个node没有链表直接放在新表的e.hash & (newCap - 1)位置
                        newTab[e.hash & (newCap - 1)] = e;
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
	/*如果e后边有链表,到这里表示e后面带着个单链表，需要遍历单链表，将每个结点重*/
                    else { // preserve order保证顺序
					////新计算在新表的位置，并进行搬运
                        Node<K,V> loHead = null, loTail = null;
                        Node<K,V> hiHead = null, hiTail = null;
                        Node<K,V> next;
						
                        do {
                            next = e.next;//记录下一个结点
			  //新表是旧表的两倍容量，实例上就把单链表拆分为两队，
　　　　　　　　　　　　　　//e.hash&oldCap为偶数一队，e.hash&oldCap为奇数一对
                            if ((e.hash & oldCap) == 0) {
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }
                            else {
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);
						
                        if (loTail != null) {//lo队不为null，放在新表原位置
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        if (hiTail != null) {//hi队不为null，放在新表j+oldCap位置
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }
```
如果同一个entryset位置存储的元素>=8时，hashmap就会采用红黑树的方式来存储元素，可以查找的时间复杂度从O(N)降为O(logN)。

## JDK1.8HashMap的红黑树

如果某个桶中的记录过大的话（当前是TREEIFY_THRESHOLD = 8），HashMap会动态的使用一个专门的treemap实现来替换掉它。这样做的结果会更好，是O(logn)，而不是糟糕的O(n)。
它是如何工作的？前面产生冲突的那些KEY对应的记录只是简单的追加到一个链表后面，这些记录只能通过遍历来进行查找。但是超过这个阈值后HashMap开始将列表升级成一个二叉树，使用哈希值作为树的分支变量，如果两个哈希值不等，但指向同一个桶的话，较大的那个会插入到右子树里。如果哈希值相等，HashMap希望key值最好是实现了Comparable接口的，这样它可以按照顺序来进行插入。这对HashMap的key来说并不是必须的，不过如果实现了当然最好。如果没有实现这个接口，在出现严重的哈希碰撞的时候，你就别指望能获得性能提升了。

## java中length,length(),size()
java中的length属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了length这个属性.
java中的length()方法是针对字符串String说的,如果想看这个字符串的长度则用到length()这个方法，需要注意的是，它计算长度是unicode编码格式的，也就是说1个中文字符算1个，而不是2个。
下面是string类的length()方法的源码：
```java
 /**
     * Returns the length of this string.
     * The length is equal to the number of <a href="Character.html#unicode">Unicode
     * code units</a> in the string.
     *
     * @return  the length of the sequence of characters represented by this
     *          object.
     */
    public int length() {
        return value.length;
    }
```
java中的size()方法是针对泛型集合（Map，Collection）说的,如果想看这个泛型有多少个元素,就调用此方法来查看
map接口中的size()源码：
```java
    /**
     * Returns the number of key-value mappings in this map.  If the
     * map contains more than <tt>Integer.MAX_VALUE</tt> elements, returns
     * <tt>Integer.MAX_VALUE</tt>.
     *
     * @return the number of key-value mappings in this map
     */
    int size();
```
collection接口中的size()源码：
```java
/**
     * Returns the number of elements in this collection.  If this collection
     * contains more than <tt>Integer.MAX_VALUE</tt> elements, returns
     * <tt>Integer.MAX_VALUE</tt>.
     *
     * @return the number of elements in this collection
     */
    int size();
```

## 进程与线程

**进程**：cpu资源分配的最小单位，拥有独立的内存单元，可以拥有一个或者多个线程。多个线程共享内存。共享复杂，但是同步简单，需要使用IPC（Inter-Process Communication）。

**线程**：cpu调度的最小单位，线程间共享进程的资源，共享简单，但是同步复杂，需要加锁。

**同一进程间的线程究竟共享哪些资源呢，而又各自独享哪些资源呢？**

 - 共享的资源有

**a. 堆**  由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的（16位平台上分全局堆和局部堆，局部堆是独享的）

**b. 全局变量** 它是与具体某一函数无关的，所以也与特定线程无关；因此也是共享的

**c. 静态变量** 虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的.bss和.data段，是共享的

**d. 文件等公用资源**  这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。

 - 独享的资源有

**a. 栈** 栈（虚拟机栈）是独享的

**b. 寄存器**  这个可能会误解，因为电脑的寄存器是物理的，每个线程去取值难道不一样吗？其实线程里存放的是副本，包括程序计数器PC

**c.程序计数器**它可以看做是当前线程所执行的字节码的行号指示器。

### 进程间通信方式

 - 管道(pipe)

    管道是一种具有两个端点的通信通道，一个管道实际上就是只存在在内存中的**文件**，**对这个文件操作需要两个已经打开文件进行，他们代表管道的两端，也叫两个句柄**，管道是一种特殊的文件，不属于一种文件系统，而是一种独立的文件系统，有自己的数据结构，根据管道的使用范围划分为无名管道和命名管道。
**无名管道**用于父进程和子进程之间，通常父进程创建管道，然后由通信的子进程继承父进程的读端点句柄和写端点句柄，或者父进程有读写句柄的子进程，这些子进程可以使用管道直接通信，不需要通过父进程。
**命名管道**，命名管道是为了解决无名管道只能在父子进程间通信而设计的，命名管道是建立在实际的磁盘介质或文件系统(而不是只存在内存中)，任何进程可以通过文件名或路径建立与该文件的联系，命名管道需要一种FIFO文件(有先进先出的原则)，虽然FIFO文件的inode节点在磁盘上，但仅是一个节点而已，文件的数据还是存在于内存缓冲页面中，和普通管道相同。

 - 信号量( semophore ) ：

 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

 - 消息队列( message queue ) ：

 消息队列是消息的链表，包括Posix消息队列和system v消息队列(Posix常用于线程，system常用于进程)，有权限的进程可以向消息队列中添加消息，有读权限的进程可以读走消息队列的消息。
消息队列克服了信号承载信息量少，管道只能承载无格式字节流及缓冲区大小受限等缺陷。

 - 共享内存( shared memory )

 ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是**最快**的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。传递文件最好用共享内存的方式。 
套接字( socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于**不同机器**间的进程通信。

## 多线程之生产者消费者

### 借助Object类方法
注意，下面的代码中的if判断，应该改为while循环。
下面的代码创建了2个消费者线程，这样会出现数据越界的错误，就是因为没有使用while的原因。
```java
/*
    生产和消费
*/
package multiThread;

class SynStack 
{
    private char[] data = new char[6];
    private int cnt = 0; //表示数组有效元素的个数
    
    public synchronized void push(char ch)
    {
        if (cnt >= data.length)
        {
            try
            {
                System.out.println("生产线程"+Thread.currentThread().getName()+"准备休眠");
                this.wait();
                System.out.println("生产线程"+Thread.currentThread().getName()+"休眠结束了");
            }
            catch (Exception e)
            {
                e.printStackTrace();
            }
        }
        this.notify(); 
        data[cnt] = ch;
        ++cnt;
        System.out.printf("生产线程"+Thread.currentThread().getName()+"正在生产第%d个产品，该产品是: %c\n", cnt, ch);
    }
    
    public synchronized char pop()
    {
        char ch;
        if (cnt <= 0)
        {
            try
            {
                System.out.println("消费线程"+Thread.currentThread().getName()+"准备休眠");
                this.wait();
                System.out.println("消费线程"+Thread.currentThread().getName()+"休眠结束了");
            }
            catch (Exception e)
            {
                e.printStackTrace();
            }
        }
        this.notify();
        ch = data[cnt-1];
        System.out.printf("消费线程"+Thread.currentThread().getName()+"正在消费第%d个产品，该产品是: %c\n", cnt, ch);
        --cnt;
        return ch;        
    }    
}

class Producer implements Runnable
{
    private SynStack ss = null;
    public Producer(SynStack ss)
    {
        this.ss = ss;
    }
    
    public void run()
    {
        char ch;
        for (int i=0; i<10; ++i)
        {
//            try{
//            Thread.sleep(100);
//            }
//            catch (Exception e){            
//            }
                
            ch = (char)('a'+i);
            ss.push(ch);
        }
    }
}

class Consumer implements Runnable
{
    private SynStack ss = null;
    
    public Consumer(SynStack ss)
    {
        this.ss = ss;
    }
    
    public void run()
    {
        for (int i=0; i<10; ++i)
        {
            /*try{
            Thread.sleep(100);
            }
            catch (Exception e){            
            }*/
            
            //System.out.printf("%c\n", ss.pop());
            ss.pop();
        }
    }
}


public class TestPC2
{
    public static void main(String[] args)
    {
        SynStack ss = new SynStack();
        Producer p = new Producer(ss);
        Consumer c = new Consumer(ss);
        
        
        Thread t1 = new Thread(p);
        t1.setName("1号");
        t1.start();
        /*Thread t2 = new Thread(p);
        t2.setName("2号");
        t2.start();*/
                
        Thread t6 = new Thread(c);
        t6.setName("6号");
        t6.start();
        Thread t7 = new Thread(c);
        t7.setName("7号");
        t7.start();
    }
}
```

### 借助BlockingQueue

由于BlockingQueue接口的实现类LinkedBlockingQueue的put、take等方法都做了加锁并发控制。因此，我们可以借助其，方便的实现生产者-消费者模式：

首先是生产者
```java
package com.audi.demo.procon;

import java.util.Random;
import java.util.concurrent.BlockingQueue;

/**
 * 生产者 使用put方法进行生产入队操作ø
 *
 * @author: WangQuanzhou
 * @date: 2021-10-06 3:20 PM
 */
public class Producer implements Runnable {

    private final BlockingQueue sharedQueue;
    private final int size;

    public Producer(BlockingQueue sharedQueue, int size) {
        this.sharedQueue = sharedQueue;
        this.size = size;
    }

    @Override
    public void run() {
        Random random = new Random();
        while (true) {
            if (sharedQueue.size() < size) {
                try {
                    int i = random.nextInt(100000);
                    System.out.println("Produced: " + i);
                    sharedQueue.put(i);
                } catch (InterruptedException ex) {
                    System.out.println(ex);
                }
            }
        }

    }
}
```

然后是消费者：
```java
package com.audi.demo.procon;

import java.util.concurrent.BlockingQueue;

/**
 * 消费者  使用take方法进行出队  可以实例化多个
 *
 * @author: WangQuanzhou
 * @date: 2021-10-06 3:20 PM
 */
public class Consumer implements Runnable {

    private final BlockingQueue blockingQueue;

    public Consumer(BlockingQueue blockingQueue) {
        this.blockingQueue = blockingQueue;
    }

    @Override
    public void run() {

        while (true) {
            if (blockingQueue.size() > 0) {
                try {
                    System.out.println(Thread.currentThread().getName() + " Consumed: " + blockingQueue.take());
                } catch (InterruptedException ex) {
                    System.out.println(ex);
                }
            }
        }
    }
}
```

最后进行测试：
```java
package com.audi.demo.procon;

import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;

public class ProducerConsumerPattern {

    public static void main(String args[]) throws InterruptedException {

        // 实例化一个有界的阻塞队列
        BlockingQueue sharedQueue = new LinkedBlockingQueue(10);

        // 初始化生产者 传入有界队列的大小  方便做拥塞控制
        Thread prodThread = new Thread(new Producer(sharedQueue, 10));

        // 初始化两个消费者
        Thread consThread1 = new Thread(new Consumer(sharedQueue));
        Thread consThread2 = new Thread(new Consumer(sharedQueue));

        // 启动生产者
        prodThread.start();

        // 这里消费者 延迟启动，以测试生产者是否可以持续进行生产
        Thread.sleep(200);
        consThread1.start();
        consThread2.start();
    }
}
```

## Java中的访问控制符号
需要特别说明“无修饰符”这个情况，子类能否访问父类中无修饰符的变量/方法，取决于**子类的位置**。如果**子类和父类在同一个包**中，那么子类可以访问父类中的无修饰符的变量/方法，否则不行。

| ...        | private   |  default  |protected|public|
| --------   | :-----:  | :----:  |:----:|:----:|
| 同一个类     | √ |   √     |√|√|
| 同一个包        |      |   √   |√|√|
| 子类        |        |    |√|√|
| 全局        |        |    ||√|


## Java中set的底层实现
Set是对数学上集的抽象,Set中不包含重复的元素.如何界定是否是重复元素?Set最多可含一个null元素;对于任意的非null元素e1和e2,都满足e1.equals(e2)==false.

**Set实现**

HashSet是使用一个哈希表存储元素的,是非排序的,可以随机访问,是Set的最优性能实现.TreeSet实现了treeMap接口,使用一个红黑树（如果出现相等的key，那么新的元素直接替换旧的元素）来存储元素,提供了元素的有序存储和访问.
```java
// Dummy value to associate with an Object in the backing Map
// 意思就是为了和hashmap的key-value方式保持一致，set这里假定了一个value值，没有实际意义
    private static final Object PRESENT = new Object();
/**
     * Constructs a new, empty set; the backing <tt>HashMap</tt> instance has
     * default initial capacity (16) and load factor (0.75).
     *   可以看出hashset的底层是使用hashmap来实现的
     */
    public HashSet() {
        map = new HashMap<>();
    }

    /**
     * Constructs a new set containing the elements in the specified
     * collection.  The <tt>HashMap</tt> is created with default load factor
     * (0.75) and an initial capacity sufficient to contain the elements in
     * the specified collection.
     *
     * @param c the collection whose elements are to be placed into this set
     * @throws NullPointerException if the specified collection is null
     * 注意下面构造函数的+1操作，因为是int格式转换的时候浮点数是向下转的，也就是说6.66f会转为6
     */
    public HashSet(Collection<? extends E> c) {
        map = new HashMap<>(Math.max((int) (c.size()/.75f) + 1, 16));
        addAll(c);
    }

    /**
     * Constructs a new, empty set; the backing <tt>HashMap</tt> instance has
     * the specified initial capacity and the specified load factor.
     *
     * @param      initialCapacity   the initial capacity of the hash map
     * @param      loadFactor        the load factor of the hash map
     * @throws     IllegalArgumentException if the initial capacity is less
     *             than zero, or if the load factor is nonpositive
     */
    public HashSet(int initialCapacity, float loadFactor) {
        map = new HashMap<>(initialCapacity, loadFactor);
    }

    /**
     * Constructs a new, empty set; the backing <tt>HashMap</tt> instance has
     * the specified initial capacity and default load factor (0.75).
     *
     * @param      initialCapacity   the initial capacity of the hash table
     * @throws     IllegalArgumentException if the initial capacity is less
     *             than zero
     */
    public HashSet(int initialCapacity) {
        map = new HashMap<>(initialCapacity);
    }

    /**
     * Constructs a new, empty linked hash set.  (This package private
     * constructor is only used by LinkedHashSet.) The backing
     * HashMap instance is a LinkedHashMap with the specified initial
     * capacity and the specified load factor.
     *
     * @param      initialCapacity   the initial capacity of the hash map
     * @param      loadFactor        the load factor of the hash map
     * @param      dummy             ignored (distinguishes this
     *             constructor from other int, float constructor.)
     * @throws     IllegalArgumentException if the initial capacity is less
     *             than zero, or if the load factor is nonpositive
     * 下满函数是default访问权限的，作域在当前类或者同包中
     */
    HashSet(int initialCapacity, float loadFactor, boolean dummy) {
        map = new LinkedHashMap<>(initialCapacity, loadFactor);
    }
```
由于set要求内部所有的元素都不重复，那么我们就来看一下它的contains函数和add函数以及remove函数的实现过程。
```java
/**
     * Returns <tt>true</tt> if this set contains the specified element.
     * More formally, returns <tt>true</tt> if and only if this set
     * contains an element <tt>e</tt> such that
     * <tt>(o==null&nbsp;?&nbsp;e==null&nbsp;:&nbsp;o.equals(e))</tt>.
     *
     * @param o element whose presence in this set is to be tested
     * @return <tt>true</tt> if this set contains the specified element
     * 这里contains方法调用了hashmap的containsKey方法，因为hashmap的key总是唯一的，不存在重复的情况。
     */
    public boolean contains(Object o) {
        return map.containsKey(o);
    }

    /**
     * Adds the specified element to this set if it is not already present.
     * More formally, adds the specified element <tt>e</tt> to this set if
     * this set contains no element <tt>e2</tt> such that
     * <tt>(e==null&nbsp;?&nbsp;e2==null&nbsp;:&nbsp;e.equals(e2))</tt>.
     * If this set already contains the element, the call leaves the set
     * unchanged and returns <tt>false</tt>.
     *
     * @param e element to be added to this set
     * @return <tt>true</tt> if this set did not already contain the specified
     * element
     * 如果元素存在，那么不对set做任何更改，并且返回false
     */
    public boolean add(E e) {
        return map.put(e, PRESENT)==null;
    }

    /**
     * Removes the specified element from this set if it is present.
     * More formally, removes an element <tt>e</tt> such that
     * <tt>(o==null&nbsp;?&nbsp;e==null&nbsp;:&nbsp;o.equals(e))</tt>,
     * if this set contains such an element.  Returns <tt>true</tt> if
     * this set contained the element (or equivalently, if this set
     * changed as a result of the call).  (This set will not contain the
     * element once the call returns.)
     *
     * @param o object to be removed from this set, if present
     * @return <tt>true</tt> if the set contained the specified element
     * map.remove函数如果成功remove一个存在的元素，那么会返回remove的元素的value 
     */
    public boolean remove(Object o) {
        return map.remove(o)==PRESENT;
    }
```
下面看下TreeSet的实现过程，从源码中可以看出treeset的实现是通过treemap来实现的,TreeMap是NavigableMap的子类,NavigableMap是SortedMap的子类，SortedMap实现了Map接口  
下面是源码：
```java
/**
     * Constructs a set backed by the specified navigable map.
     *  TreeMap是NavigableMap的子类
     */
    TreeSet(NavigableMap<E,Object> m) {
        this.m = m;
    }

    /**
     * Constructs a new, empty tree set, sorted according to the
     * natural ordering of its elements.  All elements inserted into
     * the set must implement the {@link Comparable} interface.
     * Furthermore, all such elements must be <i>mutually
     * comparable</i>: {@code e1.compareTo(e2)} must not throw a
     * {@code ClassCastException} for any elements {@code e1} and
     * {@code e2} in the set.  If the user attempts to add an element
     * to the set that violates this constraint (for example, the user
     * attempts to add a string element to a set whose elements are
     * integers), the {@code add} call will throw a
     * {@code ClassCastException}.
     */
    public TreeSet() {
        this(new TreeMap<E,Object>());
    }

    /**
     * Constructs a new, empty tree set, sorted according to the specified
     * comparator.  All elements inserted into the set must be <i>mutually
     * comparable</i> by the specified comparator: {@code comparator.compare(e1,
     * e2)} must not throw a {@code ClassCastException} for any elements
     * {@code e1} and {@code e2} in the set.  If the user attempts to add
     * an element to the set that violates this constraint, the
     * {@code add} call will throw a {@code ClassCastException}.
     *
     * @param comparator the comparator that will be used to order this set.
     *        If {@code null}, the {@linkplain Comparable natural
     *        ordering} of the elements will be used.
     */
    public TreeSet(Comparator<? super E> comparator) {
        this(new TreeMap<>(comparator));
    }

    /**
     * Constructs a new tree set containing the elements in the specified
     * collection, sorted according to the <i>natural ordering</i> of its
     * elements.  All elements inserted into the set must implement the
     * {@link Comparable} interface.  Furthermore, all such elements must be
     * <i>mutually comparable</i>: {@code e1.compareTo(e2)} must not throw a
     * {@code ClassCastException} for any elements {@code e1} and
     * {@code e2} in the set.
     *
     * @param c collection whose elements will comprise the new set
     * @throws ClassCastException if the elements in {@code c} are
     *         not {@link Comparable}, or are not mutually comparable
     * @throws NullPointerException if the specified collection is null
     */
    public TreeSet(Collection<? extends E> c) {
        this();
        addAll(c);
    }

    /**
     * Constructs a new tree set containing the same elements and
     * using the same ordering as the specified sorted set.
     *
     * @param s sorted set whose elements will comprise the new set
     * @throws NullPointerException if the specified sorted set is null
     */
    public TreeSet(SortedSet<E> s) {
        this(s.comparator());
        addAll(s);
    }
```

## 为什么需要重写hashcode方法与equals方法
这个主要是考虑到java集合中的set特性，它要求元素不重复，那么需要hashcode和equals都相等才可以。这里需要注意，hashset的底层也是使用hashmap来实现的，hashmap在put元素的时候，就需要先判断hashcode，如果相等，再判断equals，如果还相等，那么证明元素相等，就进行**替换**。
另外，如果不进行重写，对于我们自定义的对象，程序也不知道我们判断两个对象相等的条件是（比如People对象，身份证号码（ID）相等就是相等），所以必须进行重写，否则根本无法判断对象是否重复。
看一下Object.hashCode的通用约定（摘自《Effective Java》第45页）
    

 - 在一个应用程序执行期间，如果一个对象的equals方法做比较所用到的信息没有被修改的话，那么，对该对象调用hashCode方法多次，它必须始终如一地返回 同一个整数。在同一个应用程序的多次执行过程中，这个整数可以不同，即这个应用程序这次执行返回的整数与下一次执行返回的整数可以不一致。
    

 - 如果两个对象根据equals(Object)方法是相等的，那么调用这两个对象中任一个对象的hashCode方法必须产生同样的整数结果。
  

 - 如果两个对象根据equals(Object)方法是不相等的，那么调用这两个对象中任一个对象的hashCode方法，不要求必须产生不同的整数结果。然而，程序员应该意识到这样的事实，对于不相等的对象产生截然不同的整数结果，有可能提高散列表（hash
   table）的性能。

     如果只重写了equals方法而没有重写hashCode方法的话，则会违反约定的第二条：相等的对象必须具有相等的散列码（hashCode）
     同时对于HashSet和HashMap这些基于散列值（hash）实现的类。HashMap的底层处理机制是以数组的方法保存放入的数据的(Node<K,V>[] table)，其中的关键是数组下标的处理。数组的下标是根据传入的元素hashCode方法的返回值再和特定的值异或决定的。如果该数组位置上已经有放入的值了，且传入的键值相等则不处理，若不相等则覆盖原来的值，如果数组位置没有条目，则插入，并加入到相应的链表中。检查键是否存在也是根据hashCode值来确定的。所以如果不重写hashCode的话，可能导致HashSet、HashMap不能正常的运作、
  如果我们将某个自定义对象存到HashMap或者HashSet及其类似实现类中的时候，如果该对象的属性参与了hashCode的计算，那么就不能修改该对象参数hashCode计算的属性了。有可能会移除不了元素，导致内存泄漏。

## Java的深复制浅复制

 - http://blog.csdn.net/zhangjg_blog/article/details/18369201
 
### 浅复制

 对于简单对象，都是浅复制。对于引用对象，浅复制就是栈指针指向堆中同一地址空间。

### 深复制

  对于堆中的对象，在堆中产生一份相同的拷贝，并在栈中建立一个指向这个地址空间的引用。
Java当中，一般可以通过new关键字或者clone方法创建或者复制一个对象。
程序执行到new操作符时，首先去看new操作符后面的类型，因为知道了类型，才能知道要分配多大的内存空间。分配完内存之后，再调用构造函数，填充对象的各个域，这一步叫做对象的初始化，构造方法返回后，一个对象创建完毕，可以把他的引用（地址）发布到外部，在外部就可以使用这个引用操纵这个对象。
而clone在第一步是和new相似的，都是分配内存，调用clone方法时，分配的内存和源对象（即调用clone方法的对象）相同，然后再使用原对象中对应的各个域，填充新对象的域，填充完成之后，clone方法返回，一个新的相同的对象被创建，同样可以把这个新对象的引用发布到外部。 
下面展示一个完全深拷贝的例子，尤其要注意类中嵌套类（区别于简单对象）的形式。
```java
package com.audi;

public class TestClone
{
	static class Body implements Cloneable
	{
		public Head head;

		public Body()
		{
		}

		public Body(Head head)
		{
			this.head = head;
		}

		@Override
		protected Object clone() throws CloneNotSupportedException
		{
			Body newBody = (Body) super.clone();
			newBody.head = (Head) head.clone();
			return newBody;
		}

	}

	static class Head implements Cloneable
	{
		public Face face;

		public Head()
		{
		}

		public Head(Face face)
		{
			this.face = face;
		}

		@Override
		protected Object clone() throws CloneNotSupportedException
		{
			//return super.clone();
			
			// 实现完全的深拷贝
			Head newHead = (Head) super.clone();  
	        newHead.face = (Face) this.face.clone();  
	        return newHead;
		}
	}

	// static class Face{}

	// 为了实现完全的深拷贝  所以Face类也需要实现cloneable接口
	static class Face implements Cloneable
	{
		@Override
		protected Object clone() throws CloneNotSupportedException
		{
			return super.clone();
		}
	}

	public static void main(String[] args) throws CloneNotSupportedException
	{
		Body body = new Body(new Head(new Face()));
		Body body1 = (Body) body.clone();

		System.out.println("body == body1 : " + (body == body1));
		System.out.println("body.head == body1.head : " + (body.head == body1.head));
		System.out.println("body.head.face == body1.head.face : " + (body.head.face == body1.head.face));
	}
}

```

## string类的源码分析，为什么是不可变的
string类之所以是immutable的，是因为value字符数组它一旦初始化，就无法更改，且没有提供相应的set方法来修改。
```java
/** The value is used for character storage. */
    private final char value[];
```
那么string类的replace方法是如何进行替换的呢？源代码中很明显的指出：如果存在可以替换的字符，那么就替换字符，并且使用string的构造函数新建一个对象进行返回；
如果不存在替换的字符，那么直接返回原字符串对象。
上源码：
```java
/**
     * Returns a string resulting from replacing all occurrences of
     * {@code oldChar} in this string with {@code newChar}.
     * <p>
     * If the character {@code oldChar} does not occur in the
     * character sequence represented by this {@code String} object,
     * then a reference to this {@code String} object is returned.
     * Otherwise, a {@code String} object is returned that
     * represents a character sequence identical to the character sequence
     * represented by this {@code String} object, except that every
     * occurrence of {@code oldChar} is replaced by an occurrence
     * of {@code newChar}.
     * <p>
     * Examples:
     * <blockquote><pre>
     * "mesquite in your cellar".replace('e', 'o')
     *         returns "mosquito in your collar"
     * "the war of baronets".replace('r', 'y')
     *         returns "the way of bayonets"
     * "sparring with a purple porpoise".replace('p', 't')
     *         returns "starring with a turtle tortoise"
     * "JonL".replace('q', 'x') returns "JonL" (no change)
     * </pre></blockquote>
     *
     * @param   oldChar   the old character.
     * @param   newChar   the new character.
     * @return  a string derived from this string by replacing every
     *          occurrence of {@code oldChar} with {@code newChar}.
     */
    public String replace(char oldChar, char newChar) {
        if (oldChar != newChar) {
            int len = value.length;
            int i = -1;
            char[] val = value; /* avoid getfield opcode */

            while (++i < len) {
                if (val[i] == oldChar) {
                    break;
                }
            }
            if (i < len) {
                char buf[] = new char[len];
                for (int j = 0; j < i; j++) {
                    buf[j] = val[j];
                }
                while (i < len) {
                    char c = val[i];
                    buf[i] = (c == oldChar) ? newChar : c;
                    i++;
                }
                return new String(buf, true);
            }
        }
        return this;
    }
```
对于不可变对象，如果使用反射的方法，是可以改变某些值的。

## springMVC集成quartz

下面是spring中一种典型的quartz集成配置方式
```xml
<!------------ 配置调度程序quartz ，其中配置JobDetail有两种方式-------------->    
    <!--方式一：使用JobDetailBean，任务类必须实现Job接口 -->     
    <bean id="myjob" class="org.springframework.scheduling.quartz.JobDetailBean">    
     <property name="name" value="exampleJob"></property>    
     <property name="jobClass" value="com.ncs.hj.SpringQtz"></property>   
     <property name="jobDataAsMap">  
<map>  
    <entry key="service"><value>simple is the beat</value></entry>  
</map>  
;/property>  
    </bean>   
    <!--运行时请将方式一注释掉！ -->    
    <!-- 方式二：使用MethodInvokingJobDetailFactoryBean，任务类可以不实现Job接口，通过targetMethod指定调用方法-->    
    <!-- 定义目标bean和bean中的方法 -->  
    <!-- SpringQtzJob就是定时任务到的时候需要调用知道的bean，execute就是这个bean内部的一个方法 -->  
    <bean id="SpringQtzJob" class="com.ncs.hj.SpringQtz"/>  
    <bean id="SpringQtzJobMethod" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean">  
    <property name="targetObject">  
        <ref bean="SpringQtzJob"/>  
    </property>  
    <property name="targetMethod">  <!-- 要执行的方法名称 -->  
        <value>execute</value>  
    </property>  
</bean>  
  
<!-- ======================== 调度触发器 ======================== -->  
<bean id="CronTriggerBean" class="org.springframework.scheduling.quartz.CronTriggerBean">  
    <property name="jobDetail" ref="SpringQtzJobMethod"></property>  
    <property name="cronExpression" value="0/5 * * * * ?"></property>  
</bean>  
  
<!-- ======================== 调度工厂 ======================== -->  
<bean id="SpringJobSchedulerFactoryBean" class="org.springframework.scheduling.quartz.SchedulerFactoryBean">  
    <property name="triggers">  
        <list>  
            <ref bean="CronTriggerBean"/>  
        </list>  
    </property>  
</bean>    
```

## 任务调度的机制
- https://www.cnblogs.com/zhangchengzhangtuo/p/5705672.html

在这里将几个重要的类调用的过程以序列图的形式展现出来，上半部分展现的是启动过程，下半部分展现的是任务调度的过程。

 - 步骤1.用户首先需要生成一个调度器工厂SchedulerFactory，可以用下面的方式实现自己的定制化：
 - 步骤2.然后通过getScheduler()方法从调度器工厂里得到调度器实例，首先查找有没有这样的调度器，没有的话，就生成一个，有的话直接返回。所以得到的一般是单例，即默认的调度器。
 - 步骤3.Scheduler有一个QuartzSchedulerThread（Thread的子类）属性，在scheduler实例化的时候，实例化了一个对象，并用ThreadExecutor启动该线程对象。该线程就是调度线程，主要任务就是不停的从JobStore中获取即将被触发的触发器（默认30s调度一次）。在这个时候调度线程虽然启动，但是处于pause状态。
 - 步骤4.接下来是任务调度的部分：
   client通过scheduleJob()方法将任务和触发器存储在JobStore中，通过start()方法将QuartzSchedulerThread的pause状态设为false，通知调度线程执行任务，此后调度线程不停的从JobStore中去取即将触发的任务。

上半部分展现的是任务执行之前准备工作的时序，下半部分展现的是任务执行的时序。

 - 步骤1.调度线程首先去线程池中获取可用的线程，如果没有的话，就阻塞。
 - 步骤2.从JobStore(从存储介质中获取触发器，存储介质可以是内存也可以是数据库)获取（接下来30s内的）触发器，然后等待该触发器触发。
 - 步骤3.调度线程创建一个JobRunShell(就是一个Runnable)，然后从线程池中调用线程执行该任务。 接下来就是任务执行的时序：
 - 步骤4.获取trigger、JobDetail以及生成Job实例，然后执行job的execute接口函数。

## Mysql优化
主要原则就是应尽量避免全表扫描，应该考虑在where及order by 涉及的列上建立索引。

 - 一个表的索引不是越多越好，也没有一个具体的数字，根据以往的经验，一个表的索引最多不能超过**6个**，因为索引越多，对update和insert操作也会有性能的影响，涉及到索引的新建和重建操作。
 - 建立索引的方法为：
1、多数查询经常使用的列；
2、很少进行修改操作的列；
3、索引需要建立在数据差异化大的列上
 - 对应的sql优化的方法有
 
1、建立复合索引；

2、like语句优化，比如下面的语句，前后都加了%，该查询必然会走全表扫描
```sql
SELECT id FROM A WHERE name like '%abc%'
```
3、在where子句中使用 ！= 或 <>操作符，索引将被放弃使用，会进行全表查询。

4、in和not in 也要慎用，否则也会导致全表扫描。

　　 方案一：between替换in

　　 如SQL:SELECT id FROM A WHERE num in(1,2,3) 优化成：SELECT id FROM A WHERE num between 1 and 3

　　 方案二：exist替换in

　　 如SQL:SELECT id FROM A WHERE num in(select num from b ) 优化成：SELECT num FROM A WHERE num exists(select 1 from B where B.num = A.num)

　　 方案三：left join替换in

　　 如SQL:SELECT id FROM A WHERE num in(select num from B) 优化成：SELECT id FROM A LEFT JOIN B ON A.num = B.num
　　 
5、不要在where子句中的“=”**左边**进行函数、算数运算或其他表达式运算，否则系统将可能无法正确使用索引。

　　 如SQL:SELECT id FROM A WHERE num/2 = 100 优化成：SELECT id FROM A WHERE num = 100*2

　　 如SQL:SELECT id FROM A WHERE substring(name,1,3) = 'abc' 优化成：SELECT id FROM A WHERE LIKE 'abc%'

　　 如SQL:SELECT id FROM A WHERE datediff(day,createdate,'2016-11-30')=0 优化成：SELECT id FROM A WHERE createdate>='2016-11-30' and createdate<'2016-12-1'

　　 如SQL:SELECT id FROM A WHERE year(addate) <2016 优化成：SELECT id FROM A where addate<'2016-01-01'
　　 
6、任何地方都不要用 select * from table ，用具体的字段列表替换"*"，不要返回用不到的字段　

7、使用“临时表”暂存中间结果

8、limit分页优化

mysql的limit函数语法：
```sql
SELECT * FROM table  LIMIT [offset,] rows | rows OFFSET offset
```
当偏移量特别时，limit效率会非常低

　　　　SELECT id FROM A LIMIT 1000,10   很快

　　　　SELECT id FROM A LIMIT 90000,10 很慢

　　　　优化方法：

　　　　方法一：select id from A **order by** id limit 90000,10; 很快，0.04秒就OK。 因为用了id主键做索引当然快

　　　　方法二：select id,title from A where id>=(select id from collect order by id limit 90000,1) limit 10;

     　　 方法三：select id from A order by id  between 10000000 and 10000010;
     　　 
9、尽量不要使用 BY RAND()命令
BY RAND()是随机显示结果，这个函数可能会为表中每一个独立的行执行BY RAND()命令，这个会消耗处理器的处理能力。

10、排序的索引问题　
Mysql查询**只是用一个索引**，因此如果where子句中**已经**使用了索引的话，那么order by中的列是**不会使用索引**的。因此数据库默认排序可以符合要求情况下不要使用排序操作；
尽量不要包含多个列的排序，如果需要最好给这些列**创建复合索引**。

11、尽量用 union add 替换 union
union和union all的差异主要是前者需要将两个（或者多个）结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的cpu运算，加大资源消耗及延迟。所以当我们可以确认不可能出现重复结果集或者不在乎重复结果集的时候，尽量使用union all而不是union

12、Inner join 和 left join、right join、子查询

第一：inner join内连接也叫等值连接是，left/rightjoin是外连接。

　　　　 SELECT A.id,A.name,B.id,B.name FROM A LEFT JOIN B ON A.id =B.id;

　　　　 SELECT A.id,A.name,B.id,B.name FROM A RIGHT JOIN ON B A.id= B.id;

　　　　 SELECT A.id,A.name,B.id,B.name FROM A INNER JOIN ON A.id =B.id;

　　 　　经过来自多方面的证实inner join性能比较快，因为inner join是等值连接，或许返回的行数比较少。但是我们要记得有些语句隐形的用到了等值连接，如：

 　　　　SELECT A.id,A.name,B.id,B.name FROM A,B WHERE A.id = B.id;

 　　　　推荐：能用inner join连接尽量使用inner join连接

　　 第二：**子查询的性能又比外连接性能慢**，尽量用外连接来替换子查询。

　　　　Select* from A where exists (select * from B where id>=3000 and A.uuid=B.uuid);

　　　　A表的数据为十万级表，B表为百万级表，在本机执行差不多用2秒左右，我们可以通过explain可以查看到子查询是一个相关子查询(DEPENDENCE SUBQUERY);Mysql是先对外表A执行全表查询，然后根据uuid逐次执行子查询，如果外层表是一个很大的表，我们可以想象查询性能会表现比这个更加糟糕。

      　　一种简单的优化就是用innerjoin的方法来代替子查询，查询语句改为：

  　　　Select* from A inner join B ON A.uuid=B.uuid using(uuid) where b.uuid>=3000;  这个语句执行测试不到一秒；

　　第三：使用JOIN时候，应该用小的结果驱动大的结果（left join 左边表结果尽量小，如果有条件应该放到左边先处理，right join同理反向），同时尽量把牵涉到多表联合的查询拆分多个query	(多个表查询效率低，容易锁表和阻塞)。如：

	　　Select * from A left join B A.id=B.ref_id where  A.id>10;可以以优化为：
	　　select * from (select * from A wehre id >10) T1 left join B on T1.id=B.ref_id;
	　　
13、应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描
select id from t where num is null 
可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： 
select id from t where num=0 

14、尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。

15、尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 

16、尽量避免大事务操作，提高系统并发能力。



**所以，sql查询不走索引大致可以分为如下几个原因：**

 - 使用了不等号<>作为查询条件
 - 使用了null作为查询的判断条件，形如is null
 - 使用了in作为查询条件（不是绝对的，部分in条件是可以走索引的）
 - 查询条件中的“=”左边进行了运算
 - like查询前都使用了%，形如like '%abc'，但是like 'abc%'还是可以走索引的
 - 使用复合索引时，索引的第一个字段没有作为查询条件
 

### navicat查看mysql执行计划各参数意义

 1. ID：Query Optimizer 所选定的执行计划中查询的序列号；
 2. Select_type：所使用的查询类型，主要有以下这几种查询类型
 
 ◇ DEPENDENT SUBQUERY：子查询中内层的第一个SELECT，依赖于外部查询的结果集；

◇ DEPENDENT UNION：子查询中的UNION，且为UNION 中从第二个SELECT
开始的后面所有SELECT，同样依赖于外部查询的结果集；
◇ PRIMARY：子查询中的最外层查询，注意并不是主键查询；

◇ SIMPLE：除子查询或者UNION 之外的其他查询；

◇ SUBQUERY：子查询内层查询的第一个SELECT，结果不依赖于外部查询结果集；

◇ UNCACHEABLE SUBQUERY：结果集无法缓存的子查询；

◇ UNION：UNION 语句中第二个SELECT 开始的后面所有SELECT，第一个SELECT 为PRIMARY

◇ UNION RESULT：UNION 中的合并结果；

 3. Table：显示这一步所访问的数据库中的表的名称；
 4. Type：告诉我们对表所使用的访问方式，主要包含如下集中类型：
 
 ◇ all：全表扫描

◇ const：读常量，且最多只会有一条记录匹配，由于是常量，所以实际上只需要读一次；

◇ eq_ref：最多只会有一条匹配结果，一般是通过主键或者唯一键索引来访问；

◇ fulltext：

◇ index：全索引扫描；

◇ index_merge：查询中同时使用两个（或更多）索引，然后对索引结果进行merge 之后再读
取表数据；

◇ index_subquery：子查询中的返回结果字段组合是一个索引（或索引组合），但不是一个
主键或者唯一索引；

◇ rang：索引范围扫描；

◇ ref：Join 语句中被驱动表索引引用查询；

◇ ref_or_null：与ref 的唯一区别就是在使用索引引用查询之外再增加一个空值的查询；

◇ system：系统表，表中只有一行数据；

◇ unique_subquery：子查询中的返回结果字段组合是主键或者唯一约束；

 5. Possible_keys：该查询可以利用的索引. 如果没有任何索引可以使用，就会显示成null，这一项内容对于优化时候索引的调整非常重要；
 6. Key：MySQL Query Optimizer 从possible_keys 中所选择使用的索引（**注意**，mysql默认一次查询只会走一个索引）；
 7. Key_len：被选中使用索引的索引键长度；
 8. Ref：列出是通过常量（const），还是某个表的某个字段（如果是join）来过滤（通过key）的；
 9. Rows：MySQL Query Optimizer 通过系统收集到的统计信息估算出来的结果集记录条数；
 10. Extra：查询中每一步实现的额外细节信息，主要可能会是以下内容：
 
 ◇ Distinct：查找distinct 值，所以当mysql 找到了第一条匹配的结果后，将停止该值的查询而转为后面其他值的查询；
◇ Full scan on NULL key：子查询中的一种优化方式，主要在遇到无法通过索引访问null
值的使用使用；

◇ Impossible WHERE noticed after reading const tables：MySQL Query Optimizer 通过收集到的统计信息判断出不可能存在结果；

◇ No tables：Query 语句中使用FROM DUAL 或者不包含任何FROM 子句；

◇ Not exists：在某些左连接中MySQL Query Optimizer 所通过改变原有Query 的组成而使用的优化方法，可以部分减少数据访问次数；

◇ Range checked for each record (index map: N)：通过MySQL 官方手册的描述，当MySQL Query Optimizer没有发现好的可以使用的索引的时候，如果发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL 检查是否可以使用range 或index_merge 访问方法来索取行。

◇ Select tables optimized away：当我们使用某些聚合函数来访问存在索引的某个字段的
时候，MySQL Query Optimizer会通过索引而直接一次定位到所需的数据行完成整个查询。当然，前提是在Query 中不能有GROUP BY 操作。如使用MIN()或者MAX（）的时候；

◇ Using filesort：当我们的Query 中包含ORDER BY操作，而且无法利用索引完成排序操作的时候，MySQL Query Optimizer 不得不选择相应的排序算法来实现。

◇ Using index：所需要的数据只需要在Index即可全部获得而不需要再到表中取数据；

◇ Using index for group-by：数据访问和Using index一样，所需数据只需要读取索引即可，而当Query 中使用了GROUP BY 或者DISTINCT 子句的时候，如果分组字段也在索引中，Extra 中的信息就会是Using index for group-by；

◇ Using temporary：当MySQL在某些操作中必须使用临时表的时候，在Extra 信息中就会出现Using temporary 。主要常见于GROUP BY 和ORDER BY等操作中。

◇ Using where：如果我们不是读取表的所有数据，或者不是仅仅通过索引就可以获取所有需要的数据，则会出现Using where 信息；

◇ Using where with pushed condition：这是一个仅仅在NDBCluster 存储引擎中才会出现的信息，而且还需要通过打开Condition Pushdown 优化功能才可能会被使用。控制参数为engine_condition_pushdown 。
 

## 数据库事务

### 四个基本要素

基本要素：包含：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）

#### 原子性

整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。

#### 一致性

以转账案例为例，假设有五个账户，每个账户余额是100元，那么五个账户总额是500元，如果在这个5个账户之间同时发生多个转账，无论并发多少个，比如在A与B账户之间转账5元，在C与D账户之间转账10元，在B与E之间转账15元，五个账户总额也应该还是500元，这就是保护性和不变性

#### 隔离性

事物相互之间不产生影响。

#### 持久性

在事务完成commit以后，该事务对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。

### 数据库事务等级
- http://blog.csdn.net/a1324204785/article/details/53156414

数据库事物有4个等级，由低到高，分别是：
Read uncommitted、Read committed、Repeatable read、Serializable、MVCC（这个好像不常用），这五个级别可以逐个解决脏读、不可重复读、幻读这几类问题。

#### Read uncommitted（读未提交，存在脏读）
 例子：错发工资，空欢喜
         小明 辛苦搬砖一个月，领导给他账户存4000，此时领导发工资事物未提交，但小明查看工资发现账户多了4000，满心欢喜，不幸的是领导发现工资算错了，回滚事务，修改金额2000，提交事务。最终小明工资只有2000，空欢喜一场。

**总结**：此例子中，发生了**脏读**。即A事物修改，未提交，B事物先读到，A事物再修改提交。

#### Read committed（读已提交，存在不可重复读）

例子:还是小明小华销售员，余票3张，A来小华那里请求3张订票单，小华接受订单，要卖出3张票，上面的销售步骤执行中的时候，B也来小明那里买票，由于小华的销售事务执行到一半，小明事务没有看到小华的事务执行，读到的票数是3，准备接受订单的时候，小华的销售事务完成了，此时小明的系统变成显示0张票，小明刚想按下鼠标点击接受订单的手又连忙缩了回去。

**总结**：此例子中，发生了**不可重复读**。即事物A查询，事物B修改并提交，事物A读发现修改了。

**oracle默认**系统事务隔离级别是READ COMMITTED,也就是读已提交。

#### Repeatable read （可重复读，存在幻读）
 
例子：事务A执行一条`update table_name set name ==‘fff’ where id = 100`的语句，此时实际上并不存在`id=100`的数据。然后事务B插入一条`id=100`的数据，并且commit。此时，事务A再次执行`update table_name set name ==‘fff’ where id = 100`语句发送成功了（返回了受影响的行数为1），这就是所谓的`幻读`。

**mysql默认**使用的就是就是这个隔离级别，使用`select @@tx_isolation;`命令可以进行查询

注意:Repeatable read隔离级别下，有一个读进程，一个写进程，同时操作同一条数据，他们是不是不会互相阻塞的。也就是说，mysql的读写是不互斥的（innodb引擎），底层实现原理是MVCC。

#### Serializable（序列化，性能低）
 串行化事物，避免脏读、不可重复读、幻读，但是性能花费太高。

## MVCC（Multi-Version Concurrency Control 多版本并发控制 ）

在Java concurrent包中，有copyonwrite系列的类，专门用于优化读远大于写的情况。而其优化的手段就是，在进行写操作时，将数据copy一份，不会影响原有数据，然后进行修改，修改完成后原子替换掉旧的数据，而读操作只会读取原有数据。通过这种方式实现写操作不会阻塞读操作，从而优化读效率。而写操作之间是要互斥的，并且每次写操作都会有一次copy，所以只适合读大于写的情况。

MVCC的原理与copyonwrite类似，全称是Multi-Version Concurrent Control，即多版本并发控制。在MVCC协议下，每个读操作会看到一个一致性的snapshot，并且可以实现非阻塞的读。MVCC允许数据具有多个版本，这个版本可以是时间戳或者是全局递增的事务ID，在同一个时间点，不同的事务看到的数据是不同的。
现在来看看MySQL数据库为我们提供的四种隔离级别：

　　① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。

　　② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。

　　③ Read committed (读已提交)：可避免脏读的发生。

　　④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。
整理成表格的形式就是：
		 
| ...        | 脏读   |  不可重复读  |幻读|
| --------   | :-----:  | :----:  |:----:|
| Read uncommitted     | √ |   √     |√|√|
| Read committed        |      |   √   |√|
| Repeatable read        |        |    |√|
| Serializable        |        |    ||

### Spring事务的传播特性和隔离级别
**事务的几种传播特性**
1. PROPAGATION_REQUIRED: 如果存在一个事务，则支持当前事务，如果没有事务则开启，这是spring默认的传播属性
2. PROPAGATION_SUPPORTS: 如果存在一个事务，支持当前事务。如果没有事务，则非事务的执行
3. PROPAGATION_MANDATORY: 如果已经存在一个事务，支持当前事务。如果没有一个活动的事务，则抛出异常。
4. PROPAGATION_REQUIRES_NEW: 总是开启一个新的事务。如果一个事务已经存在，则将这个存在的事务挂起。
5. PROPAGATION_NOT_SUPPORTED: 总是非事务地执行，并挂起任何存在的事务。
6. PROPAGATION_NEVER: 总是非事务地执行，如果存在一个活动事务，则抛出异常
7. PROPAGATION_NESTED：如果一个活动的事务存在，则运行在一个嵌套的事务中. 如果没有活动事务,则按TransactionDefinition.PROPAGATION_REQUIRED属性执行


**Spring事务的隔离级别**
1. ISOLATION_DEFAULT： 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别.

下面的2\3\4\5与JDBC的隔离级别相对应

2. ISOLATION_READ_UNCOMMITTED： 这是事务最低的隔离级别，它充许另外一个事务可以看到这个事务未提交的数据。
      这种隔离级别会产生脏读，不可重复读和幻像读。
3. ISOLATION_READ_COMMITTED： 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据
4. ISOLATION_REPEATABLE_READ： 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。
      它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免下面的情况产生(不可重复读)。
5. ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。
      除了防止脏读，不可重复读外，还避免了幻像读。 

## Servlet的作用，生命周期，如何创建、配置Servlet
**servlet是什么**

servlet是一个基于java技术的WEB组件，运行在服务器端，我们利用 sevlet可以很轻松的扩展WEB服务器的功能，使它满足特定的应用需要。servlet由servlet容器管理，servlet容器也叫servlet引擎，是servlet的运行环境，给发送的请求和响应之上提供网络服务

**Servlet的生命周期**

servlet的生命周期是指：servlet由创建到销毁的过程。

生命周期涉及几个方法：构造器，init，service，destroy。servlet在请求时创建

构造器方法：只在第一次访问时调用一次，说明servlet是单例的。

init方法：只会在第一次访问servlet时调用一次，对servlet对象进行初始化。

service方法：每次访问时都调用一次，业务逻辑写在这个方法里。

destroy方法：在项目卸载的时候调用一次，即关闭服务器的时候调用一次。

## 常用设计模式
- http://blog.csdn.net/xsl1990/article/details/16359289

创建型模式主要有简单工厂模式（并不是23种设计模式之一）、**工厂方法**、抽象工厂模式、**单例模式**、生成器模式和原型模式。

结构型模式主要有**适配器模式adapter**、**桥接模式bridge**、组合器模式component、装饰器模式decorator、门面模式、亨元模式flyweight和**代理模式proxy**。

行为型模式主要有**命令模式command**、解释器模式、**迭代器模式**、中介者模式、备忘录模式、**观察者模式**、状态模式state、策略模式、模板模式和**访问者模式**。

### 单例模式
 单例模式。构造函数是私有的，通过一个共有的成员函数还调用这个构造函数，在多线程环境下，还需要对这个成员函数进行加锁。
下面是4种单例的创建方式，最安全也最好的是第4种，使用内部类的方式
```java
// 1、懒汉式单例，线程不安全的
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
  
    public static Singleton getInstance() {  
    if (instance == null) {  
        instance = new Singleton();  
    }  
    return instance;  
    }  
}  

// 2、懒汉式单例，线程安全的，这种写法能够在多线程中很好的工作，而且看起来它也具备很好的lazy loading，但是，遗憾的是，效率很低，99%情况下不需要同步。
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
    public static synchronized Singleton getInstance() {  
    if (instance == null) {  
        instance = new Singleton();  
    }  
    return instance;  
    }  
}  

// 3、饿汉式，线程安全，但不能保证是懒加载的模式
// 这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用getInstance方法会导致类加载，此时就是lazy loading。 
//但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到lazy loading的效果。
public class Singleton {  
    private static Singleton instance = new Singleton();  
    private Singleton (){}  
    public static Singleton getInstance() {  
    return instance;  
    }  
} 

//4、静态内部类方式
//这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程，它跟第三种方式不同的是（很细微的差别）：第三种方式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果）。
//而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显式装载SingletonHolder类，从而实例化instance。
//想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比第三种方式就显得很合理。
public class Singleton
{
	// 私有的  静态的 
	private static class SingletonHolder
	{
		// 私有的 静态的  final类型的
		private static final Singleton INSTANCE = new Singleton();
	}

	private Singleton()
	{
	}

	public static final Singleton getInstance()
	{
		// 返回内部类的静态属性
		return SingletonHolder.INSTANCE;
	}
}
```
### 工厂方法
调用和被调用者之间不产生直接的以来关系，而是由工厂来负责对象的创建，一般是在工厂的方法中调用类的构造函数，单个或者批量的创建对象。

### 代理模式(Proxy)
代理模式是一种应用非常广泛的设计模式，当客户端代码需要调用某个对象时，客户端实际上不关心是否准确得到该对象，它只要一个能提供该功能的对象即可，此时我们就可返回该对象的代理（Proxy）。

代理就是一个Java对象代表另一个Java对象来采取行动。示例代码如下：
```java
public class ImageProxy implements Image
{
    //组合一个image实例，作为被代理的对象
    private Image image;
    //使用抽象实体来初始化代理对象
    public ImageProxy(Image image)
    {
       this.image = image;
    }
    /**
     * 重写Image接口的show()方法
     * 该方法用于控制对被代理对象的访问，
     * 并根据需要负责创建和删除被代理对象
     */
    public void show()
    {
       //只有当真正需要调用image的show方法时才创建被代理对象
       if (image == null)
       {
           image = new BigImage();
       }
       image.show();
    }
}

// 调用的时候，这么调用
Image image = new ImageProxy(null);
```

### 命令模式(Command)
某个方法需要完成某一个功能，完成这个功能的大部分步骤已经确定了，但可能有少量具体步骤无法确定，必须等到执行该方法时才可以确定。（在某些编程语言如Ruby、Perl里，允许传入一个代码块作为参数。但Java暂时还不支持代码块作为参数）。在Java中，传入该方法的是一个对象，该对象通常是某个接口的匿名实现类的实例，该接口通常被称为命令接口，这种设计方式也被称为命令模式。

下面是源代码：
```java
// Command接口
public interface Command
{
    //接口里定义的process方法用于封装“处理行为”
    void process(int[] target);
}

// ProcessArray

public class ProcessArray
{
    //定义一个each()方法，用于处理数组，
    public void each(int[] target , Command cmd)
    {
       cmd.process(target);
    }
}

// TestCommand 测试
public class TestCommand
{
    public static void main(String[] args)
    {
       ProcessArray pa = new ProcessArray();
       int[] target = {3, -4, 6, 4};
       //第一次处理数组，具体处理行为取决于Command对象
       pa.each(target , new Command()
       {
           //重写process()方法，决定具体的处理行为
           public void process(int[] target)
           {
              for (int tmp : target )
              {
                  System.out.println("迭代输出目标数组的元素:" + tmp);
              }
           }
       });
       System.out.println("------------------");
       //第二次处理数组，具体处理行为取决于Command对象
       pa.each(target , new Command()
       {
           //重写process方法，决定具体的处理行为
           public void process(int[] target)
           {
              int sum = 0;
              for (int tmp : target )
              {
                  sum += tmp;         
              }
              System.out.println("数组元素的总和是:" + sum);
           }
       });
    }
}
```
### 策略模式(Strategy)

策略模式用于封装系列的算法，这些算法通常被封装在一个被称为Context的类中，客户端程序可以自由选择其中一种算法，或让Context为客户端选择一种最佳算法——使用策略模式的优势是为了支持算法的自由切换。

### 门面模式(Facade)
 
 将多个类的方法进行封装，对于一些固定的操作，封装成一个方法来执行。
 
### 桥接模式(Bridge)
 
由于实际的需要，某个类具有两个以上的维度变化，如果只是使用继承将无法实现这种需要，或者使得设计变得相当臃肿。而桥接模式的做法是把变化部分抽象出来，使变化部分与主类分离开来，从而将多个的变化彻底分离。最后提供一个管理类来组合不同维度上的变化，通过这种组合来满足业务的需要。

### 观察者模式(Observer)

观察者模式定义了对象间的一对多依赖关系，让一个或多个观察者对象观察一个主题对象。当主题对象的状态发生变化时，系统能通知所有的依赖于此对象的观察者对象，从而使得观察者对象能够自动更新。

## I/O中涉及到的设计模式
 - Java的I/O库总体设计是符合**装饰者模式**（Decorator）跟**适配器模式**（Adapter）的。
 
### 装饰者模式
在由 InputStream，OutputStream，Reader和Writer代表的等级结构内部，有一些流处理器可以对另一些流处理器起到装饰作用，形成新的，具有改善了的功能的流处理器，比如bufferedxxxStream。装饰者模式是Java I/O库的整体设计模式。这样的一个原则是符合装饰者模式的。 

### 适配器模式
Reader和Writer代表的等级结构内部，实现了**字节流到字符流**的转换，比如InputStreamReader，实现了字节流到字符流的转换。这就是适配器模式的应用。
　　
　　（需要注意的是，**不能**将字符流转换为字节流）
　　

## 浅析classloader

jvm的classloader顾名思义就是负责将*.clas文件读取jvm内存，然后由jvm将读入的二进制数据转换为对象的一个工具。

### classloader

classloader位于rt.jar文件的java.lang路径下，它有几个核心的方法如下：
```java
 /**
     * Loads the class with the specified <a href="#name">binary name</a>.
     * This method searches for classes in the same manner as the {@link
     * #loadClass(String, boolean)} method.  It is invoked by the Java virtual
     * machine to resolve class references.  Invoking this method is equivalent
     * to invoking {@link #loadClass(String, boolean) <tt>loadClass(name,
     * false)</tt>}.
     *
     * @param  name
     *         The <a href="#name">binary name</a> of the class
     *
     * @return  The resulting <tt>Class</tt> object
     *
     * @throws  ClassNotFoundException
     *          If the class was not found
     */
    public Class<?> loadClass(String name) throws ClassNotFoundException {
        return loadClass(name, false);
    }
```
```java
    /**
     * Links the specified class.  This (misleadingly named) method may be
     * used by a class loader to link a class.  If the class <tt>c</tt> has
     * already been linked, then this method simply returns. Otherwise, the
     * class is linked as described in the "Execution" chapter of
     * <cite>The Java&trade; Language Specification</cite>.
     *
     * @param  c
     *         The class to link
     *
     * @throws  NullPointerException
     *          If <tt>c</tt> is <tt>null</tt>.
     *
     * @see  #defineClass(String, byte[], int, int)
     */
    protected final void resolveClass(Class<?> c) {
        resolveClass0(c);
    }
```

方法的具体实现后续再讨论。

ClassLoader可以分为：
![此处输入图片的描述][2]

### 自定义classloader

如果要自定义一个classloader要如何实现呢？

如果要自定义classloader，需要重点关注两个方法findClass和defineClass：
```java
    /**
     * Finds the class with the specified <a href="#name">binary name</a>.
     * This method should be overridden by class loader implementations that
     * follow the delegation model for loading classes, and will be invoked by
     * the {@link #loadClass <tt>loadClass</tt>} method after checking the
     * parent class loader for the requested class.  The default implementation
     * throws a <tt>ClassNotFoundException</tt>.
     *
     * @param  name
     *         The <a href="#name">binary name</a> of the class
     *
     * @return  The resulting <tt>Class</tt> object
     *
     * @throws  ClassNotFoundException
     *          If the class could not be found
     *
     * @since  1.2
     */
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
    }
```
```java
    /**
     * Converts an array of bytes into an instance of class <tt>Class</tt>.
     * Before the <tt>Class</tt> can be used it must be resolved.
     *
     * <p> This method assigns a default {@link java.security.ProtectionDomain
     * <tt>ProtectionDomain</tt>} to the newly defined class.  The
     * <tt>ProtectionDomain</tt> is effectively granted the same set of
     * permissions returned when {@link
     * java.security.Policy#getPermissions(java.security.CodeSource)
     * <tt>Policy.getPolicy().getPermissions(new CodeSource(null, null))</tt>}
     * is invoked.  The default domain is created on the first invocation of
     * {@link #defineClass(String, byte[], int, int) <tt>defineClass</tt>},
     * and re-used on subsequent invocations.
     *
     * <p> To assign a specific <tt>ProtectionDomain</tt> to the class, use
     * the {@link #defineClass(String, byte[], int, int,
     * java.security.ProtectionDomain) <tt>defineClass</tt>} method that takes a
     * <tt>ProtectionDomain</tt> as one of its arguments.  </p>
     *
     * @param  name
     *         The expected <a href="#name">binary name</a> of the class, or
     *         <tt>null</tt> if not known
     *
     * @param  b
     *         The bytes that make up the class data.  The bytes in positions
     *         <tt>off</tt> through <tt>off+len-1</tt> should have the format
     *         of a valid class file as defined by
     *         <cite>The Java&trade; Virtual Machine Specification</cite>.
     *
     * @param  off
     *         The start offset in <tt>b</tt> of the class data
     *
     * @param  len
     *         The length of the class data
     *
     * @return  The <tt>Class</tt> object that was created from the specified
     *          class data.
     *
     * @throws  ClassFormatError
     *          If the data did not contain a valid class
     *
     * @throws  IndexOutOfBoundsException
     *          If either <tt>off</tt> or <tt>len</tt> is negative, or if
     *          <tt>off+len</tt> is greater than <tt>b.length</tt>.
     *
     * @throws  SecurityException
     *          If an attempt is made to add this class to a package that
     *          contains classes that were signed by a different set of
     *          certificates than this class (which is unsigned), or if
     *          <tt>name</tt> begins with "<tt>java.</tt>".
     *
     * @see  #loadClass(String, boolean)
     * @see  #resolveClass(Class)
     * @see  java.security.CodeSource
     * @see  java.security.SecureClassLoader
     *
     * @since  1.1
     */
    protected final Class<?> defineClass(String name, byte[] b, int off, int len)
        throws ClassFormatError
    {
        return defineClass(name, b, off, len, null);
    }
```
自定义的classloader需要**重写**上面的findClass方法，defineClass默认已经实现好，无需我们自己去实现：
```java
package com.interview.javabasic.reflect;

import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.InputStream;

public class MyClassLoader extends ClassLoader {
    private String path;
    private String classLoaderName;

    public MyClassLoader(String path, String classLoaderName) {
        this.path = path;
        this.classLoaderName = classLoaderName;
    }

    //用于寻找类文件
    @Override
    public Class findClass(String name) {
        byte[] b = loadClassData(name);
        return defineClass(name, b, 0, b.length);
    }

    //用于加载类文件
    private byte[] loadClassData(String name) {
        name = path + name + ".class";
        InputStream in = null;
        ByteArrayOutputStream out = null;
        try {
            in = new FileInputStream(new File(name));
            out = new ByteArrayOutputStream();
            int i = 0;
            while ((i = in.read()) != -1) {
                out.write(i);
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            try {
                out.close();
                in.close();
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
        return out.toByteArray();
    }
}
```

为了测试上面的classloader是否有效，执行下面的测试代码(其实就是加载一个指定路径的java文件)：
```java
package com.interview.javabasic.reflect;

public class ClassLoaderChecker {
    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException {
        MyClassLoader m = new MyClassLoader("/Users/baidu/Desktop/", "myClassLoader");
        Class c = m.loadClass("Wali");
        System.out.println(c.getClassLoader());
        System.out.println(c.getClassLoader().getParent());
        System.out.println(c.getClassLoader().getParent().getParent());
        System.out.println(c.getClassLoader().getParent().getParent().getParent());
        c.newInstance();
    }
}
```

### 自定义classloader实际用途

自定义类加载器可以完成的事情还是比较多，例如解决类冲突问题，实现热加载以及热部署，甚至可以实现jar包的加密保护。具体可以参考[这里](https://www.zhihu.com/question/46719811)。

### classloader的双亲委派机制
classloader的双亲委派机制如下图所示：

![此处输入图片的描述][3]

总结起来，就是自底向上查找类释放加载过，自顶向下尝试加载类。

我们分析一下loadclass的源码实现，源码注释其实已经将loadClass的过程写的很清楚，首先会看类是否已经加载，然后调用父类尝试进行加载类（递归的过程），加载个过程中还会使用synchronized关键字进行加锁防止类被多次加载：
```java
    /**
     * Loads the class with the specified <a href="#name">binary name</a>.  The
     * default implementation of this method searches for classes in the
     * following order:
     *
     * <ol>
     *
     *   <li><p> Invoke {@link #findLoadedClass(String)} to check if the class
     *   has already been loaded.  </p></li>
     *
     *   <li><p> Invoke the {@link #loadClass(String) <tt>loadClass</tt>} method
     *   on the parent class loader.  If the parent is <tt>null</tt> the class
     *   loader built-in to the virtual machine is used, instead.  </p></li>
     *
     *   <li><p> Invoke the {@link #findClass(String)} method to find the
     *   class.  </p></li>
     *
     * </ol>
     *
     * <p> If the class was found using the above steps, and the
     * <tt>resolve</tt> flag is true, this method will then invoke the {@link
     * #resolveClass(Class)} method on the resulting <tt>Class</tt> object.
     *
     * <p> Subclasses of <tt>ClassLoader</tt> are encouraged to override {@link
     * #findClass(String)}, rather than this method.  </p>
     *
     * <p> Unless overridden, this method synchronizes on the result of
     * {@link #getClassLoadingLock <tt>getClassLoadingLock</tt>} method
     * during the entire class loading process.
     *
     * @param  name
     *         The <a href="#name">binary name</a> of the class
     *
     * @param  resolve
     *         If <tt>true</tt> then resolve the class
     *
     * @return  The resulting <tt>Class</tt> object
     *
     * @throws  ClassNotFoundException
     *          If the class could not be found
     */
    protected Class<?> loadClass(String name, boolean resolve)
        throws ClassNotFoundException
    {
        // 加锁，避免多个线层同时进行同个类的加载工作
        synchronized (getClassLoadingLock(name)) {
            // First, check if the class has already been loaded
            Class<?> c = findLoadedClass(name);
            if (c == null) {
                long t0 = System.nanoTime();
                try {
                    // 这里体现的就是「自顶向下」尝试加载类的过程
                    if (parent != null) {
                        // 尝试调用父classloader进行类的加载
                        c = parent.loadClass(name, false);
                    } else {
                        // 尝试使用BootstrapClassLoader加载类
                        c = findBootstrapClassOrNull(name);
                    }
                } catch (ClassNotFoundException e) {
                    // ClassNotFoundException thrown if class not found
                    // from the non-null parent class loader
                }

                if (c == null) {
                    // If still not found, then invoke findClass in order
                    // to find the class.
                    long t1 = System.nanoTime();
                    // 注意如果我们没有自己实现这个方法，那么直接就会抛出ClassNotFoundException
                    c = findClass(name);

                    // this is the defining class loader; record the stats
                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                    sun.misc.PerfCounter.getFindClasses().increment();
                }
            }
            if (resolve) {
                resolveClass(c);
            }
            return c;
        }
    }
```

注意一下上面代码中的findClass方法：
```java
    /**
     * Finds the class with the specified <a href="#name">binary name</a>.
     * This method should be overridden by class loader implementations that
     * follow the delegation model for loading classes, and will be invoked by
     * the {@link #loadClass <tt>loadClass</tt>} method after checking the
     * parent class loader for the requested class.  The default implementation
     * throws a <tt>ClassNotFoundException</tt>.
     *
     * @param  name
     *         The <a href="#name">binary name</a> of the class
     *
     * @return  The resulting <tt>Class</tt> object
     *
     * @throws  ClassNotFoundException
     *          If the class could not be found
     *
     * @since  1.2
     */
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        throw new ClassNotFoundException(name);
    }
```
可以看到，它原生其实没有任何实现，直接抛出了异常。这也是我们上面实现自定义的classloader的必须要重写的一个方法，否则会抛出异常。

上面的findLoadedClass方法其实也是一个native方法，源码如下:
```java
    /**
     * Returns the class with the given <a href="#name">binary name</a> if this
     * loader has been recorded by the Java virtual machine as an initiating
     * loader of a class with that <a href="#name">binary name</a>.  Otherwise
     * <tt>null</tt> is returned.
     *
     * @param  name
     *         The <a href="#name">binary name</a> of the class
     *
     * @return  The <tt>Class</tt> object, or <tt>null</tt> if the class has
     *          not been loaded
     *
     * @since  1.1
     */
    protected final Class<?> findLoadedClass(String name) {
        if (!checkName(name))
            return null;
        return findLoadedClass0(name);
    }

    private native final Class<?> findLoadedClass0(String name);
```
native方法我们怎么去看它的实现呢？以查看findLoadedClass0方法为例，可以在   [http://hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/b860bcc84d51/src/share/native/java/lang/ClassLoader.c][4]   中搜索：JVM_FindLoadedClass即可看到。

### 为什么需要双亲委派机制

- https://www.cnblogs.com/silyvin/p/12166078.html

一句话，为了安全。避免用户写一些与jdk同名的类，覆盖了jdk的行为。比如，你写了一个类叫`java.lang.Object`，如果是双亲委派，jvm会优先加载jdk自己的`Object`对象，否则尽可能出现奇奇怪怪的问题。


## 类的初始化过程
- http://blog.csdn.net/zjl477595675/article/details/48101611

类的初始化和对象初始化是两个不同的概念。

**类的初始化**是发生在类加载过程，是类加载过程的一个阶段，该阶段并不调用类的构造器。

**对象的初始化**是在类加载完成后为对象分配内存，实例变量的初始化，实例变量的赋值及调用类构造器完成对象的初始化过程。

### 类的初始化
 
 分为类的加载——>链接——>**类初始化**
 
 可以参考[下图](https://www.zhihu.com/question/46719811)：
 
 ![class_load](./image/2018/class_load.jpg)

#### 类的加载

类加载发生在以下几种情况： 

1）new生成新的对象实例。 

2）使用java.lang.reflect包的方法对类进行发射调用时。 

3）当子类进行加载或初始化时。当加载一个类时，如果发现其存在父类并且未被加载则会继续加载父类。（**注意**：接口的加载过程与类的加载过程稍有不同。接口中不能使用static{}块。当一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有真正在使用到父接口时（例如引用接口中定义的常量）才会初始化。） 

4）虚拟机启动时，用户指定的执行主类（包含main()的执行入口类），虚拟机会加载加载该类。 

5）调用类变量（静态字段但非静态常量），类方法

注意： 

1. 调用类的静态字段，只有直接定义这个字段的类才会被加载和初始化。通过其子类来引用父类中定义的字段，只会触发父类的初始化而不会触发子类的初始化。 

2. 调用类的静态常量是不触发类的加载过程。如果在A类中调用B类的静态常量，那么在编译阶段会将该静态常量放到A的Class文件的静态常量池中，所以对该常量的调用不涉及B的加载。

```java
 class SuperClass{
    static{
        System.out.println("SuperClass 类初始化");
    }
    static int a=3;
    static final int b=4;
}
class SubClass extends SuperClass{
    static{
        System.out.println("SubClass 类初始化");
    }
}
public class Test {
    public static void main(String[] args) {
        System.out.println(SubClass.a);
    }
}
```
结果是：
```java
SuperClass 类初始化
3
```
如果Test这么写：
```java
public class Test
{
	public static void main(String[] args)
	{
//		System.out.println(SubClass.a);
		System.out.println(SubClass.b);
	}
}
```
那么输出结如下，两个类都没有进行初始化，因为此时b是类常量。
```java
4
```
类加载主要完成如下三件事情：

加载阶段虚拟机主要完成以下三件事： 

1）根据类的路径，定位并获取类的class文件 

2）通过加载器加载class文件，并将class文件里所代表的静态存储结构转化为方法区的运行数据结构 

3）在java堆中生成一个代表这个类的java.lang.Class对象，作为方法区这些数据的访问入口。

#### 类的链接

链接又可以细分为验证——>准备——>解析

 - 验证阶段：

确保Class文件的字节流包含的信息符合当前虚拟机的要求，并不会危害虚拟机自身安全。该阶段包括四个部分：

1.文件格式验证：验证字节流是否符合Class文件格式的规范 

2.元数据验证：对字节码描述的信息进行语义分析，以确保其描述的信息符合java语言规范要求 

3.字节码验证：进行数据流和控制流分析，保证校验类的方法在运行时不会做出危害虚拟机安全的行为。 

4.符号引用验证：在虚拟机中将符号引用转换为直接引用

 - 准备阶段

正式为**类变量**分配内存并设置类变量的默认值，这些内存在**方法区**中进行分配。内存分配仅针对类变量（static变量），不包括实例变量，实例变量是在对象实例化时和对象一起在堆中分配内存。 

类变量的默认值的设置和为了保证变量使用的安全性在对象实例化过程中虚拟机自动地对实例变量进行设置默认值是一样的。默认值的设置如下：
```java
/*数据类型		默认值
	int			0
	long		0L
	char		‘\u0000’
	byte		(byte)0
	boolean		false
	float		0.0f
	double		0.0d
	reference	null*/
```
 - 解析阶段
 
 将常量池内的符号引用替换为直接引用的过程，比如现在调研方法hello()，这个方法的地址是123456，那么hello就是符号引用，123456就是直接引用。
 
### 类初始化

https://blog.csdn.net/ns_code/article/details/17881581

初始化是类加载过程的最后一步，到了此阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，类变量已经被赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序指定的主观计划去初始化类变量和其他资源，或者可以从另一个角度来表达：初始化阶段是执行类构造器`< clinit >()`方法的过程。

这里简单说明下`< clinit >（）`方法的执行规则:

1、`< clinit>（）`方法是由编译器**自动**收集类中的所有类变量的赋值动作和静态语句块中的语句**合并产生**的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句中可以赋值，但是不能访问。

2、`< clinit>（）`方法与**实例构造器**`< init>（）`方法（类的构造函数）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的`< clinit>（）`方法执行之前，父类的`< clinit>（）`方法已经执行完毕。因此，在虚拟机中第一个被执行的`< clinit>（）`方法的类肯定是`java.lang.Object`。

3、`< clinit>（）`方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对类变量的赋值操作，那么编译器可以不为这个类生成`< clinit>（）`方法。

4、接口中不能使用静态语句块，但仍然有类变量（final static）初始化的赋值操作，因此接口与类一样会生成`< clinit>（）`方法。但是接口与类不同的是：执行接口的`< clinit>（）`方法不需要先执行父接口的`< clinit>（）`方法，只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的`< clinit>（）`方法。

5、虚拟机会保证一个类的`< clinit>（）`方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的`< clinit>（）`方法，其他线程都需要阻塞等待，直到活动线程执行`< clinit>（）`方法完毕。如果在一个类的`< clinit>（）`方法中有耗时很长的操作，那就可能造成多个线程阻塞，在实际应用中这种阻塞往往是很隐蔽的。

## ClassLoader的loadClass和Class.forName的区别
加载一个类，使用new关键字隐式的加载类之外，还可以使用loadClass和forName进行显示的加载。那么二者有什么区别呢？

首先，loadClass方法属于抽象类ClassLoader，而forName方法属于Class类。然后就是实现上的区别。

我们直接看一下源码，首先是loadClass：
```java
    /**
     * Loads the class with the specified <a href="#name">binary name</a>.
     * This method searches for classes in the same manner as the {@link
     * #loadClass(String, boolean)} method.  It is invoked by the Java virtual
     * machine to resolve class references.  Invoking this method is equivalent
     * to invoking {@link #loadClass(String, boolean) <tt>loadClass(name,
     * false)</tt>}.
     *
     * @param  name
     *         The <a href="#name">binary name</a> of the class
     *
     * @return  The resulting <tt>Class</tt> object
     *
     * @throws  ClassNotFoundException
     *          If the class was not found
     */
    public Class<?> loadClass(String name) throws ClassNotFoundException {
        return loadClass(name, false);
    }
```
注意其中的false参数，表示的不进行链接。它其实控制的是是否执行下面的这个方法，从源码注释 Links the specified class，我们可以看出这个方法确实是控制类的链接阶段：
```java
    /**
     * Links the specified class.  This (misleadingly named) method may be
     * used by a class loader to link a class.  If the class <tt>c</tt> has
     * already been linked, then this method simply returns. Otherwise, the
     * class is linked as described in the "Execution" chapter of
     * <cite>The Java&trade; Language Specification</cite>.
     *
     * @param  c
     *         The class to link
     *
     * @throws  NullPointerException
     *          If <tt>c</tt> is <tt>null</tt>.
     *
     * @see  #defineClass(String, byte[], int, int)
     */
    protected final void resolveClass(Class<?> c) {
        resolveClass0(c);
    }
```
综上，loadClass只是执行类的加载，并没有后续的链接、初始化阶段。下面再看看forName：
```java
    /**
     * Returns the {@code Class} object associated with the class or
     * interface with the given string name.  Invoking this method is
     * equivalent to:
     *
     * <blockquote>
     *  {@code Class.forName(className, true, currentLoader)}
     * </blockquote>
     *
     * where {@code currentLoader} denotes the defining class loader of
     * the current class.
     *
     * <p> For example, the following code fragment returns the
     * runtime {@code Class} descriptor for the class named
     * {@code java.lang.Thread}:
     *
     * <blockquote>
     *   {@code Class t = Class.forName("java.lang.Thread")}
     * </blockquote>
     * <p>
     * A call to {@code forName("X")} causes the class named
     * {@code X} to be initialized.
     *
     * @param      className   the fully qualified name of the desired class.
     * @return     the {@code Class} object for the class with the
     *             specified name.
     * @exception LinkageError if the linkage fails
     * @exception ExceptionInInitializerError if the initialization provoked
     *            by this method fails
     * @exception ClassNotFoundException if the class cannot be located
     */
    @CallerSensitive
    public static Class<?> forName(String className)
                throws ClassNotFoundException {
        Class<?> caller = Reflection.getCallerClass();
        return forName0(className, true, ClassLoader.getClassLoader(caller), caller);
    }
```
注意forName0方法的true参数，它其实控制的是是否对类进行初始化。

为了验证这一点，我们可以实际写一段代码验证一下二者的区别：

首先编写一个测试类，带有static方法，如果类进行初始化，那么static方法就会被执行：
```java
package com.interview.javabasic.reflect;

public class Robot {
    private String name;
    public void sayHi(String helloSentence){
        System.out.println(helloSentence + " " + name);
    }
    private String throwHello(String tag){
        return "Hello " + tag;
    }
    static {
        System.out.println("Hello Robot");
    }
}
```
main方法：
```java
package com.interview.javabasic.reflect;

public class LoadDifference {
    public static void main(String[] args) throws ClassNotFoundException {
        ClassLoader cl = Robot.class.getClassLoader();
//        Class r = Class.forName("com.interview.javabasic.reflect.Robot");
    }
}
```

分别使用上面的代码，会发现只有执行forName方法才会输出"Hello Robot"语句。证实了上面的说法。

值得注意的是，上面并没有调用loadClass，而是巧妙的通过获得Robot类的classloader来触发类的加载，也就是AppClassLoader.





## main函数执行所发生的一系列动作
1、JVM启动

2、对main函数中需要使用的类，执行加载、链接、初始化

3、启动main线程

4、执行main函数

5、JVM退出

## GC回收算法
JVM将堆分成了 二个大区  Young 和 Old 。

 - Young区

Young 区又分为 Eden、Survivor1、Survivor2, 两个Survivor 区相对地作为为From 和 To 逻辑区域, 当Servivor1作为 From 时 ， Servivor2 就作为 To,反之亦然。这是因为新生代区域使用的是**复制清理**的GC算法。

关于为什么要这样区分Young（将Young区分为Eden、Servivor1、Servivor2以及相对的From和To ），这要牵涉到JVM的垃圾回收算法的讨论。

1）因为引用计数法无法解决循环引用问题，JVM并没有采用这种算法来判断对象是否存活。

2）JVM一般采用GCRoots的方法，只要从任何一个GCRoots的对象可达，就是不被回收的对象

3）判断了对象生死，怎么进行内存的清理呢？

4）标记-清除算法，先标记那些要被回收的对象，然后进行清理，简单可行，但是**①**标记清除效率低，因为要一个一个标记和清除**②**造成大量不连续的内存碎片，空间碎片太多可能会导致当程序在以后的运行过程中需要分配较大对象的时候无法找到足够的连续内存而不得不触发另一次垃圾收集动作。

5）采用复制-清除算法：将可用内存按照容量分为大小相等的两块，每次只是使用其中的一块。当这一块的内存用完了，就将可用内存中存活的对象依次复制到空闲的内存区域，然后对之前的区域进行清除操作。

 - 哪些些对象可以作为GC Roots？

    虚拟机栈（栈帧中的本地变量表）中的引用的对象
    
    方法区中的类静态属性引用的对象
    
    方法区中的常量引用的对象
    
    本地方法栈中JNI（Native方法）的引用对象
    
新生代做的是复制-清理、老年代做的是标记-清理

**标记-清理的优缺点**

优点：好像没什么优点，或许优点是简单、理论上可用空间大等。

缺点：1、效率问题，标记和清理两个两个过程效率都不高。2、空间问题，标记清理完成以后会产生大量的不连续内存区域。可能导致大对象无法获得空间分配，从而触发不必要的GC操作。

**复制-清理的优缺点**

优点：不会产生碎片化问题，实现简单

缺点：会浪费掉一个部分内存区域

## 引用类型

https://github.com/WQZ321123/CS-Notes/blob/master/notes/Java%20%E8%99%9A%E6%8B%9F%E6%9C%BA.md#%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B

无论是通过引用计算算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。

Java 提供了四种强度不同的引用类型。

 **1. 强引用**

被强引用关联的对象不会被回收。使用 new 一个新对象的方式来创建强引用。
```java
Object obj = new Object();
```

 **1. 软引用**

被软引用关联的对象只有在内存不够的情况下才会被回收。使用 SoftReference 类来创建软引用。

```java
Object obj = new Object();
SoftReference<Object> sf = new SoftReference<Object>(obj);
obj = null;  // 使对象只被软引用关联
```

 **1. 弱引用**
 
 被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。使用 WeakReference 类来实现弱引用。
```java
Object obj = new Object();
WeakReference<Object> wf = new WeakReference<Object>(obj);
obj = null;
```
 **2. 虚引用**

又称为幽灵引用或者幻影引用。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。

为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。

使用 PhantomReference 来实现虚引用。

```java
Object obj = new Object();
PhantomReference<Object> pf = new PhantomReference<Object>(obj);
obj = null;
```
 
 
 
## concurrentHashMap的底层实现
concurrentHashMap在JDK1.8的实现和JDK1.7是不一样的，JDK8默认将table数组的每一项作为一个segment，而JDK7将table数组的几项作为一个segment。
JDK8直接采用transient volatile HashEntry<K,V>[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。

 - concurrentHashMap的get操作需要加锁吗？
没有加锁，但是put和remove操作有加锁，synchronized关键字加锁。

下面看一下jdk**1.8**的concurrentHashMap到源码。

#### 首先是get方法：
```java
    /**
     * Returns the value to which the specified key is mapped,
     * or {@code null} if this map contains no mapping for the key.
     *
     * <p>More formally, if this map contains a mapping from a key
     * {@code k} to a value {@code v} such that {@code key.equals(k)},
     * then this method returns {@code v}; otherwise it returns
     * {@code null}.  (There can be at most one such mapping.)
     *
     * @throws NullPointerException if the specified key is null
     */
    public V get(Object key) {
        Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
        int h = spread(key.hashCode());
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (e = tabAt(tab, (n - 1) & h)) != null) {
            if ((eh = e.hash) == h) {
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    return e.val;
            }
            else if (eh < 0)
                return (p = e.find(h, key)) != null ? p.val : null;
            while ((e = e.next) != null) {
                if (e.hash == h &&
                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }
```
从源码可以看出，get操作确实没有加锁。并且，table使用了volatile关键字进行修饰，依据JVM的happen-before原则，保证了数据到内存可见性，也就是保证了在并发读写时，读取到到数据是最新的。

#### 然后是put方法：
```java
    /**
     * Maps the specified key to the specified value in this table.
     * Neither the key nor the value can be null.
     *
     * <p>The value can be retrieved by calling the {@code get} method
     * with a key that is equal to the original key.
     *
     * @param key key with which the specified value is to be associated
     * @param value value to be associated with the specified key
     * @return the previous value associated with {@code key}, or
     *         {@code null} if there was no mapping for {@code key}
     * @throws NullPointerException if the specified key or value is null
     */
    public V put(K key, V value) {
        return putVal(key, value, false);
    }

    /** Implementation for put and putIfAbsent */
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        // 这里为什么要起一个死循环？？没搞懂。。。
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
```

put方法其实内部调用了putVal方法，实际操作也是在putVal方法内部完成的。

putVal方法逻辑也比较简单：

首先是根据put的key到hash定位需要放置到位置，如果当前位置没有元素，那么使用cas放置元素。

如果map正在扩容，则参与扩容。

最后，如果上面两个条件都不满足，那么就使用synchronized关键字加锁，然后如果锁链表结构，就在链表到尾部插入元素，如果是树，就在树中插入元素。

#### 然后是remove方法
```java
    /**
     * Removes the key (and its corresponding value) from this map.
     * This method does nothing if the key is not in the map.
     *
     * @param  key the key that needs to be removed
     * @return the previous value associated with {@code key}, or
     *         {@code null} if there was no mapping for {@code key}
     * @throws NullPointerException if the specified key is null
     */
    public V remove(Object key) {
        return replaceNode(key, null, null);
    }

    /**
     * Implementation for the four public remove/replace methods:
     * Replaces node value with v, conditional upon match of cv if
     * non-null.  If resulting value is null, delete.
     */
    final V replaceNode(Object key, V value, Object cv) {
        int hash = spread(key.hashCode());
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0 ||
                (f = tabAt(tab, i = (n - 1) & hash)) == null)
                break;
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                boolean validated = false;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            validated = true;
                            for (Node<K,V> e = f, pred = null;;) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    V ev = e.val;
                                    if (cv == null || cv == ev ||
                                        (ev != null && cv.equals(ev))) {
                                        oldVal = ev;
                                        if (value != null)
                                            e.val = value;
                                        else if (pred != null)
                                            pred.next = e.next;
                                        else
                                            setTabAt(tab, i, e.next);
                                    }
                                    break;
                                }
                                pred = e;
                                if ((e = e.next) == null)
                                    break;
                            }
                        }
                        else if (f instanceof TreeBin) {
                            validated = true;
                            TreeBin<K,V> t = (TreeBin<K,V>)f;
                            TreeNode<K,V> r, p;
                            if ((r = t.root) != null &&
                                (p = r.findTreeNode(hash, key, null)) != null) {
                                V pv = p.val;
                                if (cv == null || cv == pv ||
                                    (pv != null && cv.equals(pv))) {
                                    oldVal = pv;
                                    if (value != null)
                                        p.val = value;
                                    else if (t.removeTreeNode(p))
                                        setTabAt(tab, i, untreeify(t.first));
                                }
                            }
                        }
                    }
                }
                if (validated) {
                    if (oldVal != null) {
                        if (value == null)
                            addCount(-1L, -1);
                        return oldVal;
                    }
                    break;
                }
            }
        }
        return null;
    }
```

remove的源码其实也很简单，内部也是通过replaceNode方法去实际实现的。

replaceNode首先判断要删除到元素是否存在，如果不是处于扩容阶段，那么就使用synchronized关键字加锁，并且按照链表或者树的结构进行元素替换（remove就是替换为null），最后是更新map的大小，使用了cas的操作。




## 分布式的基本知识

- https://www.cnblogs.com/duanxz/p/5229352.html

### CAP
CAP理论是由Eric Brewer提出的分布式系统中最为重要的理论之一：

Consistency：[强]一致性，事务保障，ACID模型。

Availiablity：[高]可用性，冗余以避免单点，至少做到柔性可用（服务降级）。

Partition tolerance：[高]可扩展性（分区容忍性）：一般要求系统能够自动按需扩展，比如HBase。

![cap](./image/2018/cap.png)

一般，如果需要CAP三者同时满足的话，不太现实，因此就会出现BASE理论。

### BASE

BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写。它本质上是对CAP理论的一种实际应用，它在牺牲一定的一致性的基础上，完成对可用性，分区容错性的保证。当然，数据需要达到最终一致性。


## SpringMVC框架执行步骤（SpringMVC使用Servlet嵌入）：
SpringMVC的url请求的核心功能是使用dispatcherServlet来完成的。

1、客户端发出一个http请求给web服务器，web服务器对http请求进行解析，如果匹配DispatcherServlet的请求映射路径（在web.xml中指定），web容器将请求转交给DispatcherServlet.

2、DipatcherServlet接收到这个请求之后将根据请求的信息（包括URL、Http方法、请求报文头和请求参数Cookie等）以及HandlerMapping的配置找到处理请求的处理器（Handler）（也就是controller中对应的url处理类）。

3-4、DispatcherServlet根据HandlerMapping找到对应的Handler,将处理权交给Handler（Handler将具体的处理进行封装），再由具体的HandlerAdapter对Handler进行具体的调用（controller中具体的调用方法）。

5、Handler对数据处理完成以后将返回一个ModelAndView()对象给DispatcherServlet。

6、Handler返回的ModelAndView()只是一个逻辑视图并不是一个正式的视图，DispatcherSevlet通过ViewResolver将逻辑视图转化为真正的视图View。

7、Dispatcher通过model解析出ModelAndView()中的参数进行解析最终展现出完整的view并返回给客户端。

## spring bean的生命周期
bean的生命周期大致会经历以下一些过程。

 1. bean实例化，寻找bean的定义信息并将其实例化。
 2. 设置bean的属性值。
 3. 调用BeanNameAware的setBeanName方法设置bean名称。
 4. 调用BeanFactoryAware的setBeanFactory方法。
 5. 调用BeanPostProcessor的**预初始化**方法。
 6. 调用InitializingBean的afterPropertiesSet方法。
 7. 调用bean的init-method方法
 8. 调用BeanPostProcessor的**后初始化**方法。
 9. bean初始化完成，可以在上下文环境中使用
 10. 容器关闭的时候，需要调用DisposableBean的destroy方法。
 11. 调用bean的destroy方法。
 
面试的时候，上面的步骤应该简化着来回答，一般可以概括为：实例化，初始init，接收请求service，销毁destroy；

1、**实例化**一个Bean－－也就是我们常说的**new**；

2、按照Spring上下文对实例化的Bean进行配置－－也就是IOC注入；

3、如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，此处传递的就是Spring配置文件中Bean的id值

4、如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(setBeanFactory(BeanFactory)传递的是Spring工厂自身（可以用这个方式来获取其它Bean，只需在Spring配置文件中配置一个普通的Bean就可以）；

5、如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文（同样这个方式也可以实现步骤4的内容，但比4更好，因为ApplicationContext是BeanFactory的子接口，有更多的实现方法）；

6、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于内存或缓存技术；

7、如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。

8、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法、；

注：以上工作完成以后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一般情况下我们调用同一个id的Bean会是在内容地址相同的实例，当然在Spring配置文件中也可以配置非Singleton，这里我们不做赘述。

9、当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用那个其实现的destroy()方法；

10、最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。

## ArrayList的底层实现
- https://www.cnblogs.com/ITtangtang/p/3948555.html

 - ArrayList底层使用数组实现
 - 当不指定初始容量时，数组初始容量为10

 其中比较重要的函数，如下面源码所示：

根据下表index移除元素时，首先需要判断是否越界。然后才是删除元素，拷贝删除元素后面位置的数组，移除成功就返回移除的元素。
```java
// 移除此列表中指定位置上的元素。  
 public E remove(int index) {  
 // 如果index越界，抛出IndexOutOfBoundsException异常
    RangeCheck(index);  
  
    modCount++;  
    E oldValue = (E) elementData[index];  
  
    int numMoved = size - index - 1;  
    if (numMoved > 0)  
        System.arraycopy(elementData, index+1, elementData, index, numMoved);  
    elementData[--size] = null; // clear to let GC do its work
  
    return oldValue;  
 }
```

根据指定元素o，移除成功返回true，否则返回false
remove(Object o)中通过遍历element寻找是否存在传入对象，一旦找到就调用fastRemove移除对象。为什么找到了元素就知道了index，不通过remove(index)来移除元素呢？因为fastRemove跳过了判断边界的处理，因为找到元素就相当于确定了index不会超过边界，而且fastRemove并不返回被移除的元素。
```java
// 移除此列表中首次出现的指定元素（如果存在）。这是应为ArrayList中允许存放重复的元素。  
 public boolean remove(Object o) {  
    // 由于ArrayList中允许存放null，因此下面通过两种情况来分别处理。  
    if (o == null) {  
        for (int index = 0; index < size; index++)  
            if (elementData[index] == null) {  
                // 类似remove(int index)，移除列表中指定位置上的元素。  
                fastRemove(index);  
                return true;  
            }  
    } else {  
        for (int index = 0; index < size; index++)  
            if (o.equals(elementData[index])) {  
                fastRemove(index);  
                return true;  
            }  
        }  
        return false;  
    } 
}
```

```java
/**
     * Increases the capacity of this <tt>ArrayList</tt> instance, if
     * necessary, to ensure that it can hold at least the number of elements
     * specified by the minimum capacity argument.
     *
     * @param   minCapacity   the desired minimum capacity
     */
    public void ensureCapacity(int minCapacity) {
        int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)
            // any size if not default element table
            ? 0
            // larger than default for default empty table. It's already
            // supposed to be at default size.
            : DEFAULT_CAPACITY;

        if (minCapacity > minExpand) {
            ensureExplicitCapacity(minCapacity);
        }
    }
    
    // ensureExplicitCapacity方法
        private void ensureExplicitCapacity(int minCapacity) {
        modCount++;

        // overflow-conscious code
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }
    
    // grow方法进行实际数组的扩容，先按照2倍进行扩容，如果不够，就按照指定的minCapacity容量进行扩容
    /**
     * Increases the capacity to ensure that it can hold at least the
     * number of elements specified by the minimum capacity argument.
     *
     * @param minCapacity the desired minimum capacity
     */
    private void grow(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
    }
```

Fail-Fast机制： 
ArrayList也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。具体介绍请参考这篇文章深入Java集合学习系列：HashMap的实现原理 中的Fail-Fast机制。
ArrayList的实现中大量地调用了Arrays.copyof()和System.arraycopy()方法。Arrays.copyof()内部最终也调用了System.arraycopy()，只是调用之前先判断数组类型是否一致，再选择创建相应类型的数组（不懂可以看源码），再调用System.arraycopy()这个native方法进行数组的拷贝。

## Java Array和Arrays
Array是数组类，Arrays是一个工具类，类似于collection和collections的区别。

## 分布式如何实现session共享

- http://blog.csdn.net/sxiaobei/article/details/57086489

 1. 服务器实现的session复制或session共享，这类型的共享session是和服务器紧密相关的，比如webSphere或JBOSS在搭建集群时候可以配置实现session复制或session共享，但是这种方式有一个致命的缺点，就是不好扩展和移植，比如我们更换服务器，那么就要修改服务器配置（因为会涉及到服务器之间的直接http请求，因此会将服务器的IP写死在相应的配置文件中）。
 2. 利用成熟的技术做session复制，比如12306使用的gemfire，比如常见的内存数据库如redis或memorycache，这类方案虽然比较普适，但是严重依赖于第三方，这样当第三方服务器出现问题的时候，那么将是应用的灾难。
 3. 将session维护在客户端，很容易想到就是利用cookie，但是客户端存在风险，数据不安全，而且可以存放的数据量比较小，所以将session维护在客户端还要对session中的信息加密。
 4. 使用Spring Session
Spring Session是Spring的项目之一，GitHub地址：https://github.com/spring-projects/spring-session。
Spring Session提供了一套创建和管理Servlet HttpSession的方案。Spring Session提供了集群Session（Clustered Sessions）功能，默认采用外置的Redis来存储Session数据，以此来解决Session共享的问题。
这是官网的介绍：
Spring Session provides an API and implementations for managing a user’s session information.

Features

Spring Session provides the following features:

API and implementations for managing a user's session
HttpSession - allows replacing the HttpSession in an application container (i.e. Tomcat) neutral way
Clustered Sessions - Spring Session makes it trivial to support clustered sessions without being tied to an application container specific solution.
Multiple Browser Sessions - Spring Session supports managing multiple users' sessions in a single browser instance (i.e. multiple authenticated accounts similar to Google).
RESTful APIs - Spring Session allows providing session ids in headers to work with RESTful APIs
WebSocket - provides the ability to keep the HttpSession alive when receiving WebSocket messages
使用spring-session需要进行如下一些配置：

 - 添加spring-session-data-redis依赖
 
 ```html
 <dependency>  
    <groupId>org.springframework.session</groupId>  
    <artifactId>spring-session-data-redis</artifactId>  
    <version>1.0.1.RELEASE</version>  
</dependency>  
 ```
 
 - 第二步，编写一个配置类，用来启用RedisHttpSession功能，并向Spring容器中注册一个RedisConnectionFactory。
```java
import org.springframework.context.annotation.Bean;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;
import org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSession;

@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 7200)
public class RedisHttpSessionConfig {

    @Bean
    public RedisConnectionFactory connectionFactory() {
        JedisConnectionFactory connectionFactory = new JedisConnectionFactory();
        connectionFactory.setPort(6379);
        connectionFactory.setHostName("10.18.15.190");
        return connectionFactory;
    }
}
```

 - 第三步，将RedisHttpSessionConfig加入到WebInitializer#getRootConfigClasses()中，让Spring容器加载RedisHttpSessionConfig类。WebInitializer是一个自定义的AbstractAnnotationConfigDispatcherServletInitializer实现类，该类会在Servlet启动时加载（当然也可以采用别的加载方法，比如采用扫描@Configuration注解类的方式等等）。
```java
//该类采用Java Configuration，来代替web.xml   
public class WebInitializer extends AbstractAnnotationConfigDispatcherServletInitializer {
    
    @Override
    protected Class<?>[] getRootConfigClasses() {
        return new Class[]{Config1.class, Config2.class, RedisHttpSessionConfig.class};
    }
	
	//......
}
```
 - 第四步，编写一个一个AbstractHttpSessionApplicationInitializer实现类，用于向Servlet容器中添加springSessionRepositoryFilter。
```java
import org.springframework.session.web.context.AbstractHttpSessionApplicationInitializer;  
  
public class SpringSessionInitializer extends AbstractHttpSessionApplicationInitializer {  
} 
```

## Java中的Lock和synchronized两种锁定机制的对比
- https://www.cnblogs.com/xrq730/p/4979021.html

总的来说，Lock接口是对synchronized语法的一个扩展，它支持更加灵活的锁定范围，以及一些灵活的锁定方式，例如允许**并发读**（读写锁）。

直接复制的JDK1.6官方文档相关部分：

synchronized 方法或语句的使用提供了对与每个对象相关的隐式监视器锁的访问，但却强制所有锁获取和释放均要出现在一个块结构中：当获取了多个锁时，它们必须以相反的顺序释放，且必须在与所有锁被获取时相同的词法范围内释放所有锁。

虽然 synchronized 方法和语句的范围机制使得使用监视器锁编程方便了很多，而且还帮助避免了很多涉及到锁的常见编程错误，但有时也需要以**更为灵活**的方式使用锁。例如，某些遍历并发访问的数据结果的算法要求使用 "hand-over-hand" 或 "chain locking"：获取节点 A 的锁，然后再获取节点 B 的锁，然后释放 A 并获取 C，然后释放 B 并获取 D，依此类推。Lock 接口的实现允许锁在不同的作用范围内获取和释放，并允许以任何顺序获取和释放多个锁，从而支持使用这种技术。

随着灵活性的增加，也带来了更多的责任。不使用块结构锁就失去了使用 synchronized 方法和语句时会出现的锁自动释放功能。在大多数情况下，应该使用以下语句：
```java
Lock l = ...; 
     l.lock();
     try {
         // access the resource protected by this lock
     } finally {
         l.unlock();
     }
 
```
Lock 实现提供了使用 synchronized 方法和语句所没有的其他功能，包括提供了一个非块结构的获取锁尝试 (tryLock())、一个获取可中断锁的尝试 (lockInterruptibly()) 和一个获取超时失效锁的尝试 (tryLock(long, TimeUnit))。

## Spring中ApplicationContext和beanfactory区别
org.springframework.beans  and  org.springframework.context  是springIOC容器的基础。BeanFactory  接口提供了一套完备的配置机制，使得它可以管理任何类型的对象。  ApplicationContext  是BeanFactory  的一个子接口。  ApplicationContext子接口实现了与AOP的宽松集成：消息处理与集成；web应用中的应用层context，比如说WebApplicationContext  。
简单来说，BeanFactory  提供框架级别的配置以及基础的功能，在此基础上，ApplicationContext添加了更多针对企业级的特定功能。Applicationcontext是beanfactory的的一个完整扩展集。如果要使用beanfactory而不是applicationcontext，可以参考spring的官方文档  Section  7.16, “The BeanFactory”.
在spring中，那些由IOC容器管理的对象组成了应用的骨架，这些对象被称为beans。

## 设计模式之六大原则
 1. 单一职责原则(Single Responsibility Principle,
    SRP)：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。

 2. 开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。

 3. 里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。

 4. 依赖倒转原则(Dependency Inversion  Principle,
    DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。

 5. 接口隔离原则(Interface  Segregation Principle,
    ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。

 6. 迪米特法则(Law of  Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。
 

## linux中可以同时查看一个文件的前几行和末尾几行

可以使用head（查看前几行）、tail（查看末尾几行）两个命令。

例如：

查看/etc/profile的前10行内容，应该是：

 head -n 10 /etc/profile
 
查看/etc/profile的最后5行内容，应该是：

 tail  -n 5 /etc/profile
 
如果想同时查看可以将前10行和后5行的显示信息通过输出重定向的方法保存到一个文档，这样查看文档即可一目了然。

例如：

将内容输出到/home/test文件中

 head -n 10 /etc/profile >>/home/test
 
 tail  -n 5 /etc/profile>>/home/test
 
查看的话只需要打开test文件即可。

cat /home/test

## linux文本内容查找

从文件内容查找匹配指定字符串的行：

    $ grep "被查找的字符串" 文件名

从文件内容查找与正则表达式匹配的行：

    $ grep –e “正则表达式” 文件名

查找时不区分大小写：

    $ grep –i "被查找的字符串" 文件名

查找匹配的行数：

    $ grep -c "被查找的字符串" 文件名

从文件内容查找不匹配指定字符串的行：

    $ grep –v "被查找的字符串" 文件名

从根目录开始查找所有扩展名为.log的文本文件，并找出包含”ERROR”的行

    find / -type f -name "*.log" | xargs grep "ERROR"

上面的**xargs**参数，[参考链接](http://czmmiao.iteye.com/blog/1949225)，它的作用就是多个命令，或者引用。参考博客里的一段话，“之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了xargs命令”。

系统查找到httpd.conf文件后即时在屏幕上显示httpd.conf文件信息。 

    find/-name"httpd.conf"-ls

在根目录下查找某个文件

    find . -name "test"

在某个目录下查找包含某个字符串的文件

    grep -r "zh_CN" ./

## java并发相关
### java内存模型

- https://www.ixigua.com/6989770259024577037?logTag=b841f64f55acf3204dc9

java内存模型（java momory model，JMM），个人理解，是在java并发编程中的一种CPU、高速缓存（工作内存）、主存之间数据交互的规范，目的只有一个，为了保证在多线程并发的情况下，保证程序执行结果的正确性。

这里我们引入一张图来介绍一下：

![jmm](./image/2018/jmm.png)

当线程在CPU执行的时候，由于CPU的速度相对于内存是很快的（CPU一般GHz，内存一般千MHz，相差十多倍，并且如果遇到IO等耗时操作时，二者的差距更大）。为了弥补这两者之间的速度差异，提高CPU利用率，工程师在CPU内部增加高速缓存cache。但是，也因为cache的引入，在并发编程的场景下，容易出现数据不一致的问题。

为了解决缓存不一致性问题，通常来说有以下2种解决方法：
1. 通过在总线加LOCK锁的方式
2. 通过缓存一致性协议

两种方式都是通过硬件层面进行控制。
在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。

但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。

所以就出现了缓存一致性协议。最出名的就是Intel的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。

为了解决这种数据不一致的问题，java也设计了适合java的内存模型，屏蔽了一些底层的硬件环境和操作系统的内存访问差异，以实现让java程序在各种平台上都能达到一致的内存访问效果。下面介绍8个内存读写指令，虚拟机实现时必须保证这些指令是原子的，按照作用对象的不同，可以分为两类：
| 作用于主存        | 作用域工作内存   |  
| --------   | ----- | 
| lock：锁定     | load：载入 |  
| unlock：解除锁定        |   use：使用   |   
| read：读取        |   assign：赋值    | 
| write：写入   |    store：存储    | 

下面演示一下A、B线程之间对同一个共享变量x进行操作的同步过程：
![jmm](./image/2018/jmm-data-transfer.png)

上图演示了两个线程争抢对x共享变量进行操作，结果A线程先争抢到，然后对其进行加锁，执行后续操作，再写回主存，释放锁。此时B线程才可以对x进行后续操作。

### 原子性、可见性、有序性
 - 原子性

某一个操作，或者一系列操作，要么成功。要么失败。
例如i = 9;就是一个原子操作。
假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。
那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。

在Java中，对**基本数据类型**的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。

 - 可见性
对于共享变量，一个线程修改了它，其他线程能够立马读取到修改后的值。
　
 - 有序性

即程序执行的顺序按照代码的先后顺序执行。
一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。因为处理器在进行指令重排序之前，需要考虑数据之间的依赖关系。与处理器的乱序执行优化类似，Java虚拟机的即时编译器也有类似的指令重排序（Instruction Reorder）优化。

**虽然**指令重排序不会影响**单线程**程序的执行结果，但是对于多线程程序，就可能产生影响。比如下面的代码：
```java
//线程1:
context = loadContext();   //语句1
inited = true;             //语句2
 
//线程2:
while(!inited ){
  sleep()
}
doSomethingwithconfig(context);
```
上面的代码，如果线程2执行的时候，线程1还未对context进行初始化，那么就会出现错误。
**总之**，对于并发编程，原子性、可见性、有序性缺一不可。

### violatile关键字及原理

- http://www.cnblogs.com/dolphin0520/p/3920373.html

`volatile`保证了可见性、有序性。不能保证原子性，例如下面的代码：
```java
public class Test {
    public volatile int inc = 0;
     
    public void increase() {
        inc++;
    }
     
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i<10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j<10000;j++)
                        test.increase();
                };
            }.start();
        }
         
        while(Thread.activeCount()>1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
```
执行结果总是会小于10000，对代码使用`javap -c xx.class`进行反编译可以看到increase的字节码指令如下：
```java
  public void increase();
    Code:
       0: aload_0
       1: dup
       2: getfield      #2                  // Field inc:I
       5: iconst_1
       6: iadd
       7: putfield      #2                  // Field inc:I
      10: return
```
可以看到inc++在字节码指令中对应四条命令，并不能保证原子性。严格意义上来说，即便只有一条字节码指令，也不能意味着这个指令就是一个原子操作。在解释执行时，一条字节码指令，解释器需要执行许多行代码才能实现它的语义；在编译执行时，一条字节码指令，也可能转换成若干条本地机器码指令。

下面这段话摘自《深入理解Java虚拟机》：

观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令.

lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：

1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
2. 它会强制将对缓存的修改操作立即写入主存；
3. 如果是写操作，它会导致其他CPU中对应的缓存行无效。
　　

### synchronized关键字及原理

`synchronized`保证了可见性、有序性、原子性。

为了保证线程安全，java提供了Synchronized关键字，用于进行临界资源的锁定，从而达到线程访问互斥的目的。

Synchronized的实现基础就是Java对象头和Monitor。

一般而言，java对象在内存中都有对象头、实例数据、对齐填充三部分组成。我们这里主要认识一下对象头，如下图所示：

![对象头](./image/interview/QQ截图20200109223458.png)

markword详细数据bit位如下：

![markword](./image/interview/QQ截图20200109223820.png)

从图中我们可以看出，当对象持有的锁状态不同时，mark word的锁标志位的值也不一样。

下面再看一下monitor，默认来说，每个java对象都带有monitor锁。

monitor底层使用ObjectMonitor实现，C++编写，源码可以在  http://hg.openjdk.java.net/jdk8u/jdk8u/hotspot/file/174eed0020f2/src/share/vm/runtime/objectMonitor.hpp  位置找到。我们重点关注如下代码：
```c++
  // initialize the monitor, exception the semaphore, all other fields
  // are simple integers or pointers
  ObjectMonitor() {
    _header       = NULL;
    _count        = 0;
    _waiters      = 0,
    _recursions   = 0;
    _object       = NULL;
    _owner        = NULL;
    _WaitSet      = NULL;
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ;
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
    _previous_owner_tid = 0;
  }
```
上面的代码我们可以获得很多有用信息，_WaitSet就是等待获取monitor的线程集合，_EntryList是所有需要想要获得锁的数组。当某个线程获得锁时，_owner将会被设置为当前线程，且_count进行+1操作。更为形象的解释，可以看一下下面的图：

![markword](./image/interview/QQ截图20200109222836.png)


下面我们看一个简单的实例：
```java
package com.interview.javabasic.thread;

public class SyncBlockAndMethod {
    public void syncsTask() {
        synchronized (this) {
            System.out.println("Hello");
//            synchronized (this) {
//                System.out.println("World");
//            }
        }
    }

    public synchronized void syncTask() {
        System.out.println("Hello Again");
    }

}
```
使用如下命令编译一下源文件，并打开编译后的class文件：
```java
D:\javabasic-master\javabasic\src\com\interview\javabasic\thread>javac SyncBlockAndMethod.java

D:\javabasic-master\javabasic\src\com\interview\javabasic\thread>javap -verbose SyncBlockAndMethod.class
```
字节码指令输出如下：
```java
  Last modified 2020-1-9; size 637 bytes
  MD5 checksum eb66a779fa1538ab6678b5595d78f54d
  Compiled from "SyncBlockAndMethod.java"
public class com.interview.javabasic.thread.SyncBlockAndMethod
  minor version: 0
  major version: 52
  flags: ACC_PUBLIC, ACC_SUPER
Constant pool:
   #1 = Methodref          #7.#20         // java/lang/Object."<init>":()V
   #2 = Fieldref           #21.#22        // java/lang/System.out:Ljava/io/PrintStream;
   #3 = String             #23            // Hello
   #4 = Methodref          #24.#25        // java/io/PrintStream.println:(Ljava/lang/String;)V
   #5 = String             #26            // Hello Again
   #6 = Class              #27            // com/interview/javabasic/thread/SyncBlockAndMethod
   #7 = Class              #28            // java/lang/Object
   #8 = Utf8               <init>
   #9 = Utf8               ()V
  #10 = Utf8               Code
  #11 = Utf8               LineNumberTable
  #12 = Utf8               syncsTask
  #13 = Utf8               StackMapTable
  #14 = Class              #27            // com/interview/javabasic/thread/SyncBlockAndMethod
  #15 = Class              #28            // java/lang/Object
  #16 = Class              #29            // java/lang/Throwable
  #17 = Utf8               syncTask
  #18 = Utf8               SourceFile
  #19 = Utf8               SyncBlockAndMethod.java
  #20 = NameAndType        #8:#9          // "<init>":()V
  #21 = Class              #30            // java/lang/System
  #22 = NameAndType        #31:#32        // out:Ljava/io/PrintStream;
  #23 = Utf8               Hello
  #24 = Class              #33            // java/io/PrintStream
  #25 = NameAndType        #34:#35        // println:(Ljava/lang/String;)V
  #26 = Utf8               Hello Again
  #27 = Utf8               com/interview/javabasic/thread/SyncBlockAndMethod
  #28 = Utf8               java/lang/Object
  #29 = Utf8               java/lang/Throwable
  #30 = Utf8               java/lang/System
  #31 = Utf8               out
  #32 = Utf8               Ljava/io/PrintStream;
  #33 = Utf8               java/io/PrintStream
  #34 = Utf8               println
  #35 = Utf8               (Ljava/lang/String;)V
{
  public com.interview.javabasic.thread.SyncBlockAndMethod();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=1, locals=1, args_size=1
         0: aload_0
         1: invokespecial #1                  // Method java/lang/Object."<init>":()V
         4: return
      LineNumberTable:
        line 3: 0

  public void syncsTask();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=3, args_size=1
         0: aload_0
         1: dup
         2: astore_1
         3: monitorenter
         4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         7: ldc           #3                  // String Hello
         9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        12: aload_1
        13: monitorexit
        14: goto          22
        17: astore_2
        18: aload_1
        19: monitorexit
        20: aload_2
        21: athrow
        22: return
      Exception table:
         from    to  target type
             4    14    17   any
            17    20    17   any
      LineNumberTable:
        line 5: 0
        line 6: 4
        line 10: 12
        line 11: 22
      StackMapTable: number_of_entries = 2
        frame_type = 255 /* full_frame */
          offset_delta = 17
          locals = [ class com/interview/javabasic/thread/SyncBlockAndMethod, class java/lang/Object ]
          stack = [ class java/lang/Throwable ]
        frame_type = 250 /* chop */
          offset_delta = 4

  public synchronized void syncTask();
    descriptor: ()V
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
      stack=2, locals=1, args_size=1
         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #5                  // String Hello Again
         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return
      LineNumberTable:
        line 14: 0
        line 15: 8
}
SourceFile: "SyncBlockAndMethod.java"
```
首先找到方法syncsTask，可以看到首先使用了monitorenter尝试进行加锁，如果锁获取成功，那么后续就会有monitorexit进行锁的释放，否则会卡在monitorenter指令位置，等待获取锁。

值得注意的是，monitorexit后面还有一个monitorexit，这个其实是为了保证锁一定可以被成功释放，保证我们的业务代码放生异常时，锁也可以被释放。

再搜索一下syncTask，可以看到它并没有加解锁的指令，但是它有ACC_SYNCHRONIZED，同样可以达到相同的效果。

我们再研究一下synchronized的**可重入**性，看下面的源码：
```java
package com.interview.javabasic.thread;

public class SyncBlockAndMethod {
    public void syncsTask() {
        synchronized (this) {
            System.out.println("Hello");
            synchronized (this) {
                System.out.println("World");
            }
        }
    }

    public synchronized void syncTask() {
        System.out.println("Hello Again");
    }

}
```
同样编译，再查看class文件：
```java
D:\javabasic-master\javabasic\src\com\interview\javabasic\thread>javac SyncBlockAndMethod.java

D:\javabasic-master\javabasic\src\com\interview\javabasic\thread>javap -verbose SyncBlockAndMethod.class
Classfile /D:/BaiduNetdiskDownload/剑指Java面试-Offer直通车/javabasic-master/javabasic/src/com/interview/javabasic/thread/SyncBlockAndMethod.class
  Last modified 2020-1-9; size 710 bytes
  MD5 checksum b26cd7addb1cbb89001f975b414a6bf7
  Compiled from "SyncBlockAndMethod.java"
public class com.interview.javabasic.thread.SyncBlockAndMethod
  minor version: 0
  major version: 52
  flags: ACC_PUBLIC, ACC_SUPER
Constant pool:
   #1 = Methodref          #8.#21         // java/lang/Object."<init>":()V
   #2 = Fieldref           #22.#23        // java/lang/System.out:Ljava/io/PrintStream;
   #3 = String             #24            // Hello
   #4 = Methodref          #25.#26        // java/io/PrintStream.println:(Ljava/lang/String;)V
   #5 = String             #27            // World
   #6 = String             #28            // Hello Again
   #7 = Class              #29            // com/interview/javabasic/thread/SyncBlockAndMethod
   #8 = Class              #30            // java/lang/Object
   #9 = Utf8               <init>
  #10 = Utf8               ()V
  #11 = Utf8               Code
  #12 = Utf8               LineNumberTable
  #13 = Utf8               syncsTask
  #14 = Utf8               StackMapTable
  #15 = Class              #29            // com/interview/javabasic/thread/SyncBlockAndMethod
  #16 = Class              #30            // java/lang/Object
  #17 = Class              #31            // java/lang/Throwable
  #18 = Utf8               syncTask
  #19 = Utf8               SourceFile
  #20 = Utf8               SyncBlockAndMethod.java
  #21 = NameAndType        #9:#10         // "<init>":()V
  #22 = Class              #32            // java/lang/System
  #23 = NameAndType        #33:#34        // out:Ljava/io/PrintStream;
  #24 = Utf8               Hello
  #25 = Class              #35            // java/io/PrintStream
  #26 = NameAndType        #36:#37        // println:(Ljava/lang/String;)V
  #27 = Utf8               World
  #28 = Utf8               Hello Again
  #29 = Utf8               com/interview/javabasic/thread/SyncBlockAndMethod
  #30 = Utf8               java/lang/Object
  #31 = Utf8               java/lang/Throwable
  #32 = Utf8               java/lang/System
  #33 = Utf8               out
  #34 = Utf8               Ljava/io/PrintStream;
  #35 = Utf8               java/io/PrintStream
  #36 = Utf8               println
  #37 = Utf8               (Ljava/lang/String;)V
{
  public com.interview.javabasic.thread.SyncBlockAndMethod();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=1, locals=1, args_size=1
         0: aload_0
         1: invokespecial #1                  // Method java/lang/Object."<init>":()V
         4: return
      LineNumberTable:
        line 3: 0

  public void syncsTask();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=5, args_size=1
         0: aload_0
         1: dup
         2: astore_1
         3: monitorenter
         4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         7: ldc           #3                  // String Hello
         9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        12: aload_0
        13: dup
        14: astore_2
        15: monitorenter
        16: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
        19: ldc           #5                  // String World
        21: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        24: aload_2
        25: monitorexit
        26: goto          34
        29: astore_3
        30: aload_2
        31: monitorexit
        32: aload_3
        33: athrow
        34: aload_1
        35: monitorexit
        36: goto          46
        39: astore        4
        41: aload_1
        42: monitorexit
        43: aload         4
        45: athrow
        46: return
      Exception table:
         from    to  target type
            16    26    29   any
            29    32    29   any
             4    36    39   any
            39    43    39   any
      LineNumberTable:
        line 5: 0
        line 6: 4
        line 7: 12
        line 8: 16
        line 9: 24
        line 10: 34
        line 11: 46
      StackMapTable: number_of_entries = 4
        frame_type = 255 /* full_frame */
          offset_delta = 29
          locals = [ class com/interview/javabasic/thread/SyncBlockAndMethod, class java/lang/Object, class java/lang/Object ]
          stack = [ class java/lang/Throwable ]
        frame_type = 250 /* chop */
          offset_delta = 4
        frame_type = 68 /* same_locals_1_stack_item */
          stack = [ class java/lang/Throwable ]
        frame_type = 250 /* chop */
          offset_delta = 6

  public synchronized void syncTask();
    descriptor: ()V
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
      stack=2, locals=1, args_size=1
         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #6                  // String Hello Again
         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return
      LineNumberTable:
        line 14: 0
        line 15: 8
}
SourceFile: "SyncBlockAndMethod.java"
```

可以看到，上述代码，两个monitorenter是连着的，中间并没有monitorexit，证明了synchronized获取的锁是可重入的。

## jvm性能分析
linux系统，一般的逻辑是使用ps命令查看Java的进程id，然后使用
```linux
jmap -dump:format=b,file=3.dump 11459
```
这个命令可以将堆栈的信息以文件的方式输出，然后可以使用MAT工具打开。
如果要查看当前PID的每个线程的状态，也可以使用jstack命令
```linux
audi@audi-PC:~/Desktop$ jstack -l 21703
Picked up _JAVA_OPTIONS:   -Dawt.useSystemAAFontSettings=gasp
2017-11-29 23:35:09
Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode):

"Attach Listener" #9 daemon prio=9 os_prio=0 tid=0x00007fa9c0001000 nid=0x5544 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Service Thread" #8 daemon prio=9 os_prio=0 tid=0x00007fa9f80cb000 nid=0x54db runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C1 CompilerThread2" #7 daemon prio=9 os_prio=0 tid=0x00007fa9f80be000 nid=0x54da waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C2 CompilerThread1" #6 daemon prio=9 os_prio=0 tid=0x00007fa9f80bc000 nid=0x54d9 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C2 CompilerThread0" #5 daemon prio=9 os_prio=0 tid=0x00007fa9f80b9000 nid=0x54d8 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Signal Dispatcher" #4 daemon prio=9 os_prio=0 tid=0x00007fa9f80b7800 nid=0x54d7 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Finalizer" #3 daemon prio=8 os_prio=0 tid=0x00007fa9f8085000 nid=0x54d6 in Object.wait() [0x00007fa9e6b0c000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x00000000ff988ec8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	- locked <0x00000000ff988ec8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

   Locked ownable synchronizers:
	- None

"Reference Handler" #2 daemon prio=10 os_prio=0 tid=0x00007fa9f8080000 nid=0x54d5 in Object.wait() [0x00007fa9e6b4d000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x00000000ff986b68> (a java.lang.ref.Reference$Lock)
	at java.lang.Object.wait(Object.java:502)
	at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
	- locked <0x00000000ff986b68> (a java.lang.ref.Reference$Lock)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)

   Locked ownable synchronizers:
	- None

"main" #1 prio=5 os_prio=0 tid=0x00007fa9f800b000 nid=0x54c9 runnable [0x00007fa9fed81000]
   java.lang.Thread.State: RUNNABLE
	at com.audi.jvm.HeapOOM.main(HeapOOM.java:13)

   Locked ownable synchronizers:
	- None

"VM Thread" os_prio=0 tid=0x00007fa9f8078800 nid=0x54d4 runnable 

"GC task thread#0 (ParallelGC)" os_prio=0 tid=0x00007fa9f8020000 nid=0x54d0 runnable 

"GC task thread#1 (ParallelGC)" os_prio=0 tid=0x00007fa9f8021800 nid=0x54d1 runnable 

"GC task thread#2 (ParallelGC)" os_prio=0 tid=0x00007fa9f8023800 nid=0x54d2 runnable 

"GC task thread#3 (ParallelGC)" os_prio=0 tid=0x00007fa9f8025000 nid=0x54d3 runnable 

"VM Periodic Task Thread" os_prio=0 tid=0x00007fa9f80ce000 nid=0x54dc waiting on condition 

JNI global references: 6

```

### JVM性能瓶颈定位（CPU占用异常高、但内存使用正常）

测试代码如下（测试代码新加的，和后面的问题定位的行数可能不一致，但是方法是通用的，不影响我们的分析）：
```java
package com.audi.jvm;

import java.util.ArrayList;
import java.util.List;

public class Dump
{
	static class OOMObject{}
	
	public static void main(String[] args)
	{
		List<OOMObject> list = new ArrayList<>();
		
		while (true)
		{
			//list.add(new OOMObject());
		}
	}
}

```
 1. 使用top命令找到最耗CPU的进程ID。
```linux

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                       
23729 audi      20   0 2325496  23864  16096 S 100.0  0.3   9:41.56 java                          
  538 root      20   0  472828 159524 111776 S  25.0  2.0  12:59.41 Xorg                          
 1108 audi      20   0 1257172 174420  88856 S   6.2  2.2  17:03.47 deepin-wm                     
 1649 audi      20   0    9160   6504   1920 S   6.2  0.1  22:32.07 wineserver.real               
 2447 audi      20   0 1467844 276216 148520 S   6.2  3.4   4:59.35 chrome                        
 5558 audi      20   0  606828  41644  31080 S   6.2  0.5   0:45.75 deepin-terminal               
    1 root      20   0  212524   7592   5896 S   0.0  0.1   0:01.59 systemd                       
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.01 kthreadd                      
    3 root      20   0       0      0      0 S   0.0  0.0   0:01.50 ksoftirqd/0                   
    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H                  
    7 root      20   0       0      0      0 S   0.0  0.0   0:09.79 rcu_preempt                   
    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_sched                     
    9 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh                        
   10 root      rt   0       0      0      0 S   0.0  0.0   0:00.17 migration/0                   
   11 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-drain   
```

 2. 得到最耗CPU的进程ID以后，继续查找，在该进程下，哪一个线程最耗费CPU资源。
```linux
audi@audi-PC:~/Desktop$ ps p 23729 -L -o pcpu,pid,tid,time,tname,cmd
%CPU   PID   TID     TIME TTY      CMD
 0.0 23729 23729 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
99.8 23729 23732 00:11:55 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23737 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23738 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23739 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23740 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23742 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23743 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23744 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23745 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23746 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23747 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23748 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23749 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256
 0.0 23729 23750 00:00:00 ?        /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Xms20m -Xmx20m -Xss256

```
从TID这一列可以看出来，最耗费CPU的线程是**23732**，转换成16进制是0x5CB4，这时候就需要使用jstack命令来查看进程**23729**的内部线程的运行情况：
```linux
audi@audi-PC:~/Desktop$ jstack -l 23729
Picked up _JAVA_OPTIONS:   -Dawt.useSystemAAFontSettings=gasp
2017-11-29 23:57:06
Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.151-b12 mixed mode):

"Attach Listener" #9 daemon prio=9 os_prio=0 tid=0x00007fb1cc001000 nid=0x6d71 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Service Thread" #8 daemon prio=9 os_prio=0 tid=0x00007fb2040d3000 nid=0x5cc5 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C1 CompilerThread2" #7 daemon prio=9 os_prio=0 tid=0x00007fb2040be000 nid=0x5cc4 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C2 CompilerThread1" #6 daemon prio=9 os_prio=0 tid=0x00007fb2040bc000 nid=0x5cc3 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"C2 CompilerThread0" #5 daemon prio=9 os_prio=0 tid=0x00007fb2040b9000 nid=0x5cc2 waiting on condition [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Signal Dispatcher" #4 daemon prio=9 os_prio=0 tid=0x00007fb2040b7800 nid=0x5cc1 runnable [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE

   Locked ownable synchronizers:
	- None

"Finalizer" #3 daemon prio=8 os_prio=0 tid=0x00007fb204085000 nid=0x5cc0 in Object.wait() [0x00007fb1f26cd000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x00000000ff988ec8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
	- locked <0x00000000ff988ec8> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

   Locked ownable synchronizers:
	- None

"Reference Handler" #2 daemon prio=10 os_prio=0 tid=0x00007fb204080000 nid=0x5cbf in Object.wait() [0x00007fb1f270e000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on <0x00000000ff986b68> (a java.lang.ref.Reference$Lock)
	at java.lang.Object.wait(Object.java:502)
	at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
	- locked <0x00000000ff986b68> (a java.lang.ref.Reference$Lock)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)

   Locked ownable synchronizers:
	- None

"main" #1 prio=5 os_prio=0 tid=0x00007fb20400b000 nid=0x5cb4 runnable [0x00007fb20a949000]
   java.lang.Thread.State: RUNNABLE
	at com.audi.jvm.HeapOOM.main(HeapOOM.java:13)

   Locked ownable synchronizers:
	- None

"VM Thread" os_prio=0 tid=0x00007fb204078800 nid=0x5cbe runnable 

"GC task thread#0 (ParallelGC)" os_prio=0 tid=0x00007fb204020000 nid=0x5cb9 runnable 

"GC task thread#1 (ParallelGC)" os_prio=0 tid=0x00007fb204021800 nid=0x5cba runnable 

"GC task thread#2 (ParallelGC)" os_prio=0 tid=0x00007fb204023800 nid=0x5cbb runnable 

"GC task thread#3 (ParallelGC)" os_prio=0 tid=0x00007fb204025000 nid=0x5cbc runnable 

"VM Periodic Task Thread" os_prio=0 tid=0x00007fb2040d6000 nid=0x5cc6 waiting on condition 

JNI global references: 6

```
注意上面的，nid=0x5cb4，就是我们需要定位的线程：
```linux
"main" #1 prio=5 os_prio=0 tid=0x00007fb20400b000 nid=0x5cb4 runnable [0x00007fb20a949000]
   java.lang.Thread.State: RUNNABLE
	at com.audi.jvm.HeapOOM.main(HeapOOM.java:13)

```
显示是在HeapOOM.java:13的第十三行出了问题，结果也确实是，我在那里写了while死循环。

### jvm内存泄漏检测（CPU使用正常，但是内存占用持续增高）

测试代码如下：
```java
package com.audi.jvm;

import java.util.ArrayList;
import java.util.List;

/**
 * @author Administrator
 * VM参数：-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError
 *
 */
public class Dump
{
	static class OOMObject{}
	
	public static void main(String[] args)
	{
		List<OOMObject> list = new ArrayList<>();
		
		while (true)
		{
			list.add(new OOMObject());
		}
	}
}
```

出现内存泄漏，一般在没有出现OOM之前，内存占用率会一直上升，除了可以使用jconsle以及visual VM等工具进行在线查看以外，还可以使用-XX:+HeapDumpOnOutOfMemoryError参数配置虚拟机，使虚拟机在发生OOM的时候生成*.hprof堆快照文件；类似的使用jmap命令：
```linux
jmap -dump:format=b,file=3.hprof 11459
```
也可以生成堆快照文件。不过它不需要在OOM的时候才产生堆快照文件，调用这个命令一次就产生一个快照文件（注意修改文件名以便于产生不同的快照文件）。
然后使用eclipse的MAT工具打开生成的堆快照文件，选择Leak Suspects Report：

![Leak Suspects Report][5]

在上面的测试代码中加入线程休眠：
```java
Thread.sleep(3);
```
延迟OOM出现的时间，方便我们在各个时刻生成亏按照文件。
实际中我生成了两个hprof文件。分别为5.hprof和6.hprof。依次使用mat打开，结果如下：
稍早的快照文件：
![此处输入图片的描述][6]
稍后的快照文件：
![此处输入图片的描述][7]
从两张图片，基本可以看出问题出在图中深蓝色的区域，因为只有这个区域随着时间的增长在持续增长，点击上图中左下角的
Dominator Tree: List the biggest objects and what they keep alive.，查看大对象在堆中的内存占用情况，结果如下图所示。
![此处输入图片的描述][8]
上图中我手动标红的部分就是我们发生线程泄漏的地方，因为它就占用了34%左右的堆内存。
下图是更具体的内存泄漏的地方：
![此处输入图片的描述][9]
**注意**这里只是简单的模拟了一下内存泄漏，实际生产如果发生内存泄漏肯定比这个复杂的多，需要工作中进行积累与思考。

## Redis、Memcache和MongoDB的区别

 
- http://www.cnblogs.com/tuyile006/p/6382062.html
###  Memcached

 - Memcached的优点：
Memcached可以利用多核优势，单实例吞吐量极高，可以达到几十万QPS（取决于key、value的字节大小以及服务器硬件性能，日常环境中QPS高峰大约在4-6w左右）。适用于最大程度扛量。支持直接配置为session handle。

 - Memcached的局限性：
只支持简单的key/value数据结构，不像Redis可以支持丰富的数据类型。
无法进行持久化，数据不能备份，只能用于缓存使用，且重启后数据全部丢失。
无法进行数据同步，不能将MC中的数据迁移到其他MC实例中。
Memcached内存分配采用Slab Allocation机制管理内存，value大小分布差异较大时会造成内存利用率降低，并引发低利用率时依然出现踢出等问题。需要用户注重value设计。

 

### Redis
 - Redis的优点：
支持多种数据结构，如 string（字符串）、 list(双向链表)、dict(hash表)、set(集合）、zset(排序set)、hyperloglog（基数估算）
支持持久化操作，可以进行aof及rdb数据持久化到磁盘，从而进行数据备份或数据恢复等操作，较好的防止数据丢失的手段。
支持通过Replication进行数据复制，通过master-slave机制，可以实时进行数据的同步复制，支持多级复制和增量复制，master-slave机制是Redis进行HA的重要手段。
单线程请求，所有命令串行执行，并发情况下不需要考虑数据一致性问题。
支持pub/sub消息订阅机制，可以用来进行消息订阅与通知。
支持简单的事务需求，但业界使用场景很少，并不成熟。
 - Redis的局限性：
Redis只能使用单线程，性能受限于CPU性能，故单实例CPU最高才可能达到5-6wQPS每秒（取决于数据结构，数据大小以及服务器硬件性能，日常环境中QPS高峰大约在1-2w左右）。
支持简单的事务需求，但业界使用场景很少，并不成熟，既是优点也是缺点。
Redis在string类型上会消耗较多内存，可以使用dict（hash表）压缩存储以降低内存耗用。

Mc和Redis都是Key-Value类型，不适合在不同数据集之间建立关系，也不适合进行查询搜索。比如redis的keys pattern这种匹配操作，对redis的性能是灾难。

 - mongoDB
mongoDB 是一种文档性的数据库。先解释一下文档的数据库，即可以存放xml、json、bson类型系那个的数据。
这些数据具备自述性（self-describing），呈现分层的树状数据结构。redis可以用hash存放简单关系型数据。
mongoDB 存放**json**格式数据。
适合场景：事件记录、内容管理或者博客平台，比如评论系统。 
 - mongodb持久化原理
mongodb与mysql不同，mysql的每一次更新操作都会直接写入硬盘，但是mongo不会，做为内存型数据库，数据操作会先写入内存，然后再会持久化到硬盘中去，那么mongo是如何持久化的呢
mongodb在启动时，专门初始化一个线程不断循环（除非应用crash掉），用于在一定时间周期内来从defer队列中获取要持久化的数据并写入到磁盘的journal(日志)和mongofile(数据)处，当然因为它不是在用户添加记录时就写到磁盘上，所以按mongodb开发者说，它不会造成性能上的损耗，因为看过代码发现，当进行CUD操作时，记录(Record类型)都被放入到defer队列中以供延时批量（groupcommit）提交写入，但相信其中时间周期参数是个要认真考量的参数，系统为90毫秒，如果该值更低的话，可能会造成频繁磁盘操作，过高又会造成系统宕机时数据丢失过。
 - 什么是NoSQL数据库？NoSQL和RDBMS有什么区别？在哪些情况下使用和不使用NoSQL数据库？
NoSQL是非关系型数据库，NoSQL = Not Only SQL。
关系型数据库采用的结构化的数据，NoSQL采用的是键值对的方式存储数据。
在处理非结构化/半结构化的大数据时；在水平方向上进行扩展时；随时应对动态增加的数据项时可以优先考虑使用NoSQL数据库。
在考虑数据库的成熟度；支持；分析和商业智能；管理及专业性等问题时，应优先考虑关系型数据库。 
 - MySQL和MongoDB之间最基本的区别是什么？
关系型数据库与非关系型数据库的区别，即数据存储结构的不同。
 - MongoDB的特点是什么？
（1）面向文档（2）高性能（3）高可用（4）易扩展（5）丰富的查询语言 
 - MongoDB支持存储过程吗？如果支持的话，怎么用？
MongoDB支持存储过程，它是javascript写的，保存在db.system.js表中。
 - 如何理解MongoDB中的GridFS机制，MongoDB为何使用GridFS来存储文件？
GridFS是一种将大型文件存储在MongoDB中的文件规范。使用GridFS可以将大文件分隔成多个小文档存放，这样我们能够有效的保存大文档，而且解决了BSON对象有限制的问题。 
 - 为什么MongoDB的数据文件很大？
MongoDB采用的预分配空间的方式来防止文件碎片。
 - 当更新一个正在被迁移的块（Chunk）上的文档时会发生什么？
更新操作会立即发生在旧的块（Chunk）上，然后更改才会在所有权转移前复制到新的分片上。
 - MongoDB在A:{B,C}上建立索引，查询A:{B,C}和A:{C,B}都会使用索引吗？
不会，只会在A:{B,C}上使用索引。
 - 如果一个分片（Shard）停止或很慢的时候，发起一个查询会怎样？
如果一个分片停止了，除非查询设置了“Partial”选项，否则查询会返回一个错误。如果一个分片响应很慢，MongoDB会等待它的响应。

### Redis、Memcache和MongoDB的区别

从以下几个维度，对redis、memcache、mongoDB 做了对比，

1、性能

都比较高，性能对我们来说应该都不是瓶颈

总体来讲，TPS方面redis和memcache差不多，要大于mongodb

2、操作的便利性

memcache数据结构单一

redis丰富一些，数据操作方面，redis更好一些，较少的网络IO次数

mongodb支持丰富的数据表达，索引，最类似关系型数据库，支持的查询语言非常丰富

3、内存空间的大小和数据量的大小

redis在2.0版本后增加了自己的VM特性，突破物理内存的限制；可以对key value设置过期时间（类似memcache）

memcache可以修改最大可用内存,采用LRU算法

mongoDB适合大数据量的存储，依赖操作系统VM做内存管理，吃内存也比较厉害，服务不要和别的服务在一起

4、可用性（单点问题）

对于单点问题，

redis，依赖客户端来实现分布式读写；主从复制时，每次从节点重新连接主节点都要依赖整个快照,无增量复制，因性能和效率问题，

所以单点问题比较复杂；不支持自动sharding,需要依赖程序设定一致hash 机制。

一种替代方案是，不用redis本身的复制机制，采用自己做主动复制（多份存储），或者改成增量复制的方式（需要自己实现），一致性问题和性能的权衡

Memcache本身没有数据冗余机制，也没必要；对于故障预防，采用依赖成熟的hash或者环状的算法，解决单点故障引起的抖动问题。

mongoDB支持master-slave,replicaset（内部采用paxos选举算法，自动故障恢复）,auto sharding机制，对客户端屏蔽了故障转移和切分机制。

5、可靠性（持久化）

对于数据持久化和数据恢复，

redis支持（快照、AOF）：依赖快照进行持久化，aof增强了可靠性的同时，对性能有所影响

memcache不支持，通常用在做缓存,提升性能；

MongoDB从1.8版本开始采用binlog方式支持持久化的可靠性

6、数据一致性（事务支持）

Memcache 在并发场景下，用cas保证一致性

redis事务支持比较弱，只能保证事务中的每个操作连续执行

mongoDB不支持事务

7、数据分析

mongoDB内置了数据分析的功能(mapreduce),其他不支持

8、应用场景

redis：数据量较小的更性能操作和运算上

memcache：用于在动态系统中减少数据库负载，提升性能;做缓存，提高性能（适合读多写少，对于数据量比较大，可以采用sharding）

MongoDB:主要解决海量数据的访问效率问题

## Java的threadlocal类
java的threadlocal类，该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其 get 或 set 方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本。ThreadLocal 实例通常是类中的 private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。——出自JDK1.6文档。
Thread类中有这么一个变量，threadLocals，这个属性就是ThreadLocalMap类型的。
```java
/* ThreadLocal values pertaining to this thread. This map is maintained
 * by the ThreadLocal class. */
ThreadLocal.ThreadLocalMap threadLocals = null;
```
threadLocals属于当前线程实例，即，每一个线程都有一个自己的threadLocals属性。
ThreadLocalMap中底层实现，是以ThreadLocal类型实例对象为key的hashmap。比如下面代码，key就是name引用的ThreadLocal对象，value就是haha（通过set方法实现设置）。
```java
ThreadLocal<String> name = new ThreadLocal<>();
name.set("haha");
System.out.println(name.get());
```
ThreadLocal是default作用域，因此只能在同类和同包下是可见的。贴一段JDK8里面关于它的注释,里面还提到了关于弱引用的使用：
```java
    /**
     * ThreadLocalMap is a customized hash map suitable only for
     * maintaining thread local values. No operations are exported
     * outside of the ThreadLocal class. The class is package private to
     * allow declaration of fields in class Thread.  To help deal with
     * very large and long-lived usages, the hash table entries use
     * WeakReferences for keys. However, since reference queues are not
     * used, stale entries are guaranteed to be removed only when
     * the table starts running out of space.
     */
```


下面的例子出自《疯狂java讲义》
```java
package com.audi;

/**
 * Description:
 * <br/>网站: <a href="http://www.crazyit.org">疯狂Java联盟</a>
 * <br/>Copyright (C), 2001-2016, Yeeku.H.Lee
 * <br/>This program is protected by copyright laws.
 * <br/>Program Name:
 * <br/>Date:
 * @author Yeeku.H.Lee kongyeeku@163.com
 * @version 1.0
 */
class Account
{
	/* 定义一个ThreadLocal类型的变量，该变量将是一个线程局部变量
	每个线程都会保留该变量的一个副本 */
	private ThreadLocal<String> name = new ThreadLocal<>();
	// 定义一个初始化name成员变量的构造器
	public Account(String str)
	{
		this.name.set(str);
		// 下面代码用于访问当前线程的name副本的值
		System.out.println("---" + this.name.get());
	}
	// name的setter和getter方法
	public String getName()
	{
		return name.get();
	}
	public void setName(String str)
	{
		this.name.set(str);
	}
}
class MyTest extends Thread
{
	// 定义一个Account类型的成员变量
	private Account account;
	public MyTest(Account account, String name)
	{
		super(name);
		this.account = account;
	}
	public void run()
	{
		// 循环10次
		for (int i = 0 ; i < 10 ; i++)
		{
			// 当i == 6时输出将账户名替换成当前线程名
			if (i == 6)
			{
				account.setName(getName());
			}
			// 输出同一个账户的账户名和循环变量
			System.out.println(account.getName()
				+ " 账户的i值：" + i);
		}
	}
}
public class ThreadLocalTest
{
	public static void main(String[] args)
	{
		// 启动两条线程，两条线程共享同一个Account
		Account at = new Account("初始名");
		/*
		虽然两条线程共享同一个账户，即只有一个账户名
		但由于账户名是ThreadLocal类型的，所以每条线程
		都完全拥有各自的账户名副本，所以从i == 6之后，将看到两条
		线程访问同一个账户时看到不同的账户名。
		*/
		new MyTest(at , "线程甲").start();
		new MyTest(at , "线程乙").start ();
	}
}
```
代码输出结果如下：
```java
---初始名
null 账户的i值：0
null 账户的i值：1
null 账户的i值：2
null 账户的i值：3
null 账户的i值：4
null 账户的i值：5
线程甲 账户的i值：6
线程甲 账户的i值：7
线程甲 账户的i值：8
线程甲 账户的i值：9
null 账户的i值：0
null 账户的i值：1
null 账户的i值：2
null 账户的i值：3
null 账户的i值：4
null 账户的i值：5
线程乙 账户的i值：6
线程乙 账户的i值：7
线程乙 账户的i值：8
线程乙 账户的i值：9
```

## JDK动态代理与CGLIB动态代理

### jdk动态代理

jdk动态需要被代理的对象有接口，至于为什么，这是跟JDK动态代理的实现过程有关的。
一般的JDK动态代理都使用JAVA提供的**Proxy**类的
```java
public static Object newProxyInstance(ClassLoader loader,
                                      Class<?>[] interfaces,
                                      InvocationHandler h)
                               throws IllegalArgumentException
```
来返回一个代理对象，其中第二个参数就是被代理对象的接口名称，所以JDK 的动态代理是一定要有接口的。与之相对的，CGLIB动态代理则不需要。
JDK动态代理需要实现java.lang.reflect.InvocationHandler接口，通过实现接口的invoke方法实现动态代理。
```java
Object invoke(Object proxy,
              Method method,
              Object[] args)
              throws Throwable
```

摘抄一个《深入浅出Mybatis技术原理与实战》上的JDK动态代理的例子：
首先是接口HelloService：
```java
package com.audi.proxy.jdkProxy;

public interface HelloService
{
	public void sayHello(String name);
}

```
然后是接口的实现类HelloServiceImpl：
```java
package com.audi.proxy.jdkProxy;

public class HelloServiceImpl implements HelloService
{

	@Override
	public void sayHello(String name)
	{
		System.out.println("Hello "+name);
	}

}
```
然后是代理类：
```java
package com.audi.proxy.jdkProxy;

import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;
import java.lang.reflect.Proxy;

public class HelloServiceProxy implements InvocationHandler
{
	/** 
	* @Fields target : 真实的服务对象,也就是HelloServiceImpl类
	*/ 
	private Object target;

	/** 
	* @Title: bind 
	* @Description: 绑定委托对象target，并返回一个Proxy类型的代理
	*/
	public Object bind(Object target)
	{
		this.target=target;
		System.out.println("取得代理对象");
		return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
	}

	/** 
	* @Title: invoke 
	* @Description: TODO
	*/
	@Override
	public Object invoke(Object proxy, Method method, Object[] args) throws Throwable
	{
		System.out.println("jdk动态代理，进入invoke方法");
		Object result = null;
		System.out.println("反射方法调用前。。。");
		
		// 执行方法，相当于调用 HelloServiceImpl类的sayHello方法
		result = method.invoke(target, args);
		System.out.println("反射方法调用后。。。");
		return result;
	}

}
```
下面是jdk动态代理的测试代码：
```java
package com.audi.proxy.jdkProxy;

public class HelloServiceMain
{
	public static void main(String[] args)
	{
		HelloServiceProxy helloHandler = new HelloServiceProxy();
		HelloService proxy = (HelloService) helloHandler.bind(new HelloServiceImpl());
		proxy.sayHello("张三");
	}
}
```

 - 下面对jdk的源码实现过程进行一个简单的介绍
 首先是Proxy类的静态方法newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
下面是JDK1.8中newProxyInstance方法的实现源码，注意其中的中文注释：
```java
/**
     * Returns an instance of a proxy class for the specified interfaces
     * that dispatches method invocations to the specified invocation
     * handler.
     *
     * <p>{@code Proxy.newProxyInstance} throws
     * {@code IllegalArgumentException} for the same reasons that
     * {@code Proxy.getProxyClass} does.
     *
     * @param   loader the class loader to define the proxy class
     * @param   interfaces the list of interfaces for the proxy class
     *          to implement
     * @param   h the invocation handler to dispatch method invocations to
     * @return  a proxy instance with the specified invocation handler of a
     *          proxy class that is defined by the specified class loader
     *          and that implements the specified interfaces
     * @throws  IllegalArgumentException if any of the restrictions on the
     *          parameters that may be passed to {@code getProxyClass}
     *          are violated
     * @throws  SecurityException if a security manager, <em>s</em>, is present
     *          and any of the following conditions is met:
     *          <ul>
     *          <li> the given {@code loader} is {@code null} and
     *               the caller's class loader is not {@code null} and the
     *               invocation of {@link SecurityManager#checkPermission
     *               s.checkPermission} with
     *               {@code RuntimePermission("getClassLoader")} permission
     *               denies access;</li>
     *          <li> for each proxy interface, {@code intf},
     *               the caller's class loader is not the same as or an
     *               ancestor of the class loader for {@code intf} and
     *               invocation of {@link SecurityManager#checkPackageAccess
     *               s.checkPackageAccess()} denies access to {@code intf};</li>
     *          <li> any of the given proxy interfaces is non-public and the
     *               caller class is not in the same {@linkplain Package runtime package}
     *               as the non-public interface and the invocation of
     *               {@link SecurityManager#checkPermission s.checkPermission} with
     *               {@code ReflectPermission("newProxyInPackage.{package name}")}
     *               permission denies access.</li>
     *          </ul>
     * @throws  NullPointerException if the {@code interfaces} array
     *          argument or any of its elements are {@code null}, or
     *          if the invocation handler, {@code h}, is
     *          {@code null}
     */
    @CallerSensitive
    public static Object newProxyInstance(ClassLoader loader,
                                          Class<?>[] interfaces,
                                          InvocationHandler h)
        throws IllegalArgumentException
    {
        Objects.requireNonNull(h);

        final Class<?>[] intfs = interfaces.clone();
        final SecurityManager sm = System.getSecurityManager();
        if (sm != null) {
            checkProxyAccess(Reflection.getCallerClass(), loader, intfs);
        }

        /*
         * Look up or generate the designated proxy class.
         *
         */
        Class<?> cl = getProxyClass0(loader, intfs);

        /*
         * Invoke its constructor with the designated invocation handler.
         */
        try {
            if (sm != null) {
                checkNewProxyPermission(Reflection.getCallerClass(), cl);
            }

            final Constructor<?> cons = cl.getConstructor(constructorParams);
            final InvocationHandler ih = h;
            if (!Modifier.isPublic(cl.getModifiers())) {
                AccessController.doPrivileged(new PrivilegedAction<Void>() {
                    public Void run() {
                        cons.setAccessible(true);
                        return null;
                    }
                });
            }
            return cons.newInstance(new Object[]{h});
        } catch (IllegalAccessException|InstantiationException e) {
            throw new InternalError(e.toString(), e);
        } catch (InvocationTargetException e) {
            Throwable t = e.getCause();
            if (t instanceof RuntimeException) {
                throw (RuntimeException) t;
            } else {
                throw new InternalError(t.toString(), t);
            }
        } catch (NoSuchMethodException e) {
            throw new InternalError(e.toString(), e);
        }
    }
```

### CGLIB动态代理

使用cglib实现动态代理，首先通过net.sf.cglib.proxy.Enhancer的create方法获得代理对象 ，然后通过实现net.sf.cglib.proxy.MethodInterceptor接口的intecept方法，从而实现动态代理。
首先，是代理类ClassHasNoInterface的实现过程：
```java
package cglib;

public class ClassHasNoInterface {
	
	public void  method(){
		System.out.println("建立自己的知识体系还是很重要的，尽管觉得麻烦");
	}
	public void function(){
		System.out.println("如果我只停留在使用的别人开发的工具阶段，那么再过5年我也对不起程序员这个称呼");
	}
}
```
然后是代理类：
```java
package cglib;

import java.lang.reflect.Method;

import net.sf.cglib.proxy.Enhancer;
import net.sf.cglib.proxy.MethodInterceptor;
import net.sf.cglib.proxy.MethodProxy;

public class CglibTs implements MethodInterceptor{

	private Enhancer enhancer = new Enhancer();
	
	
	public Object getProxy(Class clazz){
		//生成指定类对象的子类,也就是重写类中的业务函数，在重写中加入intercept()函数而已。
		enhancer.setSuperclass(clazz);
		//这里是回调函数，enhancer中肯定有个MethodInterceptor属性。
		//回调函数是在setSuperclass中的那些重写的方法中调用---猜想
		enhancer.setCallback(this);
		//创建这个子类对象
		return enhancer.create();
	}
	public Object intercept(Object obj, Method method, Object[] args,
			MethodProxy proxy) throws Throwable {
		System.out.println(method.getName()+"执行之前做一些准备工作");
		//一不小心写成下面被注释一行代码了。 StackOverflowError
		//Object result = method.invoke(obj, args); 想不通
		Object result = proxy.invokeSuper(obj,args);
		System.out.println(method.getName()+"执行之后做一些准备的工作");
		return result;
	}
	
}
```

cglib的测试代码：
```java
package cglib;

public class MainTest {
	public static void main(String[] args) {
		CglibTs ct = new CglibTs();
		ClassHasNoInterface chni = (ClassHasNoInterface) ct.getProxy(ClassHasNoInterface.class);
		chni.method();
		chni.function();
	}
}
```




## 为什么spring的DAO只使用接口就可以调用mybatis的xml文件

关键在于动态代理，而且使用的还是JDK动态代理。

mybatis会根据相应的接口声明，使用sqlsession.getMapper(xxxDao.class)方法，通过使用JDK动态代理生成一个DAO实例对象。当我们使用DAO接口的某一个方法时，mybatis会根据这个方法的方法名和参数类型，确定xml文件中的statement ID，最终调用sqlSession.select(statement ID,...)来执行sql。

**mybatis的执行过程**
```c
                                应用程序
配置文件config.xml    →          Configuration
        ↑                           ↓
        ↑                           ↓
映射文件sqlMapConfig.xml        SqlSessionFactory
                                    ↓
                                SqlSession      →  Mapped Statement
                                    ↓
                                transaction
```             

## 什么是restful架构

 1. 每一个URI代表一种资源
 2. customer和server之间，传递这种资源的某种表现层；
 3. 客户端通过4个http动词，对服务器资源进行操作
 

## http的get、post、delete、put

 1. get的后退按钮无害，post的后退，数据会被重新提交；
 2. get的编码类型application/x-www-form-uri，post编码类型encodedapplication/x-www-form-urlencoded或multipart/form-data
 3. get历史数据保留在浏览器历史中，post的则不会保存
 4. get对数据长度有限制，一般为1-2KB，只允许ASCII码，post没有限制
 5. get安全性较差，不适合发送密码等数据，post更安全
 6. get/postbenzhix本质上都是TCP链接，get产生一个TCP数据包，post产生两个TCP数据包。get请求，浏览器会把http header data一并发送出去，响应为200。post请求，浏览器先发送header，服务器响应100后，浏览器继续发送data，然后返回200.
 

## hash索引和BTree索引和位图索引

https://blog.csdn.net/qq_21993785/article/details/80576642
 

 - **hash索引**
**hash索引的底层数据结构：**
hash索引底层使用的是hashmap来存储数据，一般来讲hashmap节点会存储key、value、hash(key)、next指针（预防hash冲突）。
表的索引字段将作为key，使用hash(key)确认存储位置，表的**行**数据实际存储的物理地址作为value，如果出现hash冲突那么就使用next指针以链表的形式进行存储（这是我的**个人推断**，目前暂时没有在其他地方明确看到hash索引怎么存储表数据的）。
  1. 大量不同数据等值精确查询，hash索引更快；
 2. hash索引不支持复合索引的最左匹配规则，即(where a=? and b=?）,index(a,b,c)相当于范围查找，不走索引（**因为hash索引需要对key进行hash**，如果复合索引底层是hashmap的数据结构，复合索引的索引字段不写全是无法计算hash值的）。
 3. hash索引不支持排序，hash索引不支持模糊查找（**因为hash索引需要对key进行hash**，模糊以后是无法计算hash值的）
 

| 存储引擎        | 索引类型   |
| --------   | -----:  |
| InnoDB     | BTree、hash |
| MyISAM        |   BTree   |
| memory/heap        |    BTree、hash    |
| NDB        |    Hash、BTree    |


InnoDB存储引擎支持的hash index是自适应的，InnoDB会根据表的使用情况，自动为表生成索引，不能人为干预是否在一张表中生成hash index。
 - **BTree索引**
 参考网址https://www.cnblogs.com/tgycoder/p/5410057.html，
https://dev.mysql.com/doc/refman/5.7/en/innodb-index-types.html
mysql的Btree索引在MyISAM和InnoDB两个存储引擎中实现的方式是不一样的，主要体现在Btree**存储的数据**不一样。
下面照抄博客的内容：
Innodb引擎使用B+Tree作为索引结构，叶结点的data域存放的是数据记录的地址。下面是Innodb索引的原理图：

![此处输入图片的描述][10]


----------


从图中可以看出主索引的B+Tree的key存储的索引列的值，而value部分存储的是行数据在磁盘上的物理地址。
辅助索引与主索引的结构类似，value部分也是保存物理地址。
示意图（以表的第二列为索引）如下所示：

![此处输入图片的描述][11]

MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。

下面介绍InnoDB存储引擎的B+Tree索引实现。
虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。

第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶结点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引(上面这段话摘自博客，起初我也这段话的正确性表示怀疑，直到看了mysql的官方reference)。
https://dev.mysql.com/doc/refman/5.7/en/innodb-index-types.html，

![此处输入图片的描述][12]

主索引存储方式：key是索引列的值，value是数据库表的该行除索引以外的其他数据。这也叫**聚集索引**。

![此处输入图片的描述][13]

注意，此时的副索引存储的key依然存储的是索引列的值，value存储的是主索引的key，而不再是数据。
所以，如果主索引的key过长，那么相应的副索引的存储空间就会上升，索引我们一般都要求主索引的字段长度尽量短。



 - **位图索引**
参考链接http://blog.csdn.net/zhou920786312/article/details/72790171，https://www.cnblogs.com/LBSer/p/3322630.html

首先，**mysql是不支持位图索引的**。oracle才支持。如果强行创建，那么会得到如下错误提示：
```sql
mysql> create bitmap index idx_gender_city on student(gender,city);

ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'bitmap index idx_gender_city on student(gender,city)' at line 1
mysql> 

```

位图索引需要注意几点：
1、在表中**放置单独的位图索引是没有意义的**，只有**多个列建立位图索引**，系统才能有效的利用位图索引提高查询速度. 
2、因为位图索引不能是唯一索引，也**不能对其进行键压缩** 
3、位图索引的作用源于与其他位图索引的结合，当位图索引的多个列进行查询时，oracle对这些上的位图索引进行布尔and和or运行，最终返回结果.

下面借博客的内容举个例子：

![此处输入图片的描述][14]

假设有这样一张表，对于性别和婚姻状况这两列，它的状态是有限的，我们可以针对这两列建立位图索引。
对于性别列建立位图索引：

![此处输入图片的描述][15]

针对婚姻状况列建立位图索引：

![此处输入图片的描述][16]

说明一下，对于状况对于2种的情况，比如婚姻状况，它是需要为每一种情况都建立位图索引的。
然后下图展示是匹配的过程，使用查询语句“select * from table where Gender=‘男’ and Marital=“未婚”;”的时候 首先取出男向量10100...，然后取出未婚向量00100...，将两个向量做and操作，这时生成新向量00100...，可以发现第三位为1，表示该表的**第三行**数据就是我们需要查询的结果。 

![此处输入图片的描述][17]

### 为什么mysql使用B+Tree而不是Btree来实现索引
- http://blog.csdn.net/mr253727942/article/details/50813283

 - 为什么使用Btree而不是普通的二叉排序树
 
 因为Btree的深度更浅，单次数据的查找更快。减少了磁盘的IO。

 - 为什么使用B+tree而不是Btree
 - B-tree索引存储的是key-data形式，而B+tree存储的key形式，没有data。 

1.B+-tree内部节点没有存储具体data，所以一个盘块中可以存储更多的指针，依次指向子节点。把同一节点的data放在同一盘块中，能降低IO读写次数。

2.B+-tree查询效率更加稳定，由于任何关键字查找必须走从根节点到叶子节点，效率会稳定。

3.B+-tree的叶子节点是链表有序，在做范围查询的时候速度非常快。 例如上图中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点就可以。

- **B+Tree树深度解析**

https://blog.csdn.net/qq_21993785/article/details/80576642

InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为〖10〗^3）。也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿 条记录。

实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2至4层。mysql的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。


## String类的hashcode()是怎么实现的？
先上JDK8的源码：
```java
   /**
     * Returns a hash code for this string. The hash code for a
     * {@code String} object is computed as
     * <blockquote><pre>
     * s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]
     * </pre></blockquote>
     * using {@code int} arithmetic, where {@code s[i]} is the
     * <i>i</i>th character of the string, {@code n} is the length of
     * the string, and {@code ^} indicates exponentiation.
     * (The hash value of the empty string is zero.)
     *
     * @return  a hash code value for this object.
     */
    public int hashCode() {
        int h = hash;
        if (h == 0 && value.length > 0) {
            char val[] = value;

            for (int i = 0; i < value.length; i++) {
                h = 31 * h + val[i];
            }
            hash = h;
        }
        return h;
    }
```
其实计算公式就是：
s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]
至于为什么选31呢？
是因为：
31可以表示成11111，If it were even and the multiplication overflowed, information would be lost, as multiplication by 2 is equivalent to shifting。
另外一个原因是： 31的乘法可以由i*31== (i<<5)-i来表示（也就是32×i-i），现在很多虚拟机里面都有做相关优化，使用31的原因可能是为了更好的分配hash地址，并且31只占用5bits！

## spring的AOP使用了什么设计模式

spring的AOP使用了代理模式和策略模式（策略是指使用JDK动态代理还是CGlib）。

## spring的filter使用了什么设计模式
- http://www.flyne.org/article/693
使用的是责任链设计模式。

## drools中的有状态session和无状态的session

 - 无状态的session（stateless Kie Session）

可以理解成一个函数。但是又有一些细微的差别，它的输入参数的限定比较宽松，多次调用session产生的结果之间相互不会影响。
其实，StatelessKieSession是StatefulKieSession的子类。无状态session规则的匹配通过execute()一个函数就可以实现。技术上来说，无状态的session完全可以使用有状态的session来进行替代。但是无状态session更加强调规则的匹配是one-shot evaluation。
无状态session适合于**数据验证，计算（比如风险评估、按揭利率）、数据过滤、消息路由**等。
无状态session不需要进行dispose。after  each invocation of any of the execute() methods，the resources used for thr executtion are freed。 at this point，the same stateless kie session is ready for another execution round if required。each executio() invocation will then be independent。

 - 有状态session（stateful Kie Session）
drools默认的session类型就是有状态的。有状态session与无状态session的一个显著区别就是，我们不用等到全部输入参数到达才进行规则匹配，可以在一部分参数到达以后就进行计算，另外一部分参数到达以后继续进行运算，两次运算看成实在一个session中完成的，相互之间具有关联关系。
有状态session使用完成以后必须进行释放。
有状态session的运算需要先使用insert函数插入fact，然后调用fireAllRules方法进行规则运算。

## nginx负载均衡
- http://blog.csdn.net/tjcyjd/article/details/50695922

nginx负载均衡有5种配置方式：

 1. 轮询（默认）
 
 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
 
 2. weight
 
指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
例如：
```shell
upstream bakend {
server 192.168.0.14 weight=10;
server 192.168.0.15 weight=90;
}
```

 3. ip_hash
 
每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
例如：
```shell
upstream bakend {
ip_hash;
server 192.168.0.14:88;
server 192.168.0.15:80;
}
```

 4. url_hash（第三方）
 
 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
 例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法
```shell
upstream backend {
server squid1:3128;
server squid2:3128;
hash $request_uri;
hash_method crc32;
}
```

 5. fair（第三方）
 
按后端服务器的响应时间来分配请求，响应时间短的优先分配。
```shell
upstream backend {
server server1;
server server2;
fair;
}
```

## Java锁的类型

### 公平锁/非公平锁
 公平锁是指多个线程按照申请锁的顺序来获取锁。
 
 非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。
 
 对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。
 
对于Synchronized而言，也是一种非公平锁，由于其并不像ReentrantLock是通过AQS（AbstractQueuedSynchronized）的来实现线程调度，所以并没有任何办法使其变成公平锁。
### 可重入锁
 可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。说的有点抽象，下面会有一个代码的示例。
 对于Java ReentrantLock而言, 他的名字就可以看出是一个可重入锁，其名字是Re entrant Lock重新进入锁。

对于Synchronized而言,也是一个可重入锁。可重入锁的一个好处是可一定程度避免死锁。
```java
synchronized void setA() throws Exception{
    Thread.sleep(1000);
    setB();
}

synchronized void setB() throws Exception{
    Thread.sleep(1000);
}
```
上面的代码就是一个可重入锁的一个特点，如果不是可重入锁的话，setB可能不会被当前线程执行，可能造成死锁。
### 独享锁/共享锁
 独享锁是指该锁一次只能被一个线程所持有。
 
共享锁是指该锁可被多个线程所持有。

对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。
读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。
独享锁与共享锁也是通过AQS（AbstractQueuedSynchronized）来实现的，通过实现不同的方法，来实现独享或者共享。
对于Synchronized而言，当然是独享锁。
### 互斥锁/读写锁
 上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。
互斥锁在Java中的具体实现就是ReentrantLock

读写锁在Java中的具体实现就是ReadWriteLock
### 乐观锁/悲观锁
 乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。
悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。

乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。

从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。

悲观锁在Java中的使用，就是利用各种锁。

乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。
### 分段锁
 分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。
 
我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。
当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。
但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。

分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。
### 自旋锁
 在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。

  

## java实现冒泡排序和快速排序
```java
package com.audi.mySort;

public class Sort
{
	public static void bubbleSort(int a[])
	{
		if (a == null|| a.length==0 ||a.length==1)
		{
			return;
		}
		int temp=0;
		for (int i = 0; i < a.length-1; i++)
		{
			for (int j = 0; j < a.length-i-1; j++)
			{
				if (a[j]>a[j+1])
				{
					temp=a[j];
					a[j]=a[j+1];
					a[j+1]=temp;
				}
			}
		}
	}

	//看不懂的时候看一下这个http://developer.51cto.com/art/201403/430986.htm
	public static void quickSort(int a[],int low,int high)
	{
		if (a==null|| a.length==0 ||a.length==1)
		{
			return;
		}
		int i,j,pivoit,temp;
		if (low<high)
		{
			pivoit = a[low];
			i=low;
			j=high;
			while(i<j)
			{
				while(i<j&&a[j]>=pivoit)
					j--;
				while(i<j&&a[i]<=pivoit)
					i++;
				if (i<j)
				{
					temp=a[i];
					a[i]=a[j];
					a[j]=temp;
				}
			}
			a[low]=a[i];
			a[i]=pivoit;
			quickSort(a, low, i-1);
			quickSort(a, i+1, high);
		}
	}
	
	public static void main(String[] args)
	{
		int a[]= {1,34,0,21,342,2,90};
		System.out.println("冒泡排序：");
		Sort.bubbleSort(a);
		for(int i:a)
		{
			System.out.println(i);
		}
		int b[]= {1,34,0,21,342,2,90};
		System.out.println("快速排序：");
		Sort.quickSort(b, 0, b.length-1);
		for(int i:b)
		{
			System.out.println(i);
		}
	}
}

```
为什么快速排序都要先从右边开始？
参考链接http://blog.csdn.net/w282529350/article/details/50982650
考虑数组6 1 2 7 9
6在左，9在右  我们将6作为基数。
假设从左边开始（与正确程序正好相反）
于是i 就会移动到现在的 数字 7 那个位置停下来，而  j 原来在 数字 9 那个位置 ，因为
while(arr[j]>=temp&&i<j)
于是，j 也会停留在数字7 那个位置，于是问题来了。当你最后交换基数6与7时，不对呀！！。
问题在于当我们先从在边开始时，那么 i 所停留的那个位置肯定是大于基数6的，而在上述例子中，为了满足 i<j 于是 j也停留在7的位置
但最后交换回去的时候，7就到了左边，不行，因为我们原本 交换后数字6在边应该是全部小于6，右边全部大于6.但现在不行了。
于是，我们必须从右边开始，也就是从基数的对面开始。

## java中基本类型变量存在哪里
- https://www.cnblogs.com/panxuejun/p/5970739.html

基本数据类型是放在栈中还是放在堆中，这取决于基本类型声明的位置。

 

 一：在方法中声明的变量，即该变量是局部变量，每当程序调用方法时，系统都会为该方法建立一个方法栈，其所在方法中声明的变量就放在方法栈中，当方法结束系统会释放方法栈，其对应在该方法中声明的变量随着栈的销毁而结束，这就局部变量只能在方法中有效的原因

      在方法中声明的变量可以是基本类型的变量，也可以是引用类型的变量。

         （1）当声明是基本类型的变量的时，其变量名及值（变量名及值是两个概念）是放在方法栈中

         （2）当声明的是引用变量时，所声明的变量（该变量实际上是在方法中存储的是内存地址值）是放在方法的栈中，该变量所指向的对象是放在堆类存中的。

   二：在类中声明的变量是成员变量，也叫全局变量，放在堆中的（因为全局变量不会随着某个方法执行结束而销毁）。

       同样在类中声明的变量即可是基本类型的变量 也可是引用类型的变量

       （1）当声明的是基本类型的变量其变量名及其值放在堆内存中的

       （2）引用类型时，其声明的变量仍然会存储一个内存地址值，该内存地址值指向所引用的对象。引用变量名和对应的对象仍然存储在相应的堆中
## 在JVM中，主内存究竟在哪里

虚拟机栈是为每个线程分配的，堆是公用的。
多线程的时候，并发引起的问题就是线程从主内存读取数据自己做一个copy，以后操作的都是这个copy，操作完以后才会写会主内存。
那么这个主内存是否可以认为是堆里保存的数据，而线程copy以后的数据是保存在线程自己的虚拟机栈里呢？

个人理解2017年12月7日10:57:20
所谓主内存  只是对于线程来说的
至于主内存可以是堆、方法区
主内存是堆：类中声明的属性，多线程时，主内存就是堆
主内存是方法区：类的string属性，多线程时，主内存就是方法区
![主内存和工作内存][20]


  

## CMS和G1
- http://blog.csdn.net/linhu007/article/details/48897597
- http://www.linuxidc.com/Linux/2015-01/112092.htm

并行：并行, 多个线程各做各的事情(互相间无共享状态)

并发：并发, 多个线程协同做同一件事情(有状态)

 1. CMS收集器

 CMS(Concurrent Mark Sweep)并发收集器是一种以获取最短回收停顿时间为目标的收集器。基于“标记-清除”算法实现，它的运作过程如下（具体分为6个步骤）：
 
初始标记（CMS initial mark）

并发标记（CMS concurrent mark）

并发预清理（CMS-concurrent-preclean）

重新标记（CMS remark）

并发清除（CMS concurrent sweep）

并发重置（CMS-concurrent-reset）

| 阶段        | 具体做了什么   | 
| --------   | :-----  | 
| 初始标记     |标记从GC root直接可达的对象  需要STW|
| 并发标记        |标记所有可GC root tracing的对象|
| 并发预清理        |标记从新生代晋升的对象、新分配到老年代的对象以及在并发阶段被修改了的对象|
| 重新标记        |暂停所有用户线程，重新扫描堆中的对象，进行可达性分析,标记活着的对象   需要STW|
| 并发清理        | 用户线程被重新激活，同时清理那些无效的对象 |
| 并发预清理重置        |    CMS清除内部状态，为下次回收做准备 |

示例代码：
```java
package hello;

import java.util.ArrayList;

import java.util.List;

/**
 * 
 * 简单的JAVA虚拟机内存回收,cms收集器的使用
 * 
 * 参数：-Xms30m -Xmx60m-Xmn10m -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails
 * 
 * @author 范芳铭
 */

public class EasyCMS
{

	public byte[] placeHolder = new byte[64 * 1024]; // 占位符

	public static void main(String[] args) throws Exception
	{
		outOfMemoryByExpansionSize();
	}

	private static void outOfMemoryByExpansionSize() throws Exception
	{
		List<EasyCMS> list = new ArrayList<EasyCMS>();
		while (true)
		{
			EasyCMS serial = new EasyCMS();
			list.add(serial);
			System.out.println("=========="+System.currentTimeMillis());
			Thread.sleep(10);// 停顿10毫秒
		}
	}
}

```
其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。其他动作都是并发的。

 1、 G1收集器
参考文档：http://blog.csdn.net/renfufei/article/details/41897113
G1 (Garbage-First)是一款**面向服务器**的垃圾收集器,主要针对配备**多颗处理器**及**大容量内存**的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征. 在Oracle JDK 7 update 4 及以上版本中得到完全支持, 专为以下应用程序设计:
 - 可以像CMS收集器一样,GC操作与应用的线程一起并发执行
 - 紧凑的空闲内存区间且没有很长的GC停顿时间.
 - 需要可预测的GC暂停耗时.
 - 不想牺牲太多吞吐量性能.
 - 启动后不需要请求更大的Java堆.
G1的长期目标是取代CMS(Concurrent Mark-Sweep Collector, 并发标记-清除). 因为特性的不同使G1成为比CMS更好的解决方案. 一个区别是,G1是一款压缩型的收集器.G1通过有效的压缩完全避免了对细微空闲内存空间的分配,不用依赖于regions，这不仅大大简化了收集器，而且还消除了潜在的内存碎片问题。除压缩以外，G1的垃圾收集停顿也比CMS容易估计，也允许用户自定义所希望的停顿参数(pause targets)

 更详细的可以参见https://github.com/AudiVehicle/learn/blob/master/source/G1/G1.md
 
转自https://github.com/cncounter/translation/blob/master/tiemao_2014/G1/G1.md
 
 https://tech.meituan.com/2016/09/23/g1.html
 
G1提供了两种GC模式，Young GC和Mixed GC，两种都是完全Stop The World的。 

* Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。 

* Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。

由上面的描述可知，Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。

上文中，多次提到了global concurrent marking，它的执行过程类似CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为四个步骤：

* 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。 
* 并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。 
* 最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。 
* 清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。

第一阶段initial mark是共用了Young GC的暂停，这是因为他们可以复用root scan操作，所以可以说global concurrent marking是伴随Young GC而发生的。第四阶段Cleanup只是回收了没有存活对象的Region，所以它并不需要STW。

Young GC发生的时机大家都知道，那什么时候发生Mixed GC呢？其实是由一些参数控制着的，另外也控制着哪些老年代Region会被选入CSet。 

* G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。 
* G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下，才会被选入CSet。 
* G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。 
* G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。

https://crowhawk.github.io/2017/08/15/jvm_3/

| 收集器        | 串行、并行or并发   |  新生代/老年代  |算法|目标|适用场景|
| --------   | :-----  | :----  | :----  | :----  | :----  |
|Serial|	串行|	新生代|	复制算法|	响应速度优先|	单CPU环境下的Client模式|
|Serial Old|	串行|	老年代|	标记-整理|	响应速度优先|	单CPU环境下的Client模式、CMS的后备预案|
|ParNew|	并行	|新生代	|复制算法	|响应速度优先	|多CPU环境时在Server模式下与CMS配合|
|Parallel Scavenge|	并行|	新生代|	复制算法|	吞吐量优先|	在后台运算而不需要太多交互的任务|
|Parallel Old|	并行|	老年代|	标记-整理|	吞吐量优先|	在后台运算而不需要太多交互的任务|
|CMS|	并发	|老年代|	标记-清除|	响应速度优先|	集中在互联网站或B/S系统服务端上的Java应用|
|G1|	并发	|both	|标记-整理+复制算法	|响应速度优先	|面向服务端应用，将来替换CMS|


## jdk1.8舍去了永久区
- https://www.cnblogs.com/paddix/p/5309550.html
- https://www.cnblogs.com/hadoop-dev/p/7169252.html

一般，我们说常量池存在方法区，方法区又存在永久区（Perm Space）（方法区是虚拟机规范，永久区是虚拟机的规范的具体实现，要区分开，不能说方法区就是永久区）。但是这是有条件的，条件就是：

 - JDK版本必须要在1.6及更低版本。
 
 - 针对HotSpot虚拟机而言，因为其他虚拟机没有永久区的概念。

从JDK1.7开始，就已经提出了要将perm去掉的想法，只是没有**完全**实现。之所以说没有完全实现，是因为perm在JDK1.7并没有被去除，但是JDK1.7及之后版本的JVM已经将运行时常量池从方法区中移了出来，在Java 堆（Heap）中开辟了一块区域存放运行时常量池（对于这段话的java代码验证可以参考https://www.cnblogs.com/paddix/p/5309550.html）。
JDK1.8已经完全抛弃了perm区，取而代之的是元数据区，且存在虚拟机之外的本地内存上，如下图所示：
![此处输入图片的描述][21]


## String.intern方法
String.intern()是一个Native方法，它的作用是：

 - JDK1.6：如果运行时常量池中已经包含一个等于此String对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此String内容相同的字符串，并返回常量池中创建的字符串的引用。
 
 - JDK1.7:当常量池中没有该字符串时，JDK7的intern（）方法的实现不再是在常量池中创建与此String内容相同的字符串，而改为在常量池中记录java Heap中首次出现的该字符串的引用，并返回该引用。
 

## java的finalize方法
- http://blog.csdn.net/pi9nc/article/details/12374049

finalize()方法属于Object类的一个protected方法，源码如下：
```java
   /**
     * Called by the garbage collector on an object when garbage collection
     * determines that there are no more references to the object.
     * A subclass overrides the {@code finalize} method to dispose of
     * system resources or to perform other cleanup.
     * <p>
     * The general contract of {@code finalize} is that it is invoked
     * if and when the Java&trade; virtual
     * machine has determined that there is no longer any
     * means by which this object can be accessed by any thread that has
     * not yet died, except as a result of an action taken by the
     * finalization of some other object or class which is ready to be
     * finalized. The {@code finalize} method may take any action, including
     * making this object available again to other threads; the usual purpose
     * of {@code finalize}, however, is to perform cleanup actions before
     * the object is irrevocably discarded. For example, the finalize method
     * for an object that represents an input/output connection might perform
     * explicit I/O transactions to break the connection before the object is
     * permanently discarded.
     * <p>
     * The {@code finalize} method of class {@code Object} performs no
     * special action; it simply returns normally. Subclasses of
     * {@code Object} may override this definition.
     * <p>
     * The Java programming language does not guarantee which thread will
     * invoke the {@code finalize} method for any given object. It is
     * guaranteed, however, that the thread that invokes finalize will not
     * be holding any user-visible synchronization locks when finalize is
     * invoked. If an uncaught exception is thrown by the finalize method,
     * the exception is ignored and finalization of that object terminates.
     * <p>
     * After the {@code finalize} method has been invoked for an object, no
     * further action is taken until the Java virtual machine has again
     * determined that there is no longer any means by which this object can
     * be accessed by any thread that has not yet died, including possible
     * actions by other objects or classes which are ready to be finalized,
     * at which point the object may be discarded.
     * <p>
     * The {@code finalize} method is never invoked more than once by a Java
     * virtual machine for any given object.
     * <p>
     * Any exception thrown by the {@code finalize} method causes
     * the finalization of this object to be halted, but is otherwise
     * ignored.
     *
     * @throws Throwable the {@code Exception} raised by this method
     * @see java.lang.ref.WeakReference
     * @see java.lang.ref.PhantomReference
     * @jls 12.6 Finalization of Class Instances
     */
    protected void finalize() throws Throwable { }
```
大致完成的功能是，在一个对象被虚拟机确认为不可达状态以后，**可能**会执行这个对象的finalize方法来进行一些资源的回收甚至对象的复活工作。
方法声明为protected类型的，是防止在该类之外定义的代码访问finalize()方法。

## self-introduction

Hello, my name is Wang Quanzhou.
Previously, I have done several projects about java web development, like loan mortgage and commission settlement system development. The main skill we use are java, spring, oracle, mybatis. Except these, I love sports, such as ridding and fitness. 
Give me a chance, I will give you the surprise.
Thank you.

## Java中的Error能不能被Catch
Error是一个**类**，它的父类（**注意**，是个类，不是接口）是Throwable，它的兄弟**类**是Exception，如下图所示：
![此处输入图片的描述][22]


  那么error到底可不可以被catch呢？
  参考http://blog.csdn.net/sunshinestation/article/details/4169763，实验结果表明是可以被catch的。
```java
package com.audi;

public class ExceptionDemo
{
	/**
	 * @param args
	 */
	public static void main(String[] args)
	{
		try
		{
			throw new MyError("My Error");
		} catch (MyError e)
		{
			System.out.println("Catch Error");
			System.out.println(e.getMessage());
		}
	}
}

class MyError extends Error
{

	private static final long serialVersionUID = 1L;

	public MyError()
	{
		super();
	}

	public MyError(String message, Throwable cause)
	{
		super(message, cause);
	}

	public MyError(String message)
	{
		super(message);
	}

	public MyError(Throwable cause)
	{
		super(cause);
	}

}
```
运行结果：
![此处输入图片的描述][23]

## Hbase

- https://www.jianshu.com/p/b23800d9b227



### HBase中WAL(Write-Ahead-Log)
- http://blog.csdn.net/u010916254/article/details/48025445
- http://blog.csdn.net/zdc524/article/details/49994589

通俗的讲：WAL就是在数据写入数据库的时候，先将数据的日志写入磁盘文件，再将数据写入实际的数据库表。（例如HBase、postgresql等支持WAL）


## hadoop简介

Hadoop核心项目:

　　　　HDFS:Hadoop Distributed File System分布式文件系统,用来管理文件的.在hdfs上存储的数据是分散很多服务器之上的,但是用户感觉不到,文件真的分布在很多台机器上,就像一台机器上似的.

　　　　MapReduce:分布式并行计算框架.实现的是分布式计算,大数据分布在很多台服务器上,需要它去并行地去执行

　　　　Map:在每个分散的机器上进行计算的那部分.Reduce:主要做最后的一个汇总

 - HDFS架构:
 hdfs和MapReduce都是主从结构.管理与被管理这种关系,分为管理者和被管理者.被管理者通常做具体的事物的,管理者通常是组织,协调,管理工作的.

　　　　　　节点:网络环境中的每一台服务器.

　　　　主节点:只有一个**NameNode**,负责各个节点数据的组织管理,

　　　　从节点:有很多个**DataNode**,负责存储数据,数据节点

　　　　　NameNode对外,DataNode对内,NameNode接收用户的操作请求,NameNode负责协调管理,不是真正的存放数据,会把数据分散到各个节点上去存储

　　海量数据是单节点处理不了的,所以我们的数据需要存放在多台服务器上,作为管理的NamNode知道数据具体存放在DataNode的哪些节点上面
　　
　　

 - NameNode如何知道数据存放在DataNode节点的位置的呢?
 NameNode对外暴露的就是目录的文件系统

　　　　用户要进行hdfs操作的时候,首先和NameNode打交道,NameNode上边有一个文件系统的目录结构,用户通过看文件系统的目录结构,就知道我们的数据是存放在那个路径下面,文件叫什么名字,文件的路径,文件有多大,我们的数据具体存放在那些节点上,客户是不需要关心的

　　　　NamNode负责:接收用户操作请求,是用户操作的入口.维护文件系统的目录结构,称作命名空间.

　　　　DataNode负责:存储文件数据，dataNode的数据一般都会做冗余，一般冗余为3，即除了自己以外，在同集群还有一个副本DataNode，在另外的集群还有一个副本DataNode。

 - MapReduce架构:
 主节点执行一个管理者的角色,从节点执行一个被管理者的角色.管理和被管理完成数据的一个计算(任何对数据的处理都叫做计算,查询,过滤,数据的检索..利用cpu和内存进行数据处理).

　　　　主节点只有一个:JobTracker,

　　　　把我们用户的操作请求,拿过来,分发给TaskTracker,接收用户提交的计算任务,把计算任务分配到TaskTracker去执行,监控TaskTracker的执行情况

　　　　从节点有很多个:TaskTracker,

　　　　是我们自己安装部署的,通常TaskTracker和DataNode,执行用户的操作,运行时根据TaskTracker上DataNode的数据只执行一部分,执行程序时,去找DataNode本地的数据,然后加载DataNode上边的数据,去运行

　　　　MapReduce进行计算时,处理的数据就是用户提交的这些数据

　　　　TaskTracker通过反射将我们的程序读进内存中,然后在jvm中运行,程序在含有数据的DataNode的节点上运行

　　　　TaskTracker负责用户提交的计算任务

　　　　节点的数量越多,整体的计算时间越短,JobTracker管理执行任务的TaskTracker

　　　　NameNode和DataNode负责完成数据存储

　　　　JobTracker和TaskTracker完成数据的计算

　　　　NameNode和JobTracker不一定非要在同一台机器上,在生产中,通常是分开的,因为用户的请求,NameNode也接收,JobTracker也接收,为了防止NameNode操作慢,所以NameNode　　最好是一台机器,充分利用cpu和内存,JobTracker也是一台机器,都是独立的

　　　　**DataNode和TaskTracker通常是同一台机器**,是因为TaskTracker在运行的时候,可以执行本地的数据,如果不在一起,就要经过网络传播(网络一不稳定,二耗时) DataNode只管理本地,　　不管理远程

　　　　JobTracker和TaskTracker不从HDFS上读数据一样可以去做事情

　　　　用户存储数据首先和NameNode打交道,用户的数据直接和DataNode打交道,绕过了NameNode,就是说用户在进行存储的时候,去问NameNode我要去哪里读写数据,一旦用户知道了,　　就没有NameNode的事了,直接去DataNode那去处理了.假设用户处理数据一定经过NameNode,那么两三个用户上来之后,NameNode内存几乎全爆了,因为是海量数据,内存肯定是装不下　　的.只是向NameNode申请block块和blockId

　　　　架构的设计是让数据传输的时候不经过NameNode,所以架构没有瓶颈

## storm简介

Storm是一个分布式的、高容错的实时计算系统。
Storm对于实时计算的的意义相当于Hadoop对于批处理的意义。Hadoop为我们提供了Map和Reduce原语，使我们对数据进行批处理变的非常的简单和优美。同样，Storm也对数据的实时计算提供了简单Spout和Bolt原语。
Storm适用的场景：
1、流数据处理：Storm可以用来用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。
2、分布式RPC：由于Storm的处理组件都是分布式的，而且处理延迟都极低，所以可以Storm可以做为一个通用的分布式RPC框架来使用。
在这个教程里面我们将学习如何创建Topologies, 并且把topologies部署到storm的集群里面去。Java将是我们主要的示范语言， 个别例子会使用python以演示storm的多语言特性。

 - 一个Storm集群的基本组件
 storm的集群表面上看和hadoop的集群非常像。但是在Hadoop上面你运行的是MapReduce的Job, 而在Storm上面你运行的是Topology。它们是非常不一样的 — 一个关键的区别是： 一个MapReduce Job最终会结束， 而一个Topology运永远运行（除非你显式的杀掉他）。
在Storm的集群里面有两种节点： 控制节点(master node)和工作节点(worker node)。控制节点上面运行一个后台程序：Nimbus， 它的作用类似Hadoop里面的JobTracker。Nimbus负责在集群里面分布代码，分配工作给机器， 并且监控状态。
每一个工作节点上面运行一个叫做Supervisor的节点（类似 TaskTracker）。Supervisor会监听分配给它那台机器的工作，根据需要 启动/关闭工作进程。每一个工作进程执行一个Topology（类似 Job）的一个子集；一个运行的Topology由运行在很多机器上的很多工作进程 Worker（类似 Child）组成。

![此处输入图片的描述][24]


  ![此处输入图片的描述][25]


## 分布式事务一致性
- https://www.cnblogs.com/dinglang/p/5679542.html
- http://blog.csdn.net/zheng0518/article/details/51194942

分布式系统中进行事务一致性控制，其实是比较难以实现的。根据CAP（consistency，available，partition tolerance）理论，三者同时满足是不可能的。

 - 强一致性：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据CAP 理论，这种实现需要牺牲可用性。
 - 弱一致性：系统并不保证续进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。
 - 最终一致性：弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS
   是一个典型的最终一致性系统。

在互联网领域的绝大多数的场景，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。

要实现分布式系统的事务一致性，有一下一些方法：

 1. 串行化
 业务整合方案主要采用将接口整合到本地执行的方法。拿问题场景来说，则可以将服务 A、B、C 整合为一个服务 D 给业务，这个服务 D 再通过转换为本地事务的方式，比如服务 D 包含本地服务和服务 E，而服务 E 是本地服务 A ~ C 的整合。
优点：解决（规避）了分布式事务。
缺点：显而易见，把本来规划拆分好的业务，又耦合到了一起，业务职责不清晰，不利于维护。
由于这个方法存在明显缺点，通常不建议使用。
 2. 本地消息表
这种实现方式的思路，其实是源于ebay，后来通过支付宝等公司的布道，在业内广泛使用。其基本的设计思想是将远程分布式事务拆分成一系列的本地事务。如果不考虑性能及设计优雅，借助关系型数据库中的表即可实现。

举个经典的**跨行转账**的例子来描述。

第一步伪代码如下，扣款1W，通过本地事务保证了凭证消息插入到消息表中。
![此处输入图片的描述][26]


  第二步，通知对方银行账户上加1W了。那问题来了，如何通知到对方呢？

通常采用两种方式：

采用时效性高的MQ，由对方订阅消息并监听，有消息时自动触发事件
采用定时轮询扫描的方式，去检查消息表的数据。
两种方式其实各有利弊，仅仅依靠MQ，可能会出现通知失败的问题。而过于频繁的定时轮询，效率也不是最佳的（90%是无用功）。所以，我们一般会把两种方式结合起来使用。

解决了通知的问题，又有新的问题了。万一这消息有重复被消费，往用户帐号上多加了钱，那岂不是后果很严重？

仔细思考，其实我们可以消息消费方，也通过一个“消费状态表”来记录消费状态。在执行“加款”操作之前，检测下该消息（提供标识）是否已经消费过，消费完成后，通过本地事务控制来更新这个“消费状态表”。这样子就避免重复消费的问题。

总结：上诉的方式是一种非常经典的实现，基本避免了分布式事务，实现了“最终一致性”。但是，关系型数据库的吞吐量和性能方面存在瓶颈（因为本地消息表和消费消息表是数据库表，oracle或者mysql的表），频繁的读写消息会给数据库造成压力。所以，在真正的高并发场景下，该方案也会有瓶颈和限制的。

 1. MQ（非事务消息）
 所谓**非事务**，就是说，消息的生产者和消费者是不具备事务关系，即消费者执行失败时，生产者是不会产生回滚的。
 通常情况下，在使用非事务消息支持的MQ产品时，我们很难将业务操作与对MQ的操作放在一个本地事务域中管理。通俗点描述，还是以上述提到的“跨行转账”为例，我们很难保证在扣款完成之后对MQ投递消息的操作就一定能成功。这样一致性似乎很难保证。

先从消息生产者这端来分析，请看伪代码：

![此处输入图片的描述][27]


  根据上述代码及注释，我们来分析下可能的情况：

1、操作数据库成功，向MQ中投递消息也成功，皆大欢喜
2、操作数据库失败，不会向MQ中投递消息了
3、操作数据库成功，但是向MQ中投递消息时失败，向外抛出了异常，刚刚执行的更新数据库的操作将被回滚
从上面分析的几种情况来看，貌似问题都不大的。那么我们来分析下消费者端面临的问题：

消息出列后，消费者对应的业务操作要执行成功。如果业务执行失败，消息不能失效或者丢失。需要保证消息与业务操作一致
尽量避免消息重复消费。如果重复消费，也不能因此影响业务结果
如何保证消息与业务操作一致，不丢失？

主流的MQ产品都具有持久化消息的功能。如果消费者宕机或者消费失败，都可以执行重试机制的（有些MQ可以自定义重试次数）。

如何避免消息被重复消费造成的问题？

保证消费者调用业务的服务接口的幂等性
通过消费日志或者类似状态表来记录消费状态，便于判断（建议在业务上自行实现，而不依赖MQ产品提供该特性）
 

总结：这种方式比较常见，性能和吞吐量是优于使用关系型数据库消息表的方案。如果MQ自身和业务都具有高可用性，理论上是可以满足大部分的业务场景的。不过在没有充分测试的情况下，不建议在交易业务中直接使用。

 1. MQ（事务消息）
 举个例子，Bob向Smith转账，那我们到底是先发送消息，还是先执行扣款操作？

好像都可能会出问题。如果先发消息，扣款操作失败，那么Smith的账户里面会多出一笔钱。反过来，如果先执行扣款操作，后发送消息，那有可能扣款成功了但是消息没发出去，Smith收不到钱。除了上面介绍的通过异常捕获和回滚的方式外，还有没有其他的思路呢？

下面以阿里巴巴的RocketMQ中间件为例，分析下其设计和实现思路。

RocketMQ第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。细心的读者可能又发现问题了，如果确认消息发送失败了怎么办？RocketMQ会定期扫描消息集群中的事物消息，这时候发现了Prepared消息，它会向消息发送者确认，Bob的钱到底是减了还是没减呢？如果减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。如下图：、

![此处输入图片的描述][28]


  总结：据笔者的了解，各大知名的电商平台和互联网公司，几乎都是采用类似的设计思路来实现“最终一致性”的。这种方式适合的业务场景广泛，而且比较可靠。不过这种方式技术实现的难度比较大。目前主流的开源MQ（ActiveMQ、RabbitMQ、Kafka）均未实现对事务消息的支持，所以需二次开发或者新造轮子。比较遗憾的是，RocketMQ事务消息部分的代码也并未开源，需要自己去实现。
  
  
http://blog.jobbole.com/95632/

 - 两阶段提交协议
所谓两阶段，就是**准备阶段**和**执行阶段**。该协议一般有协调者和参与者两个角色。
准备阶段：
事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。
提交阶段：
如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)
当协调者节点从所有参与者节点获得的相应消息都为”同意”时:

![此处输入图片的描述][29]


如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：

![此处输入图片的描述][30]

二阶段提交协议有如下一些缺点：
>1、同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。

>2、单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

>3、数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。

>4、二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

 - 三阶段提交协议

三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。
与两阶段提交不同的是，三阶段提交有两个改动点:
>1、引入超时机制。同时在协调者和参与者中都引入超时机制。

>2、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。
也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。

在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者abort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。）

 - 2PC与3PC的区别
 
 相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制**也会导致数据一致性问题**，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。


## 分布式锁
- http://blog.csdn.net/zxp_cpinfo/article/details/53692922

目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式的CAP理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。

在很多场景中，我们为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，Java中其实提供了很多并发处理相关的API，但是这些API在分布式场景中就无能为力了。也就是说单纯的Java Api并不能提供分布式锁的能力。所以针对分布式锁的实现目前有多种方案。
针对分布式锁的实现，目前比较常用的有以下几种方案：

 - 基于数据库实现分布式锁
 - 基于缓存（redis，memcached，tair）实现分布式锁
 - 基于Zookeeper实现分布式锁
 在分析这几种实现方案之前我们先来想一下，我们需要的分布式锁应该是怎么样的？（这里以方法锁为例，资源锁同理）
 是这样的：
 可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。
这把锁要是一把可重入锁（避免死锁）
这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）
有高可用的获取锁和释放锁功能
获取锁和释放锁的性能要好


**方案一**：基于数据库实现分布式锁
基于数据库表

要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。

当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。
创建这样一张数据库表：
```sql
CREATE TABLE `methodLock` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名',
  `desc` varchar(1024) NOT NULL DEFAULT '备注信息',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法';
```
当我们想要锁住某个方法时，执行以下SQL：
```sql
insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)
```
因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。

当方法执行完毕之后，想要释放锁的话，需要执行以下Sql:
```sql
delete from methodLock where method_name ='method_name'
```
>上面这种简单的实现有以下几个问题：
1、这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。
2、这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。
3、这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。
4、这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。

**方案二**：基于数据库排他锁
除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。

我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作：
```java
public boolean lock(){
    connection.setAutoCommit(false)
    while(true){
        try{
            result = select * from methodLock where method_name=xxx for update;
            if(result！=null){
                return true;
            }
        }catch(Exception e){

        }
        sleep(1000);
    }
    return false;
}
```
在查询语句后面增加**for update**，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，**只有通过索引进行检索的时候才会使用行级锁**，否则会使用表级锁。这里**我们希望使用行级锁，就要给method_name添加索引**，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。

我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：
```java
public void unlock(){
    connection.commit();
}
```
**方案三**：基于Zookeeper实现分布式锁
基于zookeeper临时有序节点可以实现的分布式锁。

大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。
获取锁:
```java
public void lock(){
    path = 在父节点下创建临时顺序节点
    while(true){
        children = 获取父节点的所有节点
        if(path是children中的最小的){
            代表获取了节点
            return;
        }else{
            添加监控前一个节点是否存在的watcher
            wait();
        }
    }
}

watcher中的内容{
    notifyAll();
}
```
释放锁：
```java
public void release(){
    删除上述创建的节点
}
```
ZooKeeper版本的分布式锁问题相对比较来说少。

 - 锁的占用时间限制：
redis就有占用时间限制，而ZooKeeper则没有，最主要的原因是redis目前没有办法知道已经获取锁的客户端的状态，是已经挂了呢还是正在执行耗时较长的业务逻辑。而ZooKeeper通过临时节点就能清晰知道，如果临时节点存在说明还在执行业务逻辑，如果临时节点不存在说明已经执行完毕释放锁或者是挂了。由此看来redis如果能像ZooKeeper一样添加一些与客户端绑定的临时键，也是一大好事。
 - 是否单点故障：
redis本身有很多中玩法，如客户端一致性hash，服务器端sentinel方案或者cluster方案，很难做到一种分布式锁方式能应对所有这些方案。而ZooKeeper只有一种玩法，多台机器的节点数据是一致的，没有redis的那么多的麻烦因素要考虑。

总体上来说ZooKeeper实现分布式锁更加的简单，可靠性更高。

ZooKeeper实现分布式锁架构图：
![此处输入图片的描述][31]

其中，左边的整个区域表示一个Zookeeper集群，locker是Zookeeper的一个持久节点，node_1、node_2、node_3是locker这个持久节点下面的临时顺序节点。client_1、client_2、client_n表示多个客户端，Service表示需要互斥访问的共享资源。

客户端A要获取分布式锁的时候首先到locker下创建一个临时顺序节点（node_n），然后立即获取locker下的所有（一级）子节点。
此时因为会有多个客户端同一时间争取锁，因此locker下的子节点数量就会大于1。对于顺序节点，特点是节点名称后面自动有一个数字编号，
先创建的节点数字编号小于后创建的，因此可以将子节点按照节点名称后缀的数字顺序从小到大排序，这样排在第一位的就是最先创建的顺序节点，
此时它就代表了最先争取到锁的客户端！此时判断最小的这个节点是否为客户端A之前创建出来的node_n，如果是则表示客户端A获取到了锁，如果不是则表示锁已经被其它客户端获取，因此客户端A要等待它释放锁，也就是等待获取到锁的那个客户端B把自己创建的那个节点删除。
此时就通过监听比node_n次小的那个顺序节点的删除事件来知道客户端B是否已经释放了锁，如果是，此时客户端A再次获取locker下的所有子节点，
再次与自己创建的node_n节点对比，直到自己创建的node_n是locker的所有子节点中顺序号最小的，此时表示客户端A获取到了锁！

**方案四**：基于redis缓存实现分布式锁

首先是获取锁：
```java
public void lock(){
    for(){
        ret = setnx lock_ley (current_time + lock_timeout)
        if(ret){
            //获取到了锁
            break;
        }
        //没有获取到锁
        sleep(100);
    }
}
```
然后是释放锁：
```java
public void release(){
    del lock_ley
}
```
setnx来创建一个key，如果key不存在则创建成功返回1，如果key已经存在则返回0。依照上述来判定是否获取到了锁

获取到锁的执行业务逻辑，完毕后删除lock_key，来实现释放锁

其他未获取到锁的则进行**不断重试**，直到自己获取到了锁.

**方案五**：基于redis缓存实现分布式锁的改进版本
方案四在正常情况下是OK的，但是一旦获取到锁的客户端挂了，没有执行上述释放锁的操作，则其他客户端就无法获取到锁了，所以在这种情况下有2种方式来解决：

1、为lock_key设置一个过期时间
2、对lock_key的value进行判断是否过期
以第一种为例，在set键值的时候带上过期时间，即使挂了，也会在过期时间之后，其他客户端能够重新竞争获取锁
```java
public void lock(){
    while(true){
        ret = set lock_key identify_value nx ex lock_timeout
        if(ret){
            //获取到了锁
            return;
        }
        sleep(100);
    }
}

public void release(){
    value = get lock_key
    if(identify_value == value){
        del lock_key
    }
}
```
该方案的**缺点**是：过期时长不好设置，无法保证任务一定能在过期时间内完成。

**方案五**：实际项目中基于redis缓存实现分布式锁

我们项目中的做法是：首先获取task的下次执行时间，如果执行时间大于当前时间，那么久放弃争抢锁及后续的任务执行。否则开始争抢锁，如果获取锁成功，就开始执行任务，在任务执行完毕，在当前时间基础上加上固定的间隔，写入缓存作为下次任务执行的触发时间。上一段代码吧(其实，下面的代码最好是把设置下次任务执行时间的代码放在finally语句块中)：
```java
@Scheduled(fixedDelay = 1 * 60 * 1000)
    public void unfreezeSecurityPwd() {
        if (!enabled) {
            return;
        }

        //从redis上获取下次定时任务执行时间，如果为空，表示第一次执行。
        //如果不为空，如果当前时间小于下次定时任务执行时间，则不执行操作。
        String executeTime = stringRedisTemplate.opsForValue()
                .get("TaskMember.unfreezeSecurityPwd.executeTime");

        if (StringUtils.isNotEmpty(executeTime)
                && Long.parseLong(executeTime) > System.currentTimeMillis()) {
            return;
        }

        RLock lock = redisClient.getLock("TaskMember.unfreezeSecurityPwd");
        boolean isLocked = lock.tryLock();
        if (isLocked) {
            try {
                log.info("TaskMember memberTask unfreezeSecurityPwd begin...");
                memberSecurityPwdUnfreezeTask.execute();
                log.info("TaskMember memberTask unfreezeSecurityPwd end...");

                //在redis上写入下次执行的时间
                stringRedisTemplate.opsForValue()
                        .set("TaskMember.unfreezeSecurityPwd.executeTime",
                                String.valueOf(System.currentTimeMillis() + 5 * 60 * 1000));
            } finally {
                lock.unlock();
            }
        }
    }
```
该方案的有点是：可以有效避免方案四中的过期时间设置过短，导致锁提前释放的问题。

**方案六**：实际项目中基于redis缓存实现分布式锁

redis官方提供的red-lock方式：

大概意思就是，每次获取锁不是从一个redis服务器获取，而是从N个（官方建议大于4）redis服务器获取锁，如果成功获取锁的个数超过N/2+1个，那么就代表获取锁成功了，否则认为获取锁失败。获取的锁，同样需要设置过期时间，到时间自动解除锁定。

但是red-lock也会有问题：主要问题就在于这个过期时间，如果任务因为执行时间较长，或者遇到了full GC导致有效时间内没有执行完任务，那么另外一个线程也会获取锁，结果就是同一个任务，两个节点都在执行。


针对上面的**问题**，可以这么干（其实就是加了个版本号）：

为锁增加一个 token-fencing。

获取锁的时候，还需要获取一个递增的token，在上图中 Client 1 还获得了一个 token=33的 fencing。
发生了上文的 FGC 问题后，Client 获取了 token=34 的锁。
在提交数据的时候，需要判断token的大小，如果token 小于 上一次提交的 token 数据就会被拒绝。


## java移位运算符
java中有三种移位运算符

/<<      :     左移运算符，num << 1,相当于num乘以2

/>>      :     右移运算符，num >> 1,相当于num除以2

/>>>    :     无符号右移，忽略符号位，空位都以0补齐


## jsp的内置对象
- http://www.cnblogs.com/leirenyuan/p/6016063.html

JSP中一共预先定义了9个这样的对象，分别为：request、response、session、application、out、pagecontext、config、page、exception

1、request对象
request 对象是 javax.servlet.httpServletRequest类型的对象。 该对象代表了客户端的请求信息，主要用于接受通过HTTP协议传送到服务器的数据。（包括头信息、系统信息、请求方式以及请求参数等）。request对象的作用域为一次请求。

2、response对象
response 代表的是对客户端的响应，主要是将JSP容器处理过的对象传回到客户端。response对象也具有作用域，它只在JSP页面内有效。

3、session对象
session 对象是由服务器自动创建的与用户请求相关的对象。服务器为每个用户都生成一个session对象，用于保存该用户的信息，跟踪用户的操作状态。session对象内部使用Map类来保存数据，因此保存数据的格式为 “Key/value”。 session对象的value可以使复杂的对象类型，而不仅仅局限于字符串类型。

4、application对象
 application 对象可将信息保存在服务器中，直到服务器关闭，否则application对象中保存的信息会在整个应用中都有效。与session对象相比，application对象生命周期更长，类似于系统的“全局变量”。

5、out 对象
out 对象用于在Web浏览器内输出信息，并且管理应用服务器上的输出缓冲区。在使用 out 对象输出数据时，可以对数据缓冲区进行操作，及时清除缓冲区中的残余数据，为其他的输出让出缓冲空间。待数据输出完毕后，要及时关闭输出流。

6、pageContext 对象
pageContext 对象的作用是取得任何范围的参数，通过它可以获取 JSP页面的out、request、reponse、session、application 等对象。pageContext对象的创建和初始化都是由容器来完成的，在JSP页面中可以直接使用 pageContext对象。

7、config 对象
config 对象的主要作用是取得服务器的配置信息。通过 pageConext对象的 getServletConfig() 方法可以获取一个config对象。当一个Servlet 初始化时，容器把某些信息通过 config对象传递给这个 Servlet。 开发者可以在web.xml 文件中为应用程序环境中的Servlet程序和JSP页面提供初始化参数。

8、page 对象
page 对象代表JSP本身，只有在JSP页面内才是合法的。 page隐含对象本质上包含当前 Servlet接口引用的变量，类似于Java编程中的 this 指针。

9、exception 对象
exception 对象的作用是显示异常信息，只有在包含 isErrorPage="true" 的页面中才可以被使用，在一般的JSP页面中使用该对象将无法编译JSP文件。excepation对象和Java的所有对象一样，都具有系统提供的继承结构。exception 对象几乎定义了所有异常情况。在Java程序中，可以使用try/catch关键字来处理异常情况； 如果在JSP页面中出现没有捕获到的异常，就会生成 exception 对象，并把 exception 对象传送到在page指令中设定的错误页面中，然后在错误页面中处理相应的 exception 对象。

### jsp中的charset和pageEncoding的区别

 - charset设置的是当前jsp响应页面的字符编码方式，鼠标放在charset上，可以看到Attribute :
   contentType；实际调用的是response.setContentType("jsp页面上的contentType的值");
 - pageEncoding则是设置当前页面的保存方式，在eclipse中，如果采用默认的GBK编码，而pageEncoding方式采用“ISO-8859-1”的话，如果jsp中中文字符，则会出现错误，当前jsp页面无法以“IS0-8859-1”的编码方式进行保存。
 

## Http协议与TCP协议简单理解
- https://www.cnblogs.com/dingjiaoyang/p/5326544.html

TCP协议对应于传输层，而HTTP协议对应于应用层，从本质上来说，二者没有可比性。Http协议是建立在TCP协议基础之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过TCP建立起一个到服务器的连接通道，当本次请求需要的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的。所以Http连接是一种短连接，是一种**无状态**的连接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，所以记不住任何状态，成为无状态连接。

 

## cookie 和session 的区别详解
1. 由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车，当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的，使用一些缓存服务比如Memcached之类的来放 Session。

2. 思考一下服务端如何识别特定的客户？这个时候Cookie就登场了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用 Cookie 来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。有人问，如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。

3. Cookie其实还可以用在一些方便用户的场景下，设想你某次登陆过一个网站，下次登录的时候不想再次输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名给填了，能够方便一下用户。这也是Cookie名称的由来，给用户的一点甜头。所以，总结一下：Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中；Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。

简单来说：

 - 相同点
 都可以存储一些信息
 都可以设置过期时间
 都是基于kye-value的结构来存储数据
 
 - 不同点
session存在服务器端，cookie存在浏览器端
session更加安全，可以存储一些敏感信息。cookie安全性相对较低，一般存放一些不是很重要的信息
session理论上大小没有限制，但是有过期时间可以设置。单个cookie的大小是有限制的，单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。


## 前端垮域问题
- http://www.jianshu.com/p/c3dc6081cf8b

 - 为什么需要跨域
 受浏览器同源策略的限制，本域的js不能操作其他域的页面对象（比如DOM）。但在安全限制的同时也给注入iframe或是ajax应用上带来了不少麻烦。所以我们要通过一些方法使本域的js能够操作其他域的页面对象或者使其他域的js能操作本域的页面对象（iframe之间）。
这里需要明确的一点是： 所谓的域跟js的存放服务器没有关系，比如baidu.com的页面加载了google.com的js，那么此js的所在域是baidu.com而不是google.com。也就是说此时该js能操作baidu.com的页面对象，而不能操作google.com的页面对象。

1.同源策略：

它是由Netscape提出的一个著名的安全策略。同源是指，域名，协议，端口相同。浏览器执行javascript脚本时，会检查这个脚本属于那个页面，如果不是同源页面，就不会被执行。

2.为什么script标签引入的文件不受同源策略的限制？

因为script标签引入的文件内容是不能够被客户端的js获取到的，不会影响到被引用文件的安全，所以没必要使script标签引入的文件遵循浏览器的同源策略。而通过ajax加载的文件内容是能够被客户端js获取到的，所以ajax必须遵循同源策略，否则被引入文件的内容会泄漏或者存在其他风险。

3.静态HTTP服务器：Nginx是一个HTTP服务器，可以将服务器上的静态文件（如HTML、图片）通过HTTP协议展现给客户端

4.反向代理服务器：客户端本来可以直接通过HTTP协议访问某网站应用服务器，网站管理员可以在中间加上一个Nginx，客户端请求Nginx，Nginx请求应用服务器，然后将结果返回给客户端，此时Nginx就是反向代理服务器。

5.负载均衡:当网站访问量非常大，一台服务器已经不够用了。于是将同一个应用部署在多台服务器上，将大量用户的请求分配给多台机器处理。Nginx可以通过反向代理来实现负载均衡。

 - 跨域常用的解决方式
通过jsonp跨域
通过修改document.domain来跨子域
使用window.name来进行跨域
使用HTML5中新引进的window.postMessage方法来跨域传送数据
## JavaScript中的null、undefined

Undefined类型只有一个值，即undefined。当声明的变量还未被初始化时，变量的默认值为undefined。
Null类型也只有一个值，即null。null用来表示尚未存在的对象，常用来表示函数企图返回一个不存在的对象。
例1：js 代码：
    var oValue;  
    alert(oValue == undefined); //output "true"  
     
    这段代码显示为true,代表oVlaue的值即为undefined，因为我们没有初始化它。
例2：js 代码：
    alert(null == document.getElementById('notExistElement'));  
     
    当页面上不存在id为"notExistElement"的DOM节点时，这段代码显示为"true"，因为我们尝试获取一个不存在的对象。
例3：js 代码：
    alert(typeof undefined); //output "undefined"  
    alert(typeof null); //output "object"
    
```javascript
Number(null)
// 0
5 + null
// 5


Number(undefined)
// NaN
5 + undefined
// NaN
```

## redis如何建立集群
- http://blog.csdn.net/fengshizty/article/details/51368004
- https://www.cnblogs.com/hjwublog/p/5681700.html

从redis3.0开始，官方已经开始支持集群模式。
一个主从结构的redis集群模式，如下图所示：

![此处输入图片的描述][32]


上图中的master节点之间，以及slave节点之间，以及master-slave节点之间，都进行了连接。这样做有一个好处，首先主从节点之间数据复制十分方便。然后，当新增集群master节点，或者减少master节点时，会涉及到数据迁移，主节点之间的数据迁移，这时主节点之间相互建立连接就方便了。

增删节点的情况：
假设原来有三个主节点：
节点A覆盖0－5460;
节点B覆盖5461－10922;
节点C覆盖10923－16383.

现在增加一个主节点D：
节点A覆盖1365-5460
节点B覆盖6827-10922
节点C覆盖12288-16383
节点D覆盖0-1364,5461-6826,10923-12287
**注意**节点D覆盖的hash范围，这样做的好处是可以更少的移动元素。


 - 集群分区好处

无论是memcached的一致性哈希算法，还是redis的集群分区，最主要的目的都是在移除、添加一个节点时对已经存在的缓存数据的定位影响尽可能的降到最小。redis将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点， 比如说：

如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。

与此类似， 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。

因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线，从而保证集群的可用性。下面我们就来学习下集群中节点的增加和删除。

## 查询出student表中选课数大于3的人学号及课程总分
```sql
mysql> select * from student;
+-----+--------+-------+
| num | course | score |
+-----+--------+-------+
|   1 | yuwen  | 60    |
|   1 | yingyu | 60    |
|   1 | shuxue | 60    |
|   1 | wuli   | 60    |
|   1 | huaxue | 60    |
|   2 | huaxue | 60    |
|   3 | huaxue | 60    |
|   4 | huaxue | 60    |
|   4 | wuli   | 60    |
|   4 | shuxue | 60    |
|   4 | yingyu | 60    |
+-----+--------+-------+
11 rows in set (0.00 sec)

mysql> select num,sum(score) from student group by num having count(num) >3;
+-----+------------+
| num | sum(score) |
+-----+------------+
|   1 |        300 |
|   4 |        240 |
+-----+------------+
2 rows in set (0.00 sec)

mysql> 
```

## linux运维知识
- http://blog.csdn.net/xiaoguaihai/article/details/8705992/

Linux下几个常见的文件查找命令：

which       查看**可执行文件**的位置 
whereis    寻找特定文件，查看文件的位置 
locate       配合数据库查看文件位置 
find          **实际搜寻硬盘查询文件名称** 


线上查询及帮助命令（1个）
man 
目录操作命令（6个）
ls tree pwd mkdir rmdir cd


文件操作命令（7个）
touch cp mv rm ln find rename


文件查看及处理命令（21个）
cat more less head tac head tail cut paste 
sort uniq wc iconv dos2unix file diff tree chattr 
lsattr rev vimdiff


文件打包压缩命令（3个）
gzip tar unzip


信息显示命令（12个）
uname hostname dmesg uptime file stat du df top free w date


搜索文件命令（4个）
find which whereis locate


用户管理命令（10个）
useradd userdel passwd chage usermod id su sudo visudo 
groupadd


基本网络操作命令（10个）
telnet ssh scp wget ping route ifconfig ifup ifdown netstat


深入网络操作命令（6个）
route mail mutt nslookup dig wget


有关磁盘空间的命令（6个）
mount umount df du fsck dd


关机和查看系统信息的命令（7个）
shutdown reboot ps top kill date


安装和登录命令（3个）
shutdown halt reboot


系统管理相关命令（9个）
top free vmstat mpstat iostat sar kill chkconfig last


系统安全相关命令（13个）
passwd su sudo umask chgrp chmod chown chattr lsattr ps 
whoami


查看系统用户登陆信息命令（6个）
w who users last lastlog fingers


查看硬件相关命令（6个）
ethtool mii-tool dmidecode dmesg lspci


其它（14个）
chkconfig echo yum watch alias unalias date clear history eject 
time nohup nc xargs


监视物理组件的高级 Linux命令

内存:top free vmstat mpstat iostat sar 
CPU:top vmstat mpstat iostat sar 
I/O:vmstat mpstat iostat sar 
进程:ipcs ipcrm 
负载:uptime


以上命令属于武功里的《九阴真经》，如果掌握好了，会非常牛。


关机/重启/注销命令


关机: 
shutdown -h now ——>立刻关机(生产常用) 
shhutdown -h +1 ——>1 分钟以后关机
init 0 
halt ——>立即停止系统，需要人工关闭电源
halt -p 
poweroff ——>立即停止系统，并且关闭电源
重启: 
reboot(生产常用) 
shutdown -r now(生产常用) 
shhutdown -r +1 ——>1 分钟以后重起
init 6 
注销
logout 
exit(生产常用) 
ctl+d ——>快捷键(生产常用)


进程管理：（16个）
bg：后台运行 fg：挂起程序 jobs：显示后台程序 kill,killall,pkill：杀掉进程
crontab：设置定时 ps：查看进程 pstree：显示进程状态树
top：显示进程 nice：改变优先权 nohup：用户退出系统之后继续工作
pgrep：查找匹配条件的进程 strace：跟踪一个进程的系统调用
ltrace：跟踪进程调用库函数的情 vmstat：报告虚拟内存统计信息


危险的系统命令：
mv rm dd fdisk parted


linux 四剑客（4 个）
grep egrep sed awk

 - tar命令
 tar命令可以调用gzip命令（-z参数）或者是bzip命令(-j参数)来进行文件的压缩（tar命令本身只执行打包，并不会压缩）。
 
 以使用gzip为例：压缩src文件夹
 压缩：tar -zcv -f src.tar.gz src
 解压缩：tar -zxv -f src.tar.gz
 
 压缩率bzip2 > gzip > zip
 zip的通用性较好，而现在windows下软件winrar,7zip等对tar.gz的支持也非常好。推荐用tar.gz，bzip2要耗费更多的cpu
 
 

## Integer包装类
```java
        Integer ii = 100;
		int jj = 100;
		if (ii == jj)
		{
			System.out.println("简单类型，范围没有超过-128至127，所以相等");
		}
		Integer iii = 200;
		int jjj = 200;
		if (iii == jjj)
		{
			System.out.println("简单类型，范围虽然超过了-128至127，但是使用了自动拆箱，所以相等");
		}
		Integer iiii = 100;
		Integer jjjj = 100;
		if (iiii == jjjj)
		{
			System.out.println("自动拆箱成简单类型，范围在-128至127，所以相等");
		}
		
		Integer iiiii = 200;
		Integer jjjjj = 200;
		if (iiiii == jjjjj)
		{
			System.out.println("范围超过了-128至127，相当于new了两个对象，所以不相等");
		}
```

程序的运行结果如下：

![此处输入图片的描述][33]


  当我们使用Integer类去定义一个变量时，会用到java提供的自动装箱的技术，即会使用Integer中的这个函数：
  
```java
   /**
     * Returns an {@code Integer} instance representing the specified
     * {@code int} value.  If a new {@code Integer} instance is not
     * required, this method should generally be used in preference to
     * the constructor {@link #Integer(int)}, as this method is likely
     * to yield significantly better space and time performance by
     * caching frequently requested values.
     *
     * This method will always cache values in the range -128 to 127,
     * inclusive, and may cache other values outside of this range.
     *
     * @param  i an {@code int} value.
     * @return an {@code Integer} instance representing {@code i}.
     * @since  1.5
     */
    public static Integer valueOf(int i) {
        if (i >= IntegerCache.low && i <= IntegerCache.high)
            return IntegerCache.cache[i + (-IntegerCache.low)];
        return new Integer(i);
    }
```

正如这个函数的注释部分所说，将-128至127范围内的数据认为是频繁使用的数据，使用数组进行缓存。

当然，下面这种纯粹的简单类型，是不会涉及装箱技术的：

```java
        int kk =200;
		int ll = 200;
		if (kk==ll)
		{
			System.out.println("相等");
		}
```

## HashMap插入null的具体操作
HashMap是允许存在key为null的情况的，有且仅有一个key是null，当key为null的时候，put操作会怎么处理呢？
首先看一下put操作的源码：
```java
/**
     * Associates the specified value with the specified key in this map.
     * If the map previously contained a mapping for the key, the old
     * value is replaced.
     *
     * @param key key with which the specified value is to be associated
     * @param value value to be associated with the specified key
     * @return the previous value associated with <tt>key</tt>, or
     *         <tt>null</tt> if there was no mapping for <tt>key</tt>.
     *         (A <tt>null</tt> return can also indicate that the map
     *         previously associated <tt>null</tt> with <tt>key</tt>.)
     */
    public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
```

它内部是调用了putVal方法，但是其实putVal方法内部是没有对null的key的这种情况进行特殊的处理，是在hash方法的内部处理的。
下面是hash方法的源码：
```java
 /**
     * Computes key.hashCode() and spreads (XORs) higher bits of hash
     * to lower.  Because the table uses power-of-two masking, sets of
     * hashes that vary only in bits above the current mask will
     * always collide. (Among known examples are sets of Float keys
     * holding consecutive whole numbers in small tables.)  So we
     * apply a transform that spreads the impact of higher bits
     * downward. There is a tradeoff between speed, utility, and
     * quality of bit-spreading. Because many common sets of hashes
     * are already reasonably distributed (so don't benefit from
     * spreading), and because we use trees to handle large sets of
     * collisions in bins, we just XOR some shifted bits in the
     * cheapest possible way to reduce systematic lossage, as well as
     * to incorporate impact of the highest bits that would otherwise
     * never be used in index calculations because of table bounds.
     */
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```

从源码可以看出，key为null的时候，它就被存在0位置。

这里顺便说一下,为什么上面的hash函数,在计算key的hash的时候,需要有一个移位异或的操作?可以参考一下下面的链接:

https://www.cnblogs.com/zhengwang/p/8136164.html

主要目的还是为了防止hash碰撞,因为hashmap的put操作的时候,需要计算元素存放的位置,以map大小为16(16-1=15。2进制表示是00000000 00000000 00001111)来举例:
```java
    10100101 11000100 00100101
&   00000000 00000000 00001111
----------------------------------
    00000000 00000000 00000101    //高位全部归零，只保留末四位
```

从上面的例子,可以看出进行位与操作实际上只有末尾的4位有用,当数据量增大的时候,如果在计算的hash的直接使用hashcode值,那相当于损失了高位的信息,所以做一个移位正好可以将高位的信息与低位的信息进行一个融合,降低碰撞发生的概率.



**注意**，Hashtable中是不允许key为null的情况。下面是Hashtable的put方法的源码：
```java
/**
     * Maps the specified <code>key</code> to the specified
     * <code>value</code> in this hashtable. Neither the key nor the
     * value can be <code>null</code>. <p>
     *
     * The value can be retrieved by calling the <code>get</code> method
     * with a key that is equal to the original key.
     *
     * @param      key     the hashtable key
     * @param      value   the value
     * @return     the previous value of the specified key in this hashtable,
     *             or <code>null</code> if it did not have one
     * @exception  NullPointerException  if the key or value is
     *               <code>null</code>
     * @see     Object#equals(Object)
     * @see     #get(Object)
     */
    public synchronized V put(K key, V value) {
        // Make sure the value is not null
        if (value == null) {
            throw new NullPointerException();
        }

        // Makes sure the key is not already in the hashtable.
        Entry<?,?> tab[] = table;
        int hash = key.hashCode();
        int index = (hash & 0x7FFFFFFF) % tab.length;
        @SuppressWarnings("unchecked")
        Entry<K,V> entry = (Entry<K,V>)tab[index];
        for(; entry != null ; entry = entry.next) {
            if ((entry.hash == hash) && entry.key.equals(key)) {
                V old = entry.value;
                entry.value = value;
                return old;
            }
        }

        addEntry(hash, key, value, index);
        return null;
    }
```

注意源码中的：Neither the key nor the value can be null。

**注意**，ConcurrentHashMap也**不**允许key和value为null的情况。
下面是put方法的源码：
```java
/**
     * Maps the specified key to the specified value in this table.
     * Neither the key nor the value can be null.
     *
     * <p>The value can be retrieved by calling the {@code get} method
     * with a key that is equal to the original key.
     *
     * @param key key with which the specified value is to be associated
     * @param value value to be associated with the specified key
     * @return the previous value associated with {@code key}, or
     *         {@code null} if there was no mapping for {@code key}
     * @throws NullPointerException if the specified key or value is null
     */
    public V put(K key, V value) {
        return putVal(key, value, false);
    }

    /** Implementation for put and putIfAbsent */
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
```

## stringbuffer和stringbuilder的扩容函数的具体实现

二者都是继承自AbstractStringBuilder抽象类，二者在扩容的时候，都会调用AbstractStringBuilder的ensureCapacityInternal方法，源码如下：

```java
   /**
     * For positive values of {@code minimumCapacity}, this method
     * behaves like {@code ensureCapacity}, however it is never
     * synchronized.
     * If {@code minimumCapacity} is non positive due to numeric
     * overflow, this method throws {@code OutOfMemoryError}.
     */
    private void ensureCapacityInternal(int minimumCapacity) {
        // overflow-conscious code
        if (minimumCapacity - value.length > 0) {
            value = Arrays.copyOf(value,
                    newCapacity(minimumCapacity));
        }
    }
```
注意，其中的newCapacity方法源码如下，扩容的思路大概思路是：首先扩容到原大小的2倍大+2的大小。然后判断扩容后的数组能否存下，否则就按照新的字符串长度进行扩容。
```java
/**
     * Returns a capacity at least as large as the given minimum capacity.
     * Returns the current capacity increased by the same amount + 2 if
     * that suffices.
     * Will not return a capacity greater than {@code MAX_ARRAY_SIZE}
     * unless the given minimum capacity is greater than that.
     *
     * @param  minCapacity the desired minimum capacity
     * @throws OutOfMemoryError if minCapacity is less than zero or
     *         greater than Integer.MAX_VALUE
     */
    private int newCapacity(int minCapacity) {
        // overflow-conscious code
        int newCapacity = (value.length << 1) + 2;
        if (newCapacity - minCapacity < 0) {
            newCapacity = minCapacity;
        }
        return (newCapacity <= 0 || MAX_ARRAY_SIZE - newCapacity < 0)
            ? hugeCapacity(minCapacity)
            : newCapacity;
    }
```

注意上面源码中的hugeCapacity方法，当newCapacity超过了MAX_ARRAY_SIZE（Integer.MAX_VALUE - 8）的时候，将会调用该方法，下面是该方法源码。但是也要注意newCapacity**不能**超过Integer.MAX_VALUE，否则会抛出OutOfMemoryError异常。

```java
    private int hugeCapacity(int minCapacity) {
        if (Integer.MAX_VALUE - minCapacity < 0) { // overflow
            throw new OutOfMemoryError();
        }
        return (minCapacity > MAX_ARRAY_SIZE)
            ? minCapacity : MAX_ARRAY_SIZE;
    }
```

## 统计出某个log文件中ip出现次数最多的ip
cat  access_log_2011_06_26.log |awk '{print $1}'|uniq -c|sort -n ｜head 5

其中，$1表示IP地址会出现在log文件的第1列.




## ps命令、netstat命令

```java
ps -ef|grep java
```
查看所有的java进程，示例输出如下：

```linux
audi@audi-PC:~/WorkSpace_git/learn$ ps -ef|grep java
audi      2590  2573 71 12:05 ?        00:04:20 /usr/lib/jvm/java/jdk1.8.0_151/jre/bin/java -Dosgi.requiredJavaVersion=1.8 -Dosgi.instance.area.default=@user.home/eclipse-workspace -XX:+UseG1GC -XX:+UseStringDeduplication -Dosgi.requiredJavaVersion=1.8 -Xms256m -Xmx1024m -jar /home/audi/runtime/eclipse//plugins/org.eclipse.equinox.launcher_1.4.0.v20161219-1356.jar -os linux -ws gtk -arch x86_64 -showsplash /home/audi/runtime/eclipse//plugins/org.eclipse.epp.package.common_4.7.1.20171005-1200/splash.bmp -launcher /home/audi/runtime/eclipse/eclipse -name Eclipse --launcher.library /home/audi/runtime/eclipse//plugins/org.eclipse.equinox.launcher.gtk.linux.x86_64_1.1.550.v20170928-1359/eclipse_1629.so -startup /home/audi/runtime/eclipse//plugins/org.eclipse.equinox.launcher_1.4.0.v20161219-1356.jar --launcher.appendVmargs -exitdata 58800d -product org.eclipse.epp.package.jee.product -vm /usr/lib/jvm/java/jdk1.8.0_151/jre/bin/java -vmargs -Dosgi.requiredJavaVersion=1.8 -Dosgi.instance.area.default=@user.home/eclipse-workspace -XX:+UseG1GC -XX:+UseStringDeduplication -Dosgi.requiredJavaVersion=1.8 -Xms256m -Xmx1024m -jar /home/audi/runtime/eclipse//plugins/org.eclipse.equinox.launcher_1.4.0.v20161219-1356.jar
audi      2839  2590 99 12:11 ?        00:00:04 /usr/lib/jvm/java/jdk1.8.0_151/bin/java -Dfile.encoding=UTF-8 -classpath /usr/lib/jvm/java/jdk1.8.0_151/jre/lib/resources.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/rt.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/jsse.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/jce.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/charsets.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/jfr.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/nashorn.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/jfxrt.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/sunec.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/localedata.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/dnsns.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/zipfs.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/cldrdata.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/sunjce_provider.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/sunpkcs11.jar:/usr/lib/jvm/java/jdk1.8.0_151/jre/lib/ext/jaccess.jar:/home/audi/WorkSpace_git/helloWorld/bin:/home/audi/WorkSpace_git/helloWorld/mysql-connector-java-6.0.6.jar:/home/audi/WorkSpace_git/helloWorld/cglib-3.2.5.jar com.audi.SayHello
audi      2860  2404  0 12:11 pts/0    00:00:00 grep java
audi@audi-PC:~/WorkSpace_git/learn$ 
```

输出结果的第二列就是PID。得到了PID就可以使用kill -9 命令进行强制停止线程。

netstat命令可以用于查看程序的端口链接情况，或者占用情况。
例如，Linux下查看tomcat占用端口，可以使用如下命令：
```linux
1、先查看tomcat的进程号
ps -ef | grep tomcat*
后面带*号，是为了查看多个tomcat，例如tomcat6，tomcat7。

2、根据进程号查看端口号

netstat -anop | grep 15161

可以看到8865、8866、8867端口号被占用
```

## 找到当前系统的最大的文件
```linux
find / -type f -size +1G 找到根目录下大于1G的文件
find . -type f -size +800M 找到当前目录下大于800MB的文件

查找当前目录（搜索深度为1）下最大的10个文件
du --max-depth=1 / -h |sort -h -r |head -10
```

## Linux du命令和df命令区别
  

 - du，disk usage
是通过搜索文件来计算每个文件的大小然后累加，du能看到的文件只是一些当前存在的，没有被删除的。他计算的大小就是当前他认为存在的所有文件大小的累加和。
       
 - df，disk free
通过文件系统来快速获取空间大小的信息，当我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了，而是暂时消失了，当所有程序都不用时，才会根据OS的规则释放掉已经删除的文件， df记录的是通过文件系统获取到的文件的大小，他比du强的地方就是能够看到已经删除的文件，而且计算大小的时候，把这一部分的空间也加上了，更精确了。当文件系统也确定删除了该文件后，这时候du与df就一致了。

使用示例如下，注意加入-h参数可以使得结果更加便于阅读（转换成了KB或者MB）。
```linux
root@audi-PC:/usr/local# du  （查看的是当前目录下的文件空间占用情况）
23152	./redis/bin
23220	./redis
4	./etc
4	./sbin
4	./games
4	./src
284	./lib/python2.7/dist-packages/pygments/formatters
284	./lib/python2.7/dist-packages/pygments/styles
32	./lib/python2.7/dist-packages/pygments/filters
5832	./lib/python2.7/dist-packages/pygments/lexers
6760	./lib/python2.7/dist-packages/pygments
56	./lib/python2.7/dist-packages/Pygments-2.2.0.dist-info
6820	./lib/python2.7/dist-packages
4	./lib/python2.7/site-packages
6828	./lib/python2.7
4	./lib/python3.5/dist-packages
8	./lib/python3.5
6840	./lib
4	./include
8	./bin
4	./share/sgml/declaration
4	./share/sgml/dtd
4	./share/sgml/misc
4	./share/sgml/entities
4	./share/sgml/stylesheet
24	./share/sgml
4	./share/xml/declaration
4	./share/xml/misc
4	./share/xml/schema
4	./share/xml/entities
20	./share/xml
16	./share/icons/hicolor/128x128/apps
20	./share/icons/hicolor/128x128
24	./share/icons/hicolor/256x256/apps
28	./share/icons/hicolor/256x256
32	./share/icons/hicolor/64x64/apps
36	./share/icons/hicolor/64x64
40	./share/icons/hicolor/16x16/apps
44	./share/icons/hicolor/16x16
8	./share/icons/hicolor/22x22/apps
12	./share/icons/hicolor/22x22
44	./share/icons/hicolor/48x48/apps
48	./share/icons/hicolor/48x48
48	./share/icons/hicolor/512x512/apps
52	./share/icons/hicolor/512x512
28	./share/icons/hicolor/32x32/apps
32	./share/icons/hicolor/32x32
28	./share/icons/hicolor/24x24/apps
32	./share/icons/hicolor/24x24
308	./share/icons/hicolor
312	./share/icons
4	./share/fonts
16	./share/applications
4	./share/emacs/site-lisp
8	./share/emacs
4	./share/man
4	./share/ca-certificates
396	./share
30488	.
root@audi-PC:/usr/local# du -h
23M	./redis/bin
23M	./redis
4.0K	./etc
4.0K	./sbin
4.0K	./games
4.0K	./src
284K	./lib/python2.7/dist-packages/pygments/formatters
284K	./lib/python2.7/dist-packages/pygments/styles
32K	./lib/python2.7/dist-packages/pygments/filters
5.7M	./lib/python2.7/dist-packages/pygments/lexers
6.7M	./lib/python2.7/dist-packages/pygments
56K	./lib/python2.7/dist-packages/Pygments-2.2.0.dist-info
6.7M	./lib/python2.7/dist-packages
4.0K	./lib/python2.7/site-packages
6.7M	./lib/python2.7
4.0K	./lib/python3.5/dist-packages
8.0K	./lib/python3.5
6.7M	./lib
4.0K	./include
8.0K	./bin
4.0K	./share/sgml/declaration
4.0K	./share/sgml/dtd
4.0K	./share/sgml/misc
4.0K	./share/sgml/entities
4.0K	./share/sgml/stylesheet
24K	./share/sgml
4.0K	./share/xml/declaration
4.0K	./share/xml/misc
4.0K	./share/xml/schema
4.0K	./share/xml/entities
20K	./share/xml
16K	./share/icons/hicolor/128x128/apps
20K	./share/icons/hicolor/128x128
24K	./share/icons/hicolor/256x256/apps
28K	./share/icons/hicolor/256x256
32K	./share/icons/hicolor/64x64/apps
36K	./share/icons/hicolor/64x64
40K	./share/icons/hicolor/16x16/apps
44K	./share/icons/hicolor/16x16
8.0K	./share/icons/hicolor/22x22/apps
12K	./share/icons/hicolor/22x22
44K	./share/icons/hicolor/48x48/apps
48K	./share/icons/hicolor/48x48
48K	./share/icons/hicolor/512x512/apps
52K	./share/icons/hicolor/512x512
28K	./share/icons/hicolor/32x32/apps
32K	./share/icons/hicolor/32x32
28K	./share/icons/hicolor/24x24/apps
32K	./share/icons/hicolor/24x24
308K	./share/icons/hicolor
312K	./share/icons
4.0K	./share/fonts
16K	./share/applications
4.0K	./share/emacs/site-lisp
8.0K	./share/emacs
4.0K	./share/man
4.0K	./share/ca-certificates
396K	./share
30M	.
root@audi-PC:/usr/local# df  （查看的是整个磁盘的占用情况，还有剩余空间情况）
文件系统           1K-块      已用     可用 已用% 挂载点
udev             4018948         0  4018948    0% /dev
tmpfs             808520      1436   807084    1% /run
/dev/sda7      129679476  34844620 88204408   29% /
tmpfs            4042596    154992  3887604    4% /dev/shm
tmpfs               5120         4     5116    1% /run/lock
tmpfs            4042596         0  4042596    0% /sys/fs/cgroup
tmpfs             808516        24   808492    1% /run/user/1000
/dev/sda5      209720508 146873736 62846772   71% /media/audi/0002DA810009FB6F
root@audi-PC:/usr/local# df -h
文件系统        容量  已用  可用 已用% 挂载点
udev            3.9G     0  3.9G    0% /dev
tmpfs           790M  1.5M  789M    1% /run
/dev/sda7       124G   34G   85G   29% /
tmpfs           3.9G  152M  3.8G    4% /dev/shm
tmpfs           5.0M  4.0K  5.0M    1% /run/lock
tmpfs           3.9G     0  3.9G    0% /sys/fs/cgroup
tmpfs           790M   24K  790M    1% /run/user/1000
/dev/sda5       201G  141G   60G   71% /media/audi/0002DA810009FB6F
root@audi-PC:/usr/local# 
```

## java线程池

### newFixedThreadPool

定长线程池，源码如下：
```java
/**
     * Creates a thread pool that reuses a fixed number of threads
     * operating off a shared unbounded queue.  At any point, at most
     * {@code nThreads} threads will be active processing tasks.
     * If additional tasks are submitted when all threads are active,
     * they will wait in the queue until a thread is available.
     * If any thread terminates due to a failure during execution
     * prior to shutdown, a new one will take its place if needed to
     * execute subsequent tasks.  The threads in the pool will exist
     * until it is explicitly {@link ExecutorService#shutdown shutdown}.
     *
     * @param nThreads the number of threads in the pool
     * @return the newly created thread pool
     * @throws IllegalArgumentException if {@code nThreads <= 0}
     */
    public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
    }
```
从源码可以看出，它内部调用了ThreadPoolExecutor类的构造函数来生成ExecutorService类型的实例对象。**注意**，ThreadPoolExecutor是AbstractExecutorService抽象类的子类，AbstractExecutorService是ExecutorService接口的实现类。

ThreadPoolExecutor构造函数中的第3个参数**0L**表示，线程会一直存活，不会被回收。

ThreadPoolExecutor的源码如下：
```java
/**
     * Creates a new {@code ThreadPoolExecutor} with the given initial
     * parameters and default thread factory and rejected execution handler.
     * It may be more convenient to use one of the {@link Executors} factory
     * methods instead of this general purpose constructor.
     *
     * @param corePoolSize the number of threads to keep in the pool, even
     *        if they are idle, unless {@code allowCoreThreadTimeOut} is set
     * @param maximumPoolSize the maximum number of threads to allow in the
     *        pool
     * @param keepAliveTime when the number of threads is greater than
     *        the core, this is the maximum time that excess idle threads
     *        will wait for new tasks before terminating.
     * @param unit the time unit for the {@code keepAliveTime} argument
     * @param workQueue the queue to use for holding tasks before they are
     *        executed.  This queue will hold only the {@code Runnable}
     *        tasks submitted by the {@code execute} method.
     * @throws IllegalArgumentException if one of the following holds:<br>
     *         {@code corePoolSize < 0}<br>
     *         {@code keepAliveTime < 0}<br>
     *         {@code maximumPoolSize <= 0}<br>
     *         {@code maximumPoolSize < corePoolSize}
     * @throws NullPointerException if {@code workQueue} is null
     */
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), defaultHandler);
    }
```

### newCachedThreadPool
 根据实时任务的调用数量来动态的增加或者减少线程的数量，其源码如下：
```java
 /**
     * Creates a thread pool that creates new threads as needed, but
     * will reuse previously constructed threads when they are
     * available.  These pools will typically improve the performance
     * of programs that execute many short-lived asynchronous tasks.
     * Calls to {@code execute} will reuse previously constructed
     * threads if available. If no existing thread is available, a new
     * thread will be created and added to the pool. Threads that have
     * not been used for sixty seconds are terminated and removed from
     * the cache. Thus, a pool that remains idle for long enough will
     * not consume any resources. Note that pools with similar
     * properties but different details (for example, timeout parameters)
     * may be created using {@link ThreadPoolExecutor} constructors.
     *
     * @return the newly created thread pool
     */
    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
    }
```
从源码中可以看出，它内部其实也是调用了ThreadPoolExecutor构造函数来进行线程池的构造。**注意**，线程池内的线程空闲超过60s，那么就会进行回收，线程池内默认没有任何线程。

### newSingleThreadExecutor
创建一个只有单个线程的线程池，其源码如下：
```java
/**
     * Creates an Executor that uses a single worker thread operating
     * off an unbounded queue. (Note however that if this single
     * thread terminates due to a failure during execution prior to
     * shutdown, a new one will take its place if needed to execute
     * subsequent tasks.)  Tasks are guaranteed to execute
     * sequentially, and no more than one task will be active at any
     * given time. Unlike the otherwise equivalent
     * {@code newFixedThreadPool(1)} the returned executor is
     * guaranteed not to be reconfigurable to use additional threads.
     *
     * @return the newly created single-threaded Executor
     */
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
```

从源码中可以看出，它的过期时间也是0L，也就是说不会被回收。

### newScheduledThreadPool
创建一个可延缓指定时间执行的线程池，或者可以周期性执行的线程池，其源码如下：
```java
/**
     * Creates a thread pool that can schedule commands to run after a
     * given delay, or to execute periodically.
     * @param corePoolSize the number of threads to keep in the pool,
     * even if they are idle
     * @return a newly created scheduled thread pool
     * @throws IllegalArgumentException if {@code corePoolSize < 0}
     */
    public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
        return new ScheduledThreadPoolExecutor(corePoolSize);
    }
```
它内部调用的就不是ThreadPoolExecutor构造函数了，而是ScheduledThreadPoolExecutor构造函数，ScheduledThreadPoolExecutor其实是ThreadPoolExecutor的子类。
ScheduledThreadPoolExecutor的源码如下：
```java
/**
     * Creates a new {@code ScheduledThreadPoolExecutor} with the
     * given core pool size.
     *
     * @param corePoolSize the number of threads to keep in the pool, even
     *        if they are idle, unless {@code allowCoreThreadTimeOut} is set
     * @throws IllegalArgumentException if {@code corePoolSize < 0}
     */
    public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue());
    }
```
从源码可以看出，它内部其实还是调用的ThreadPoolExecutor的构造函数，只不过它的队列类型是DelayedWorkQueue。

调度可以通过ScheduledExecutorService类的4个schedule方法实现,具体如下所示:
```java
   /**
     * Creates and executes a one-shot action that becomes enabled
     * after the given delay.
     *
     * @param command the task to execute
     * @param delay the time from now to delay execution
     * @param unit the time unit of the delay parameter
     * @return a ScheduledFuture representing pending completion of
     *         the task and whose {@code get()} method will return
     *         {@code null} upon completion
     * @throws RejectedExecutionException if the task cannot be
     *         scheduled for execution
     * @throws NullPointerException if command is null
     */
    public ScheduledFuture<?> schedule(Runnable command,
                                       long delay, TimeUnit unit);

    /**
     * Creates and executes a ScheduledFuture that becomes enabled after the
     * given delay.
     *
     * @param callable the function to execute
     * @param delay the time from now to delay execution
     * @param unit the time unit of the delay parameter
     * @param <V> the type of the callable's result
     * @return a ScheduledFuture that can be used to extract result or cancel
     * @throws RejectedExecutionException if the task cannot be
     *         scheduled for execution
     * @throws NullPointerException if callable is null
     */
    public <V> ScheduledFuture<V> schedule(Callable<V> callable,
                                           long delay, TimeUnit unit);

    /**
     * Creates and executes a periodic action that becomes enabled first
     * after the given initial delay, and subsequently with the given
     * period; that is executions will commence after
     * {@code initialDelay} then {@code initialDelay+period}, then
     * {@code initialDelay + 2 * period}, and so on.
     * If any execution of the task
     * encounters an exception, subsequent executions are suppressed.
     * Otherwise, the task will only terminate via cancellation or
     * termination of the executor.  If any execution of this task
     * takes longer than its period, then subsequent executions
     * may start late, but will not concurrently execute.
     *
     * @param command the task to execute
     * @param initialDelay the time to delay first execution
     * @param period the period between successive executions
     * @param unit the time unit of the initialDelay and period parameters
     * @return a ScheduledFuture representing pending completion of
     *         the task, and whose {@code get()} method will throw an
     *         exception upon cancellation
     * @throws RejectedExecutionException if the task cannot be
     *         scheduled for execution
     * @throws NullPointerException if command is null
     * @throws IllegalArgumentException if period less than or equal to zero
     */
    public ScheduledFuture<?> scheduleAtFixedRate(Runnable command,
                                                  long initialDelay,
                                                  long period,
                                                  TimeUnit unit);

    /**
     * Creates and executes a periodic action that becomes enabled first
     * after the given initial delay, and subsequently with the
     * given delay between the termination of one execution and the
     * commencement of the next.  If any execution of the task
     * encounters an exception, subsequent executions are suppressed.
     * Otherwise, the task will only terminate via cancellation or
     * termination of the executor.
     *
     * @param command the task to execute
     * @param initialDelay the time to delay first execution
     * @param delay the delay between the termination of one
     * execution and the commencement of the next
     * @param unit the time unit of the initialDelay and delay parameters
     * @return a ScheduledFuture representing pending completion of
     *         the task, and whose {@code get()} method will throw an
     *         exception upon cancellation
     * @throws RejectedExecutionException if the task cannot be
     *         scheduled for execution
     * @throws NullPointerException if command is null
     * @throws IllegalArgumentException if delay less than or equal to zero
     */
    public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command,
                                                     long initialDelay,
                                                     long delay,
                                                     TimeUnit unit);

}
```


### newWorkStealingPool（JDK1.8新增）

利用分治的思想，将一个任务划分给多个线程执行，有点类似于mapReduce的思想。其源码如下：
```java
/**
     * Creates a thread pool that maintains enough threads to support
     * the given parallelism level, and may use multiple queues to
     * reduce contention. The parallelism level corresponds to the
     * maximum number of threads actively engaged in, or available to
     * engage in, task processing. The actual number of threads may
     * grow and shrink dynamically. A work-stealing pool makes no
     * guarantees about the order in which submitted tasks are
     * executed.
     *
     * @param parallelism the targeted parallelism level
     * @return the newly created thread pool
     * @throws IllegalArgumentException if {@code parallelism <= 0}
     * @since 1.8
     */
    public static ExecutorService newWorkStealingPool(int parallelism) {
        return new ForkJoinPool
            (parallelism,
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }

    /**
     * Creates a work-stealing thread pool using all
     * {@link Runtime#availableProcessors available processors}
     * as its target parallelism level.
     * @return the newly created thread pool
     * @see #newWorkStealingPool(int)
     * @since 1.8
     */
    public static ExecutorService newWorkStealingPool() {
        return new ForkJoinPool
            (Runtime.getRuntime().availableProcessors(),
             ForkJoinPool.defaultForkJoinWorkerThreadFactory,
             null, true);
    }
```

其中的ForkJoinPool构造函数源码如下：
```java
/**
     * Creates a {@code ForkJoinPool} with the given parameters.
     *
     * @param parallelism the parallelism level. For default value,
     * use {@link java.lang.Runtime#availableProcessors}.
     * @param factory the factory for creating new threads. For default value,
     * use {@link #defaultForkJoinWorkerThreadFactory}.
     * @param handler the handler for internal worker threads that
     * terminate due to unrecoverable errors encountered while executing
     * tasks. For default value, use {@code null}.
     * @param asyncMode if true,
     * establishes local first-in-first-out scheduling mode for forked
     * tasks that are never joined. This mode may be more appropriate
     * than default locally stack-based mode in applications in which
     * worker threads only process event-style asynchronous tasks.
     * For default value, use {@code false}.
     * @throws IllegalArgumentException if parallelism less than or
     *         equal to zero, or greater than implementation limit
     * @throws NullPointerException if the factory is null
     * @throws SecurityException if a security manager exists and
     *         the caller is not permitted to modify threads
     *         because it does not hold {@link
     *         java.lang.RuntimePermission}{@code ("modifyThread")}
     */
    public ForkJoinPool(int parallelism,
                        ForkJoinWorkerThreadFactory factory,
                        UncaughtExceptionHandler handler,
                        boolean asyncMode) {
        this(checkParallelism(parallelism),
             checkFactory(factory),
             handler,
             asyncMode ? FIFO_QUEUE : LIFO_QUEUE,
             "ForkJoinPool-" + nextPoolId() + "-worker-");
        checkPermission();
    }
```
默认会使用可用的CPU数量来定义并行级别。

### 自定义线程池

上面介绍的几种线程池，参数都是相对固定的，且无法设置阻塞队列的大小以及拒绝策略，适用的场景有限，下面我们介绍下自定义线程池：
```java
// 阻塞队列 容量为10
BlockingDeque<Runnable> deque = new LinkedBlockingDeque<>(10);
ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 5, 2, TimeUnit.SECONDS, deque, new ThreadPoolExecutor.AbortPolicy());
```
核心线程数2，最大线程数5，如果最大线程数大于核心线程数，那么在其空闲2秒以后将会被回收，直到剩下核心线程。使用如下测试代码，查看线程池启动、运行、后续的一整个过程：
```java
    public static void main(String[] args) {
        BlockingQueue<Runnable> queue = new LinkedBlockingQueue<>(10);
        // 设置线程池的参数，默认拒绝策略是AbortPolicy，即抛出异常
        ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 5, 2, TimeUnit.SECONDS, queue, new ThreadPoolExecutor.DiscardPolicy());
        // 如果为true，那么 超时时间一到，核心线程也会被回收
        System.out.println("是否允许回收核心线程 " + executor.allowsCoreThreadTimeOut());
        System.out.println();
        // 可以尝试设置allowCoreThreadTimeOut为true，可以看到线程池的空闲时间以后，线程池的线程都会被回收，默认为false
//        executor.allowCoreThreadTimeOut(Boolean.TRUE);
        print(executor);
        
        for (int i = 0; i < 20; i++) {
            executor.submit(() -> {
                try {
                    // 每个任务，假设执行耗时100ms
                    Thread.sleep(100);
                    System.out.println(Thread.currentThread().getName() + " 工作线程休眠结束");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            });
            // 打印相关信息
            print(executor);
        }

        try {
            // 主线程等待线程池任务执行完，查看线程池的相关信息
            Thread.sleep(4000);
            System.out.println();
            System.out.println(Thread.currentThread().getName() + " 休眠结束");
            print(executor);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 及时关闭线程池
        executor.shutdown();
    }

    private static void print(ThreadPoolExecutor executor) {
        System.out.println("executor.getPoolSize() = " + executor.getPoolSize());
        System.out.println("executor.getQueue().size() = " + executor.getQueue().size());
        System.out.println("executor.getCompletedTaskCount() = " + executor.getCompletedTaskCount());
        System.out.println();
    }
```
程序完成的功能很简单，循环往线程池提交任务，直至队列满，然后查看线程池的相关信息。程序输出如下(在里面我加了// 注释)：
```java
是否允许回收核心线程 false

// 可以看到线程池刚刚创建好，是没有任何线程创建的
executor.getPoolSize() = 0
executor.getQueue().size() = 0
executor.getCompletedTaskCount() = 0

//随着任务的submit到线程池，开始创建线程
executor.getPoolSize() = 1
executor.getQueue().size() = 0
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 0
executor.getCompletedTaskCount() = 0

// 当任务的数量大于corePoolSize的时候，不会继续创建线程，而是将多的任务丢到队列中
executor.getPoolSize() = 2
executor.getQueue().size() = 1
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 2
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 3
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 4
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 5
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 6
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 7
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 8
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 2
executor.getQueue().size() = 9
executor.getCompletedTaskCount() = 0

// 此时队列满
executor.getPoolSize() = 2
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

// 任务继续submit的时候，线程池开始继续创建线程
executor.getPoolSize() = 3
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 4
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

// 此时线程数量达到maxPoolSize
executor.getPoolSize() = 5
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

// 此时提交的任务会被丢弃掉
executor.getPoolSize() = 5
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 5
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 5
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 5
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

executor.getPoolSize() = 5
executor.getQueue().size() = 10
executor.getCompletedTaskCount() = 0

// 总共有15个任务被成功执行
pool-1-thread-5 工作线程休眠结束
pool-1-thread-3 工作线程休眠结束
pool-1-thread-4 工作线程休眠结束
pool-1-thread-1 工作线程休眠结束
pool-1-thread-2 工作线程休眠结束
pool-1-thread-4 工作线程休眠结束
pool-1-thread-1 工作线程休眠结束
pool-1-thread-5 工作线程休眠结束
pool-1-thread-2 工作线程休眠结束
pool-1-thread-3 工作线程休眠结束
pool-1-thread-5 工作线程休眠结束
pool-1-thread-4 工作线程休眠结束
pool-1-thread-1 工作线程休眠结束
pool-1-thread-2 工作线程休眠结束
pool-1-thread-3 工作线程休眠结束

// 输出excutor在执行完任务以后的一些信息，可以看到线程数回落到corePoolSize大小
main 休眠结束
executor.getPoolSize() = 2
executor.getQueue().size() = 0
executor.getCompletedTaskCount() = 15
```

###  Executor相关
 - Excutor：实现线程池最基本的借口，只有一个execute方法，且无法获取线程池的执行结果。
 - ExecutorService：具备管理执行器和任务生命周期的方法，提交任务机制更为完善。可以submit方法获取Future对象，从而获得线程执行结果。
 - ScheduledExecutorService：支持Future以及定时任务调度执行。

## 接口的幂等性的概念
幂等性是指重复使用同样的参数调用同一方法时总能获得同样的结果。比如对同一资源的GET请求访问结果都是一样的。

- http://www.cnblogs.com/binyue/p/4015884.html

## java8的lambda表达式

lambda表达式的主要作用就是代替匿名内部类的繁琐语法
lambda表达式只能为函数式接口创建实例;
匿名内部类可以为任何接口创建实例,只要匿名内部类实现所有的抽象方法即可;
匿名内部类可以为抽象类身子普通类创建实例,但是lambda只能为函数式接口创建实例;
匿名内部类实现的抽象方法的方法体允许调用接口中定义的默认方法,但是lambda表达式不允许.

代码实例:
首先是函数式接口:
```java
public interface LambdaTest
{
	int add(int a,int b);
}
```

下面lambda的实现,以及main方法中的测试代码:
```java
	LambdaTest lambdaTest = (a,b)->a+b;
	System.out.println(lambdaTest.add(2, 3));
	LambdaTest lambdaTest1 = (a,b)->a-b;
	System.out.println(lambdaTest1.add(2, 3));
```
程序运行输出结果:
```java
5
-1
```

## Java8的optional类
- http://www.importnew.com/6675.html


这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。
下面简要介绍该类的几个方法:
orElse
如果有值则将其返回，否则返回指定的其它值。源码如下:
```java
    /**
     * Return the value if present, otherwise return {@code other}.
     *
     * @param other the value to be returned if there is no value present, may
     * be null
     * @return the value, if present, otherwise {@code other}
     */
    public T orElse(T other) {
        return value != null ? value : other;
    }
```

map
map方法文档说明如下：
如果有值，则对其执行调用mapping函数得到返回值。如果返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional。
map方法用来对Optional实例的值执行一系列操作。通过一组实现了Function接口的lambda表达式传入操作。源码如下:
```java
/**
     * If a value is present, apply the provided mapping function to it,  
     * and if the result is non-null, return an {@code Optional} describing the
     * result.  Otherwise return an empty {@code Optional}.
     *
     * @apiNote This method supports post-processing on optional values, without
     * the need to explicitly check for a return status.  For example, the
     * following code traverses a stream of file names, selects one that has
     * not yet been processed, and then opens that file, returning an
     * {@code Optional<FileInputStream>}:
     *
     * <pre>{@code
     *     Optional<FileInputStream> fis =
     *         names.stream().filter(name -> !isProcessedYet(name))
     *                       .findFirst()
     *                       .map(name -> new FileInputStream(name));
     * }</pre>
     *
     * Here, {@code findFirst} returns an {@code Optional<String>}, and then
     * {@code map} returns an {@code Optional<FileInputStream>} for the desired
     * file if one exists.
     *
     * @param <U> The type of the result of the mapping function
     * @param mapper a mapping function to apply to the value, if present
     * @return an {@code Optional} describing the result of applying a mapping
     * function to the value of this {@code Optional}, if a value is present,
     * otherwise an empty {@code Optional}
     * @throws NullPointerException if the mapping function is null
     */
    public<U> Optional<U> map(Function<? super T, ? extends U> mapper) {
        Objects.requireNonNull(mapper);
        if (!isPresent())
            return empty();
        else {
            return Optional.ofNullable(mapper.apply(value));
        }
    }
```

filter

filter个方法通过传入限定条件对Optional实例的值进行过滤。文档描述如下：

如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。

读到这里，可能你已经知道如何为filter方法传入一段代码。是的，这里可以传入一个lambda表达式。对于filter函数我们应该传入实现了Predicate接口的lambda表达式。
源码如下:
```java
 /**
     * If a value is present, and the value matches the given predicate,
     * return an {@code Optional} describing the value, otherwise return an
     * empty {@code Optional}.
     *
     * @param predicate a predicate to apply to the value, if present
     * @return an {@code Optional} describing the value of this {@code Optional}
     * if a value is present and the value matches the given predicate,
     * otherwise an empty {@code Optional}
     * @throws NullPointerException if the predicate is null
     */
    public Optional<T> filter(Predicate<? super T> predicate) {
        Objects.requireNonNull(predicate);
        if (!isPresent())
            return this;
        else
            return predicate.test(value) ? this : empty();
    }
```

## mock测试springMVC的controller
-- https://www.cnblogs.com/xiaohunshi/p/5706943.html

## redis哨兵模式

它的**主要功能**有一下几点:
1、不时地监控redis是否按照预期良好地运行;
2、如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端);
3、能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的新地址。
4、哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。

需要指出的是,哨兵（sentinel）本身也是支持**集群**的.


## ServiceLoader作用及原理
- https://blog.csdn.net/is_zhoufeng/article/details/50722440

在java中根据一个子类获取其父类或接口信息非常方便，但是根据一个接口获取该接口的所有实现类却没那么容易。 这个时候就可以使用ServiceLoader来实现上述需求。java本身提供了一种方式来获取一个接口的子类，那就是使用java.util.ServiceLoader#load(java.lang.Class)

方法，但是直接使用该方法也是不能获取到给定接口所有的子类的。

需要接口的子类以配置的方式主动注册到一个接口上，才能使用ServiceLoader进行加载到子类，并且**子类需要有一个无参构造方法**，用于被ServiceLoader进行实例化。

ServiceLoader的原理其实很简单，就是根据给定的参数（接口）就能定位到该接口与实现类的映射配置文件的路径了，然后读取该配置文件，就能获取到该接口的子类

使用实例：

 1. 编写Service

```java
package com.mogujie.uni.sl;
/**
 1. Created by laibao
 */
public interface Animal {
        void eat();
}   
```
 2. 编写实现类（注意：实现类不一定要与接口在同一个工程中，可以存在于其他的jar包中）
 ```java
 package com.mogujie.uni.sl;
/**
 * Created by laibao
 */
public class Pig implements Animal {
    @Override
    public void eat() {
        System.out.println("Pig eating...");
    }
}
 ```
 
 ```java
 package com.mogujie.uni.sl;
/**
 * Created by laibao
 */
public class Dog implements Animal {
    @Override
    public void eat() {
        System.out.println("Dog eating...");
    }
}
 ```
 
在实现类所在的工程的classpath下面的建立META-INF/services目录，该目录是固定的，一定要按照规定的名称去创建，该目录用于配置接口与实现类的映射关系 
```java
com.mogujie.uni.sl.Pig
com.mogujie.uni.sl.Dog
```

接下来就能使用ServiceLoader的方法获取com.mogujie.uni.sl.Animal接口的所有子类了。测试类如下：
```java
package com.mogujie.uni;
import com.mogujie.uni.sl.Animal;
import java.util.Iterator;
import java.util.ServiceLoader;
/**
 * Created by laibao
 */
public class TestServiceLoader {
    public static void main(String[] args) {
        ServiceLoader<Animal> serviceLoader = ServiceLoader.load(Animal.class);
        Iterator<Animal> animalIterator = serviceLoader.iterator();
        while(animalIterator.hasNext()){
            Animal animal = animalIterator.next();
            animal.eat();
        }
    }
}
```

测试输出：
```java
Pig eating...
Dog eating...
```

下面自己实现一个CustomServiceLoader与系统的ServiceLoader具有同样的功能
```java
package com.mogujie.uni;

import org.apache.commons.io.IOUtils;
import java.net.URL;
import java.util.Enumeration;
import java.util.LinkedList;
import java.util.List;

/**
 * Created by laibao
 */
public class CustomServiceLoader {

    public static final String MAPPING_CONFIG_PREFIX = "META-INF/services";

    public static <S> List<S> loade(Class<S> service) throws Exception{
        String mappingConfigFile = MAPPING_CONFIG_PREFIX + "/" + service.getName() ;
        //由于一个接口的实现类可能存在多个jar包中的META-INF目录下，所以下面使用getResources返回一个URL数组
        Enumeration<URL> configFileUrls =  CustomServiceLoader.class.getClassLoader().getResources(mappingConfigFile);
        if(configFileUrls == null){
            return null ;
        }
        List<S> services = new LinkedList<S>();
        while(configFileUrls.hasMoreElements()){
            URL configFileUrl = configFileUrls.nextElement();
            String configContent = IOUtils.toString(configFileUrl.openStream());
            String[] serviceNames = configContent.split("\n");
            for(String serviceName : serviceNames){
                Class serviceClass = CustomServiceLoader.class.getClassLoader().loadClass(serviceName);
                Object serviceInstance = serviceClass.newInstance();
                services.add((S)serviceInstance);
            }
        }
        return services ;
    }

}
```

测试类如下：
```java
package com.mogujie.uni;
import com.mogujie.uni.sl.Animal;
import java.util.List;
/**
 * Created by laibao
 */
public class CustomServiceLoaderTest {
    public static void main(String[] args) throws Exception {
        List<Animal> animals = CustomServiceLoader.loade(Animal.class);
        for (Animal animal : animals){
            animal.eat();
        }
    }
}
```

## Java中的锁
- http://ifeve.com/locks/

可重入锁

Java中的synchronized同步块是可重入的。这意味着如果一个java线程进入了代码中的synchronized同步块，并因此获得了该同步块使用的同步对象对应的管程上的锁，那么这个线程可以进入由同一个管程对象所同步的另一个java代码块。下面是一个例子：
```java
public class Reentrant{
    public synchronized outer(){
        inner();
    }
 
    public synchronized inner(){
        //do something
    }
}

```

注意outer()和inner()都被声明为synchronized，这在Java中和synchronized(this)块等效。如果一个线程调用了outer()，在outer()里调用inner()就没有什么问题，因为这两个方法（代码块）都由同一个管程对象（”this”)所同步。如果一个线程已经拥有了一个管程对象上的锁，那么它就有权访问被这个管程对象同步的所有代码块。这就是可重入。线程可以进入任何一个它已经拥有的锁所同步着的代码块。


## java中的happen before原则
- http://ifeve.com/java-%E4%BD%BF%E7%94%A8-happen-before-%E8%A7%84%E5%88%99%E5%AE%9E%E7%8E%B0%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E7%9A%84%E5%90%8C%E6%AD%A5%E6%93%8D%E4%BD%9C/

happen before（HB）原则，简单来说，java中一个动作的执行要先于另外一个动作，否则就会出错。

HB 有哪些规则？

 1. 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
 2. 锁定规则：在监视器锁上的解锁操作必须在同一个监视器上的加锁操作之前执行。
 3. volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
 4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
 5. 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作；
 6. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
 7. 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
 8. 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始
 
 假设A HB C，那么A对共享变量的修改，对于C来说都是可见的（可见性）。可见性的实现是通过cache protocol（缓存一致性）和memory barrier（内存栅栏）实现的。
 
 例如下面的交替打印奇偶数的例子:
 ```java
/**
 * @desc 程序使用两个线程,实现奇偶数字的打印
 *
 */
public class HappenBefore {

	static int num = 0; // 没有使用volatile关键字修饰符
	static volatile boolean flag = false;

	public static void main(String[] args) {

		Thread t1 = new Thread(() -> {
			Thread.currentThread().setName("1号线程:");
			for (; 100 > num;) {
				if (!flag && (num == 0 || ++num % 2 == 0)) {
					System.out.println(Thread.currentThread().getName() + num);
					flag = true;
				}
			}
		});

		Thread t2 = new Thread(() -> {
			Thread.currentThread().setName("2号线程:");
			for (; 100 > num;) {
				if (flag && (++num % 2 != 0)) {
					System.out.println(Thread.currentThread().getName() + num);
					flag = false;
				}
			}
		});

		t1.start();
		t2.start();
	}
}
 ```
 
 虽然num 变量没有使用volatile,但是程序也可以正常输出0-100(注意**边界值**0和100也要输出来)的奇偶数.同样的,如果num变量使用volatile关键字修饰,但是flag变量没有使用volatile修饰,程序照样可以正常输出结果.程序控制台输出如下所示:
 ```java
 Picked up _JAVA_OPTIONS:   -Dawt.useSystemAAFontSettings=gasp
1号线程:0
2号线程:1
1号线程:2
2号线程:3
1号线程:4
2号线程:5
1号线程:6
2号线程:7
1号线程:8
2号线程:9
1号线程:10
2号线程:11
1号线程:12
2号线程:13
1号线程:14
2号线程:15
1号线程:16
2号线程:17
1号线程:18
2号线程:19
1号线程:20
2号线程:21
1号线程:22
2号线程:23
1号线程:24
2号线程:25
1号线程:26
2号线程:27
1号线程:28
2号线程:29
1号线程:30
2号线程:31
1号线程:32
2号线程:33
1号线程:34
2号线程:35
1号线程:36
2号线程:37
1号线程:38
2号线程:39
1号线程:40
2号线程:41
1号线程:42
2号线程:43
1号线程:44
2号线程:45
1号线程:46
2号线程:47
1号线程:48
2号线程:49
1号线程:50
2号线程:51
1号线程:52
2号线程:53
1号线程:54
2号线程:55
1号线程:56
2号线程:57
1号线程:58
2号线程:59
1号线程:60
2号线程:61
1号线程:62
2号线程:63
1号线程:64
2号线程:65
1号线程:66
2号线程:67
1号线程:68
2号线程:69
1号线程:70
2号线程:71
1号线程:72
2号线程:73
1号线程:74
2号线程:75
1号线程:76
2号线程:77
1号线程:78
2号线程:79
1号线程:80
2号线程:81
1号线程:82
2号线程:83
1号线程:84
2号线程:85
1号线程:86
2号线程:87
1号线程:88
2号线程:89
1号线程:90
2号线程:91
1号线程:92
2号线程:93
1号线程:94
2号线程:95
1号线程:96
2号线程:97
1号线程:98
2号线程:99
1号线程:100
 ```
 
 但是,如果num和flag都没有使用使用volatile关键字修饰的话,那输出会怎样?会卡住,即,输出到某个数字的时候,程序会一直处于等待状态.因为两个线程的共享变量的值,不知道什么时候会从线程的working-memory刷新到内存中.

注意,使用下面的程序也可以达到同样的目的. 
 ```java
/**
 * @desc 程序使用两个线程,实现奇偶数字的打印
 *
 */
public class HappenBefore {

	static volatile int num = 0; // 没有使用volatile关键字修饰符
	static boolean flag = false;

	public static void main(String[] args) {

		Thread t1 = new Thread(() -> {
			Thread.currentThread().setName("1号线程:");
			for (; 1001 > num;) {
				if ((num % 2 == 0) && num < 1001) {
					System.out.println(Thread.currentThread().getName() + num);
					num++;
				}
			}
		});

		Thread t2 = new Thread(() -> {
			Thread.currentThread().setName("2号线程:");
			for (; 1000 > num;) {
				if ((num % 2 != 0)) {
					System.out.println(Thread.currentThread().getName() + num);
					num++;
				}
			}
		});

		t1.start();
		t2.start();
	}
}
 ```
 
 注意t1的边界条件,如果写成1000的话,那么1000有**可能**会被打印出来,也可能不会.
 
 



## java并发控制机制

### AQS底层原理
- https://www.cnblogs.com/waterystone/p/4920797.html

谈到并发，不得不谈ReentrantLock；而谈到ReentrantLock，不得不谈AbstractQueuedSynchronizer（AQS）！
它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。如下图所示：
![此处输入图片的描述][18]

另外还有一个AbstractQueuedLongSynchronizer，它和AbstractQueuedSynchronizer唯一的区别在于，它是以long来表示state，即可以表示更多的state。

下面的内容大多都来自于上面的参考连接里，我觉得版主已经总结的很好了。

类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch...。

AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。

不同的自定义同步器争用共享资源的方式也不同。**自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可**，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：

 - isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
 - tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
 - tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
 - tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
 - tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。
 
 以ReentrantLock为例，**state初始化为0**，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（**state会累加**），这就是**可重入**的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。

再以CountDownLatch以例，任务分为N个子线程去执行，**state也初始化为N（注意和ReentrantLock中state初始值的差异）**（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。

下面我们分析（照抄）一下源码：

此方法是独占模式下线程获取共享资源的顶层入口。**如果获取到资源，线程直接返回，否则进入等待队列**，直到获取到资源为止，且整个过程忽略中断的影响。这也正是lock()的语义，当然不仅仅只限于lock()。获取到资源后，线程就可以去执行其临界区代码了。下面是acquire()的源码：
```java
 /**
     * Acquires in exclusive mode, ignoring interrupts.  Implemented
     * by invoking at least once {@link #tryAcquire},
     * returning on success.  Otherwise the thread is queued, possibly
     * repeatedly blocking and unblocking, invoking {@link
     * #tryAcquire} until success.  This method can be used
     * to implement method {@link Lock#lock}.
     *
     * @param arg the acquire argument.  This value is conveyed to
     *        {@link #tryAcquire} but is otherwise uninterpreted and
     *        can represent anything you like.
     */
    public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
```

函数流程如下：

 1. tryAcquire()尝试直接去获取资源，如果成功则直接返回；
 2. addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；
 3. acquireQueued()使线程在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。
 4. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。

　　这时单凭这4个抽象的函数来看流程还有点朦胧，不要紧，看完接下来的分析后，你就会明白了。就像《大话西游》里唐僧说的：等你明白了舍生取义的道理，你自然会回来和我唱这首歌的。
　　
　　**tryAcquire(int)**
```java
/**
     * Attempts to acquire in exclusive mode. This method should query
     * if the state of the object permits it to be acquired in the
     * exclusive mode, and if so to acquire it.
     *
     * <p>This method is always invoked by the thread performing
     * acquire.  If this method reports failure, the acquire method
     * may queue the thread, if it is not already queued, until it is
     * signalled by a release from some other thread. This can be used
     * to implement method {@link Lock#tryLock()}.
     *
     * <p>The default
     * implementation throws {@link UnsupportedOperationException}.
     *
     * @param arg the acquire argument. This value is always the one
     *        passed to an acquire method, or is the value saved on entry
     *        to a condition wait.  The value is otherwise uninterpreted
     *        and can represent anything you like.
     * @return {@code true} if successful. Upon success, this object has
     *         been acquired.
     * @throws IllegalMonitorStateException if acquiring would place this
     *         synchronizer in an illegal state. This exception must be
     *         thrown in a consistent fashion for synchronization to work
     *         correctly.
     * @throws UnsupportedOperationException if exclusive mode is not supported
     */
    protected boolean tryAcquire(int arg) {
        throw new UnsupportedOperationException();
    }
```
注意这个方法是**没有实现**的，直接throw异常，说好的功能呢？好吧，还记得概述里讲的AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现吗？就是这里了！！！AQS这里只定义了一个接口，具体资源的获取交由自定义同步器去实现了（通过state的get/set/CAS）！！！至于能不能重入，能不能加塞，那就看具体的自定义同步器怎么去设计了！！！当然，自定义同步器在进行资源访问时要考虑线程安全的影响。

　　这里之所以没有定义成abstract，是因为独占模式下只用实现tryAcquire-tryRelease，而共享模式下只用实现tryAcquireShared-tryReleaseShared。如果都定义成abstract，那么每个模式也要去实现另一模式下的接口。说到底，Doug Lea还是站在咱们开发者的角度，尽量减少不必要的工作量。
　　
　　**addWaiter(Node)**
```java
private Node addWaiter(Node mode) {
    //以给定模式构造结点。mode有两种：EXCLUSIVE（独占）和SHARED（共享）
    Node node = new Node(Thread.currentThread(), mode);
    
    //尝试快速方式直接放到队尾。
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    
    //上一步失败则通过enq入队。
    enq(node);
    return node;
}
```

不用再说了，直接看注释吧。这里我们说下Node。Node结点是对每一个访问同步代码的线程的封装，其包含了需要同步的线程本身以及线程的状态，如是否被阻塞，是否等待唤醒，是否已经被取消等。变量waitStatus则表示当前被封装成Node结点的等待状态，共有4种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE。
CANCELLED：值为1，在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的结点，其结点的waitStatus为CANCELLED，即结束状态，进入该状态后的结点将不会再变化。

 - SIGNAL：值为-1，被标识为该等待唤醒状态的后继结点，当其前继结点的线程释放了同步锁或被取消，将会通知该后继结点的线程执行。说白了，就是处于唤醒状态，只要前继结点释放锁，就会通知标识为SIGNAL状态的后继结点的线程执行。
 - CONDITION：值为-2，与Condition相关，该标识的结点处于等待队列中，结点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。
 - PROPAGATE：值为-3，与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。
 - 0状态：值为0，代表初始化状态。
 
 **AQS在判断状态时**，通过用**waitStatus>0表示取消状态**，而waitStatus<0表示有效状态。
 
 **enq(Node)**
 此方法用于将node加入**队尾**。源码如下：
 
 ```java
 private Node enq(final Node node) {
    //CAS"自旋"，直到成功加入队尾
    for (;;) {
        Node t = tail;
        if (t == null) { // 队列为空，创建一个空的标志结点作为head结点，并将tail也指向它。
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {//正常流程，放入队尾
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
 ```
 
 **acquireQueued(Node, int)**
 
 OK，通过tryAcquire()和addWaiter()，该线程获取资源失败，已经被放入等待队列尾部了。聪明的你立刻应该能想到该线程下一部该干什么了吧：**进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源，然后就可以去干自己想干的事了**。没错，就是这样！是不是跟医院排队拿号有点相似~~acquireQueued()就是干这件事：在等待队列中排队拿号（中间没其它事干可以休息），直到拿到号后再返回。这个函数非常关键，还是上源码吧：
 ```java
 final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;//标记是否成功拿到资源
    try {
        boolean interrupted = false;//标记等待过程中是否被中断过
        
        //又是一个“自旋”！
        for (;;) {
            final Node p = node.predecessor();//拿到前驱
            //如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源（可能是老大释放完资源唤醒自己的，当然也可能被interrupt了）。
            if (p == head && tryAcquire(arg)) {
                setHead(node);//拿到资源后，将head指向该结点。所以head所指的标杆结点，就是当前获取到资源的那个结点或null。
                p.next = null; // setHead中node.prev已置为null，此处再将head.next置为null，就是为了方便GC回收以前的head结点。也就意味着之前拿完资源的结点出队了！
                failed = false;
                return interrupted;//返回等待过程中是否被中断过
            }
            
            //如果自己可以休息了，就进入waiting状态，直到被unpark()
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;//如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
 ```
 到这里了，我们先不急着总结acquireQueued()的函数流程，先看看shouldParkAfterFailedAcquire()和parkAndCheckInterrupt()具体干些什么。
 
 **shouldParkAfterFailedAcquire(Node, Node)**
 
 此方法主要用于检查状态，看看自己是否真的可以去休息了（进入waiting状态，如果线程状态转换不熟，可以参考本人上一篇写的Thread详解），万一队列前边的线程都放弃了只是瞎站着，那也说不定，对吧！
 ```java
 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;//拿到前驱的状态
    if (ws == Node.SIGNAL)
        //如果已经告诉前驱拿完号后通知自己一下，那就可以安心休息了
        return true;
    if (ws > 0) {
        /*
         * 如果前驱放弃了，那就一直往前找，直到找到最近一个正常等待的状态，并排在它的后边。
         * 注意：那些放弃的结点，由于被自己“加塞”到它们前边，它们相当于形成一个无引用链，稍后就会被保安大叔赶走了(GC回收)！
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
         //如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下。有可能失败，人家说不定刚刚释放完呢！
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
 ```
 整个流程中，如果前驱结点的状态不是SIGNAL，那么自己就不能安心去休息，需要去找个安心的休息点，同时可以再尝试下看有没有机会轮到自己拿号。
 
 **parkAndCheckInterrupt()**
 
 如果线程找好安全休息点后，那就可以安心去休息了。此方法就是让线程去休息，真正进入等待状态。
 ```java
 private final boolean parkAndCheckInterrupt() {
     LockSupport.park(this);//调用park()使线程进入waiting状态
     return Thread.interrupted();//如果被唤醒，查看自己是不是被中断的。
 }
 ```
 park()会让当前线程进入waiting状态。在此状态下，有两种途径可以唤醒该线程：1）被unpark()；2）被interrupt()。（再说一句，如果线程状态转换不熟，可以参考本人写的Thread详解）。需要注意的是，Thread.interrupted()会清除当前线程的中断标记位。 
 
 OK，看了shouldParkAfterFailedAcquire()和parkAndCheckInterrupt()，现在让我们再回到acquireQueued()，总结下该函数的具体流程：
 
1. 进入队尾后，检查状态，找到安全休息点；
2. 调用park()进入waiting状态，等待unpark()或interrupt()唤醒自己；
3. 被唤醒后，看自己是不是有资格能拿到号。如果拿到，head指向当前结点，并返回从入队到拿到号的整个过程中是否被中断过；如果没拿到，继续流程1。

OK，acquireQueued()分析完之后，我们接下来再回到acquire()！再贴上它的源码吧：
```java
public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
```
再来总结下它的流程吧：

1. 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；
2. 没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；
3. acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。
4. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。

由于此函数是重中之重，我再用流程图总结一下：

![此处输入图片的描述][19]

至此，acquire()的流程终于算是告一段落了。这也就是ReentrantLock.lock()的流程，不信你去看其lock()源码吧，整个函数就是一条acquire(1)！！！


上一小节已经把acquire()说完了，这一小节就来讲讲它的反操作release()吧。此方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。这也正是unlock()的语义，当然不仅仅只限于unlock()。下面是release()的源码：
```java
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;//找到头结点
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);//唤醒等待队列里的下一个线程
        return true;
    }
    return false;
}
```
逻辑并不复杂。它调用tryRelease()来释放资源。有一点需要注意的是，它是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自定义同步器在设计tryRelease()的时候要明确这一点！！

**tryRelease(int)**

此方法尝试去释放指定量的资源。下面是tryRelease()的源码：
```java
protected boolean tryRelease(int arg) {
     throw new UnsupportedOperationException();
 }
```
跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。

**unparkSuccessor(Node)**
此方法用于唤醒等待队列中下一个线程。下面是源码：
```java
private void unparkSuccessor(Node node) {
    //这里，node一般为当前线程所在的结点。
    int ws = node.waitStatus;
    if (ws < 0)//置零当前线程所在的结点状态，允许失败。
        compareAndSetWaitStatus(node, ws, 0);

    Node s = node.next;//找到下一个需要唤醒的结点s
    if (s == null || s.waitStatus > 0) {//如果为空或已取消
        s = null;
        for (Node t = tail; t != null && t != node; t = t.prev)
            if (t.waitStatus <= 0)//从这里可以看出，<=0的结点，都是还有效的结点。
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);//唤醒
}
```
这个函数并不复杂。一句话概括：**用unpark()唤醒等待队列中最前边的那个未放弃线程**，这里我们也用s来表示吧。此时，再和acquireQueued()联系起来，s被唤醒后，进入if (p == head && tryAcquire(arg))的判断（即使p!=head也没关系，它会再进入shouldParkAfterFailedAcquire()寻找一个安全点。这里既然s已经是等待队列中最前边的那个未放弃线程了，那么通过shouldParkAfterFailedAcquire()的调整，s也必然会跑到head的next结点，下一次自旋p==head就成立啦），然后s把自己设置成head标杆结点，表示自己已经获取到资源了，acquire()也返回了！！And then, DO what you WANT!

release()是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。






**acquireShared(int)**
此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。下面是acquireShared()的源码：
```java
 public final void acquireShared(int arg) {
     if (tryAcquireShared(arg) < 0)
         doAcquireShared(arg);
 }
```
这里tryAcquireShared()依然需要自定义同步器去实现。但是AQS已经把其返回值的语义定义好了：负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取。所以这里acquireShared()的流程就是：

 1. tryAcquireShared()尝试获取资源，成功则直接返回；
 2. 失败则通过doAcquireShared()进入等待队列，直到获取到资源为止才返回。
 
 **doAcquireShared(int)**
 此方法用于将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回。下面是doAcquireShared()的源码：
 ```java
 private void doAcquireShared(int arg) {
    final Node node = addWaiter(Node.SHARED);//加入队列尾部
    boolean failed = true;//是否成功标志
    try {
        boolean interrupted = false;//等待过程中是否被中断过的标志
        for (;;) {
            final Node p = node.predecessor();//前驱
            if (p == head) {//如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己的
                int r = tryAcquireShared(arg);//尝试获取资源
                if (r >= 0) {//成功
                    setHeadAndPropagate(node, r);//将head指向自己，还有剩余资源可以再唤醒之后的线程
                    p.next = null; // help GC
                    if (interrupted)//如果等待过程中被打断过，此时将中断补上。
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }
            
            //判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt()
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
 ```
 有木有觉得跟acquireQueued()很相似？对，其实流程并没有太大区别。只不过这里将补中断的selfInterrupt()放到doAcquireShared()里了，而独占模式是放到acquireQueued()之外，其实都一样，不知道Doug Lea是怎么想的。

　　跟独占模式比，**还有一点需要注意的是**，这里只有线程是head.next时（“老二”），才会去尝试获取资源，有剩余的话还会唤醒之后的队友。那么问题就来了，假如老大用完后释放了5个资源，而老二需要6个，老三需要1个，老四需要2个。老大先唤醒老二，老二一看资源不够，他是把资源让给老三呢，还是不让？答案是否定的！老二会继续park()等待其他线程释放资源，也更不会去唤醒老三和老四了。独占模式，同一时刻只有一个线程去执行，这样做未尝不可；但共享模式下，多个线程是可以同时执行的，现在因为老二的资源需求量大，而把后面量小的老三和老四也都卡住了。当然，这并不是问题，只是AQS保证严格按照入队顺序唤醒罢了（保证公平，但降低了并发）。
　　
　　**setHeadAndPropagate(Node, int)**
```java
private void setHeadAndPropagate(Node node, int propagate) {
    Node h = head; 
    setHead(node);//head指向自己
     //如果还有剩余量，继续唤醒下一个邻居线程
    if (propagate > 0 || h == null || h.waitStatus < 0) {
        Node s = node.next;
        if (s == null || s.isShared())
            doReleaseShared();
    }
}
```
此方法在setHead()的基础上多了一步，就是自己苏醒的同时，如果条件符合（比如还有剩余资源），还会去唤醒后继结点，毕竟是共享模式！

　　doReleaseShared()我们留着下一小节的releaseShared()里来讲。
　　
　　OK，至此，acquireShared()也要告一段落了。让我们再梳理一下它的流程：

tryAcquireShared()尝试获取资源，成功则直接返回；
失败则通过doAcquireShared()进入等待队列park()，直到被unpark()/interrupt()并成功获取到资源才返回。整个等待过程也是忽略中断的。
　　其实跟acquire()的流程大同小异，**只不过多了个自己拿到资源后，还会去唤醒后继队友的操作**（这才是共享嘛）。
　　
　　
　　**releaseShared()**
　　
　　上一小节已经把acquireShared()说完了，这一小节就来讲讲它的反操作releaseShared()吧。此方法是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。下面是releaseShared()的源码：
```java
　　public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {//尝试释放资源
        doReleaseShared();//唤醒后继结点
        return true;
    }
    return false;
}
```

此方法的流程也比较简单，一句话：**释放掉资源后，唤醒后继**。跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。例如，资源总量是13，A（5）和B（7）分别获取到资源并发运行，C（4）来时只剩1个资源就需要等待。A在运行过程中释放掉2个资源量，然后tryReleaseShared(2)返回true唤醒C，C一看只有3个仍不够继续等待；随后B又释放2个，tryReleaseShared(2)返回true唤醒C，C一看有5个够自己用了，然后C就可以跟A和B一起运行。而ReentrantReadWriteLock读锁的tryReleaseShared()只有在完全释放掉资源（state=0）才返回true，所以自定义同步器可以根据需要决定tryReleaseShared()的返回值。

**doReleaseShared()**
此方法主要用于唤醒后继。下面是它的源码：
```java
private void doReleaseShared() {
    for (;;) {
        Node h = head;
        if (h != null && h != tail) {
            int ws = h.waitStatus;
            if (ws == Node.SIGNAL) {
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;
                unparkSuccessor(h);//唤醒后继
            }
            else if (ws == 0 &&
                     !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                continue;
        }
        if (h == head)// head发生变化
            break;
    }
}
```

本节我们详解了独占和共享两种模式下获取-释放资源(acquire-release、acquireShared-releaseShared)的源码，相信大家都有一定认识了。值得注意的是，acquire()和acquireShared()两种方法下，线程在等待队列中都是忽略中断的。AQS也支持响应中断的，acquireInterruptibly()/acquireSharedInterruptibly()即是，这里相应的源码跟acquire()和acquireShared()差不多，这里就不再详解了。

**Mutex（互斥锁）**
Mutex是一个不可重入的互斥锁实现。锁资源（AQS里的state）只有两种状态：0表示未锁定，1表示锁定。下边是Mutex的核心源码：
```java
class Mutex implements Lock, java.io.Serializable {
    // 自定义同步器
    private static class Sync extends AbstractQueuedSynchronizer {
        // 判断是否锁定状态
        protected boolean isHeldExclusively() {
            return getState() == 1;
        }

        // 尝试获取资源，立即返回。成功则返回true，否则false。
        public boolean tryAcquire(int acquires) {
            assert acquires == 1; // 这里限定只能为1个量
            if (compareAndSetState(0, 1)) {//state为0才设置为1，不可重入！
                setExclusiveOwnerThread(Thread.currentThread());//设置为当前线程独占资源
                return true;
            }
            return false;
        }

        // 尝试释放资源，立即返回。成功则为true，否则false。
        protected boolean tryRelease(int releases) {
            assert releases == 1; // 限定为1个量
            if (getState() == 0)//既然来释放，那肯定就是已占有状态了。只是为了保险，多层判断！
                throw new IllegalMonitorStateException();
            setExclusiveOwnerThread(null);
            setState(0);//释放资源，放弃占有状态
            return true;
        }
    }

    // 真正同步类的实现都依赖继承于AQS的自定义同步器！
    private final Sync sync = new Sync();

    //lock<-->acquire。两者语义一样：获取资源，即便等待，直到成功才返回。
    public void lock() {
        sync.acquire(1);
    }

    //tryLock<-->tryAcquire。两者语义一样：尝试获取资源，要求立即返回。成功则为true，失败则为false。
    public boolean tryLock() {
        return sync.tryAcquire(1);
    }

    //unlock<-->release。两者语文一样：释放资源。
    public void unlock() {
        sync.release(1);
    }

    //锁是否占有状态
    public boolean isLocked() {
        return sync.isHeldExclusively();
    }
}
```
同步类在实现时一般都将自定义同步器（sync）定义为内部类，供自己使用；而同步类自己（Mutex）则实现某个接口，对外服务。当然，接口的实现要直接依赖sync，它们在语义上也存在某种对应关系！！而sync只用实现资源state的获取-释放方式tryAcquire-tryRelelase，至于线程的排队、等待、唤醒等，上层的AQS都已经实现好了，我们不用关心。

　　除了Mutex（互斥锁，内部使用CAS实现），ReentrantLock/CountDownLatch/Semphore这些同步类的实现方式都差不多，不同的地方就在获取-释放资源的方式tryAcquire-tryRelelase。掌握了这点，AQS的核心便被攻破了！

### 信号量Semaphore

- https://www.cnblogs.com/dolphin0520/p/3920397.html

Semaphore可以控同时访问的线程个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。
它的两个构造函数如下(注意参数permits可以为负数,此时表示执行任何的acquire操作之前,都必须先执行release操作):
```java
/**
     * Creates a {@code Semaphore} with the given number of
     * permits and nonfair fairness setting.
     *
     * @param permits the initial number of permits available.
     *        This value may be negative, in which case releases
     *        must occur before any acquires will be granted.
     */
    public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }

    /**
     * Creates a {@code Semaphore} with the given number of
     * permits and the given fairness setting.
     *
     * @param permits the initial number of permits available.
     *        This value may be negative, in which case releases
     *        must occur before any acquires will be granted.
     * @param fair {@code true} if this semaphore will guarantee
     *        first-in first-out granting of permits under contention,
     *        else {@code false}
     */
    public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }
```

下面说一下Semaphore类中比较重要的几个方法，首先是acquire()、release()方法：
```java
public void acquire() throws InterruptedException {  }     //获取一个许可
public void acquire(int permits) throws InterruptedException { }    //获取permits个许可
public void release() { }          //释放一个许可
public void release(int permits) { }    //释放permits个许可
```
需要注意的是,acquire方法是阻塞的,如果想要非阻塞的,那么可以使用下面的方法:
```java
public boolean tryAcquire() { };    //尝试获取一个许可，若获取成功，则立即返回true，若获取失败，则立即返回false
public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException { };  //尝试获取一个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false
public boolean tryAcquire(int permits) { }; //尝试获取permits个许可，若获取成功，则立即返回true，若获取失败，则立即返回false
public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException { }; //尝试获取permits个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false
```
此外,可以使用如下方法获取当前信号量中可获取的许可数量(jdk建议一般是在debug或者test时使用该方法):
```java
/**
     * Returns the current number of permits available in this semaphore.
     *
     * <p>This method is typically used for debugging and testing purposes.
     *
     * @return the number of permits available in this semaphore
     */
    public int availablePermits() {
        return sync.getPermits();
    }
```

下面照抄博客上的一个使用信号量进行同步控制的例子,假若一个工厂有5台机器，但是有8个工人，一台机器同时只能被一个工人使用，只有使用完了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现：:
```java
public class TestSemaphore {
	public static void main(String[] args) {
		int N = 8; // 工人数
		Semaphore semaphore = new Semaphore(5); // 机器数目
		for (int i = 0; i < N; i++)
			new Worker(i, semaphore).start();
	}

	static class Worker extends Thread {
		private int num;
		private Semaphore semaphore;

		public Worker(int num, Semaphore semaphore) {
			this.num = num;
			this.semaphore = semaphore;
		}

		@Override
		public void run() {
			try {
				semaphore.acquire();
				System.out.println("工人" + this.num + "占用一个机器在生产...");
				Thread.sleep(2000);
				System.out.println("工人" + this.num + "释放出机器");
				semaphore.release();
			} catch (InterruptedException e) {
				e.printStackTrace();
			}
		}
	}
}
```
程序运行输出:
```java
工人0占用一个机器在生产...
工人1占用一个机器在生产...
工人2占用一个机器在生产...
工人3占用一个机器在生产...
工人5占用一个机器在生产...
工人0释放出机器
工人3释放出机器
工人2释放出机器
工人4占用一个机器在生产...
工人1释放出机器
工人5释放出机器
工人7占用一个机器在生产...
工人6占用一个机器在生产...
工人4释放出机器
工人7释放出机器
工人6释放出机器
```

### CountDownLatch

- https://www.cnblogs.com/dolphin0520/p/3920397.html#undefined

CountDownLatch一般用于实现线程之间的同步等待,即,一个线程是否继续执行,需要依靠其他几个线程是否执行完成.

该类的构造器如下:
```java
/**
     * Constructs a {@code CountDownLatch} initialized with the given count.
     *
     * @param count the number of times {@link #countDown} must be invoked
     *        before threads can pass through {@link #await}
     * @throws IllegalArgumentException if {@code count} is negative
     */
    public CountDownLatch(int count) {
        if (count < 0) throw new IllegalArgumentException("count < 0");
        this.sync = new Sync(count);
    }
```
然后下面这3个方法是CountDownLatch类中最重要的方法：
```java
public void await() throws InterruptedException { };   //调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行
public boolean await(long timeout, TimeUnit unit) throws InterruptedException { };  //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行
public void countDown() { };  //将count值减1
```
下面照抄博客CountDownLatch的例子:
```java
public class TestCountDownLatch {
	public static void main(String[] args) {
		final CountDownLatch latch = new CountDownLatch(2);

		new Thread() {
			public void run() {
				try {
					System.out.println("子线程" + Thread.currentThread().getName() + "正在执行");
					Thread.sleep(3000);
					System.out.println("子线程" + Thread.currentThread().getName() + "执行完毕");
					latch.countDown();
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
			};
		}.start();

		new Thread() {
			public void run() {
				try {
					System.out.println("子线程" + Thread.currentThread().getName() + "正在执行");
					Thread.sleep(3000);
					System.out.println("子线程" + Thread.currentThread().getName() + "执行完毕");
					latch.countDown();
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
			};
		}.start();

		try {
			System.out.println("等待2个子线程执行完毕...");
			latch.await();  //这里执行等待操作
			System.out.println("2个子线程已经执行完毕");
			System.out.println("继续执行主线程");
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
	}
}
```
控制台输出如下:
```java
子线程Thread-0正在执行
子线程Thread-1正在执行
等待2个子线程执行完毕...
子线程Thread-0执行完毕
子线程Thread-1执行完毕
2个子线程已经执行完毕
继续执行主线程
```

### CyclicBarrier
- https://www.cnblogs.com/dolphin0520/p/3920397.html#undefined

通过它可以实现让一组线程等待至某个状态之后再全部同时执行,需要注意的是CyclicBarrier是可以重用的(从名字上就可以看出来，Cycle...).而CountDownLatch是不可以重用的，Semaphore也可以重用.

对于CyclicBarrier，每一次重用都伴随着一个`generation`的周期概念在里面：
```java
    /**
     * Updates state on barrier trip and wakes up everyone.
     * Called only while holding lock.
     */
    private void nextGeneration() {
        // signal completion of last generation
        trip.signalAll();
        // set up next generation
        count = parties;
        generation = new Generation();
    }
```

它的两个构造函数如下(注意,barrierAction是由最后一个达到parties数量的线程去执行的):
```java
/**
     * Creates a new {@code CyclicBarrier} that will trip when the
     * given number of parties (threads) are waiting upon it, and which
     * will execute the given barrier action when the barrier is tripped,
     * performed by the last thread entering the barrier.
     *
     * @param parties the number of threads that must invoke {@link #await}
     *        before the barrier is tripped
     * @param barrierAction the command to execute when the barrier is
     *        tripped, or {@code null} if there is no action
     * @throws IllegalArgumentException if {@code parties} is less than 1
     */
    public CyclicBarrier(int parties, Runnable barrierAction) {
        if (parties <= 0) throw new IllegalArgumentException();
        this.parties = parties;
        this.count = parties;
        this.barrierCommand = barrierAction;
    }

    /**
     * Creates a new {@code CyclicBarrier} that will trip when the
     * given number of parties (threads) are waiting upon it, and
     * does not perform a predefined action when the barrier is tripped.
     *
     * @param parties the number of threads that must invoke {@link #await}
     *        before the barrier is tripped
     * @throws IllegalArgumentException if {@code parties} is less than 1
     */
    public CyclicBarrier(int parties) {
        this(parties, null);
    }
```
然后CyclicBarrier中最重要的方法就是await方法，它有2个重载版本：
```java
public int await() throws InterruptedException, BrokenBarrierException { };
public int await(long timeout, TimeUnit unit)throws InterruptedException,BrokenBarrierException,TimeoutException { };
```

1. 第一个版本比较常用，用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任务；
2. 第二个版本是让这些线程等待至一定的时间，如果还有线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。
 
 以下是一些用例:
 
 假若有若干个线程都要进行写数据操作，并且只有所有线程都完成写数据操作之后，这些线程才能继续做后面的事情，此时就可以利用CyclicBarrier了：
 ```java
public class TestCyclicBarrier {
	public static void main(String[] args) {
		int N = 4;
		CyclicBarrier barrier = new CyclicBarrier(N); // 注意这种方式创建的CyclicBarrier对象,在达到指定的数量后,所有的线程都会继续执行各自后续的任务
		for (int i = 0; i < N; i++)
			new Writer(barrier).start();
	}

	static class Writer extends Thread {
		private CyclicBarrier cyclicBarrier;

		public Writer(CyclicBarrier cyclicBarrier) {
			this.cyclicBarrier = cyclicBarrier;
		}

		@Override
		public void run() {
			System.out.println("线程" + Thread.currentThread().getName() + "正在写入数据...");
			try {
				Thread.sleep(5000); // 以睡眠来模拟写入数据操作
				System.out.println("线程" + Thread.currentThread().getName() + "写入数据完毕，等待其他线程写入完毕");
				cyclicBarrier.await();
			} catch (InterruptedException e) {
				e.printStackTrace();
			} catch (BrokenBarrierException e) {
				e.printStackTrace();
			}
			System.out.println("所有线程写入完毕，继续处理其他任务...");
		}
	}
}
 ```
 
 控制台输出:
 ```java
线程Thread-0正在写入数据...
线程Thread-2正在写入数据...
线程Thread-1正在写入数据...
线程Thread-3正在写入数据...
线程Thread-0写入数据完毕，等待其他线程写入完毕
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-1写入数据完毕，等待其他线程写入完毕
线程Thread-3写入数据完毕，等待其他线程写入完毕
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
 ```

如果说想在所有线程写入操作完之后，进行额外的其他操作可以为CyclicBarrier提供Runnable参数：
```java
public class TestCyclicBarrier2 {
	public static void main(String[] args) {
		int N = 4;
		
		//这种方式创建的CyclicBarrier对象,当达到指定的数量后,最后一个达到指定数量的线程获取执行指定的action操作
		CyclicBarrier barrier = new CyclicBarrier(N, new Runnable() {
			@Override
			public void run() {
				System.out.println("当前线程" + Thread.currentThread().getName());
			}
		});

		for (int i = 0; i < N; i++)
			new Writer(barrier).start();
	}

	static class Writer extends Thread {
		private CyclicBarrier cyclicBarrier;

		public Writer(CyclicBarrier cyclicBarrier) {
			this.cyclicBarrier = cyclicBarrier;
		}

		@Override
		public void run() {
			System.out.println("线程" + Thread.currentThread().getName() + "正在写入数据...");
			try {
				Thread.sleep(5000); // 以睡眠来模拟写入数据操作
				System.out.println("线程" + Thread.currentThread().getName() + "写入数据完毕，等待其他线程写入完毕");
				cyclicBarrier.await();
			} catch (InterruptedException e) {
				e.printStackTrace();
			} catch (BrokenBarrierException e) {
				e.printStackTrace();
			}
			System.out.println("所有线程写入完毕，继续处理其他任务...");
		}
	}
}
```
控制台输出如下:
```java
线程Thread-0正在写入数据...
线程Thread-1正在写入数据...
线程Thread-3正在写入数据...
线程Thread-2正在写入数据...
线程Thread-0写入数据完毕，等待其他线程写入完毕
线程Thread-1写入数据完毕，等待其他线程写入完毕
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-3写入数据完毕，等待其他线程写入完毕
当前线程Thread-2
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
所有线程写入完毕，继续处理其他任务...
```
 下面看一下为await指定等待时间的效果：
 
```java
 public class TestCyclicBarrier3 {
	public static void main(String[] args) {
		int N = 4;
		CyclicBarrier barrier = new CyclicBarrier(N);

		for (int i = 0; i < N; i++) {
			if (i < N - 1)
				new Writer(barrier).start();
			else {
				try {
					Thread.sleep(5000);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
				new Writer(barrier).start();
			}
		}
	}

	static class Writer extends Thread {
		private CyclicBarrier cyclicBarrier;

		public Writer(CyclicBarrier cyclicBarrier) {
			this.cyclicBarrier = cyclicBarrier;
		}

		@Override
		public void run() {
			System.out.println("线程" + Thread.currentThread().getName() + "正在写入数据...");
			try {
				Thread.sleep(5000); // 以睡眠来模拟写入数据操作
				System.out.println("线程" + Thread.currentThread().getName() + "写入数据完毕，等待其他线程写入完毕");
				try {
					cyclicBarrier.await(2000, TimeUnit.MILLISECONDS);
				} catch (TimeoutException e) {
					System.out.println(Thread.currentThread().getName() + "等待超时,抛出了TimeoutException异常");
					e.printStackTrace();
				}
			} catch (InterruptedException e) {
				e.printStackTrace();
			} catch (BrokenBarrierException e) {
				e.printStackTrace();
			}
			System.out.println(Thread.currentThread().getName() + "所有线程写入完毕，继续处理其他任务...");
		}
	}
}
```
 控制台输出如下:
```java
Picked up _JAVA_OPTIONS:   -Dawt.useSystemAAFontSettings=gasp
线程Thread-2正在写入数据...
线程Thread-0正在写入数据...
线程Thread-1正在写入数据...
线程Thread-0写入数据完毕，等待其他线程写入完毕
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-1写入数据完毕，等待其他线程写入完毕
线程Thread-3正在写入数据...
Thread-1等待超时,抛出了TimeoutException异常
java.util.concurrent.BrokenBarrierException
Thread-0所有线程写入完毕，继续处理其他任务...
	at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)
	at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)
	at com.audi.TestCyclicBarrier3$Writer.run(TestCyclicBarrier3.java:41)
java.util.concurrent.TimeoutException
	at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:257)
	at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)
	at com.audi.TestCyclicBarrier3$Writer.run(TestCyclicBarrier3.java:41)
java.util.concurrent.BrokenBarrierExceptionThread-1所有线程写入完毕，继续处理其他任务...
	at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)

	at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)
	at com.audi.TestCyclicBarrier3$Writer.run(TestCyclicBarrier3.java:41)
Thread-2所有线程写入完毕，继续处理其他任务...
线程Thread-3写入数据完毕，等待其他线程写入完毕
java.util.concurrent.BrokenBarrierException
	at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:207)
	at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)
	at com.audi.TestCyclicBarrier3$Writer.run(TestCyclicBarrier3.java:41)
Thread-3所有线程写入完毕，继续处理其他任务...
```
其他线程在等待超时的情况下,会选择一个线程(注意,并不是所有等待的线程都会抛出这个异常)抛出TimeoutException异常,然后继续执行后续的逻辑.
 
 
 下面,看一下CyclicBarrier的重用例子:
```java
 public class TestCyclicBarrier4 {
	public static void main(String[] args) {
		int N = 4;
		CyclicBarrier barrier = new CyclicBarrier(N);

		for (int i = 0; i < N; i++) {
			new Writer(barrier).start();
		}

		try {
			Thread.sleep(25000);
		} catch (InterruptedException e) {
			e.printStackTrace();
		}

		System.out.println("CyclicBarrier重用");

		for (int i = 0; i < N; i++) {
			new Writer(barrier).start();
		}
	}

	static class Writer extends Thread {
		private CyclicBarrier cyclicBarrier;

		public Writer(CyclicBarrier cyclicBarrier) {
			this.cyclicBarrier = cyclicBarrier;
		}

		@Override
		public void run() {
			System.out.println("线程" + Thread.currentThread().getName() + "正在写入数据...");
			try {
				Thread.sleep(5000); // 以睡眠来模拟写入数据操作
				System.out.println("线程" + Thread.currentThread().getName() + "写入数据完毕，等待其他线程写入完毕");
				cyclicBarrier.await();
			} catch (InterruptedException e) {
				e.printStackTrace();
			} catch (BrokenBarrierException e) {
				e.printStackTrace();
			}
			System.out.println(Thread.currentThread().getName() + "所有线程写入完毕，继续处理其他任务...");
		}
	}
}
```
 控制台输出如下:
```java
线程Thread-0正在写入数据...
线程Thread-1正在写入数据...
线程Thread-2正在写入数据...
线程Thread-3正在写入数据...
线程Thread-0写入数据完毕，等待其他线程写入完毕
线程Thread-1写入数据完毕，等待其他线程写入完毕
线程Thread-2写入数据完毕，等待其他线程写入完毕
线程Thread-3写入数据完毕，等待其他线程写入完毕
Thread-3所有线程写入完毕，继续处理其他任务...
Thread-1所有线程写入完毕，继续处理其他任务...
Thread-2所有线程写入完毕，继续处理其他任务...
Thread-0所有线程写入完毕，继续处理其他任务...
**CyclicBarrier重用**
线程Thread-5正在写入数据...
线程Thread-4正在写入数据...
线程Thread-7正在写入数据...
线程Thread-6正在写入数据...
线程Thread-5写入数据完毕，等待其他线程写入完毕
线程Thread-4写入数据完毕，等待其他线程写入完毕
线程Thread-7写入数据完毕，等待其他线程写入完毕
线程Thread-6写入数据完毕，等待其他线程写入完毕
Thread-6所有线程写入完毕，继续处理其他任务...
Thread-5所有线程写入完毕，继续处理其他任务...
Thread-7所有线程写入完毕，继续处理其他任务...
Thread-4所有线程写入完毕，继续处理其他任务...
```
 
 

## Exchanger

- https://java2blog.com/java-exchanger-example/

用于**两个线程**之间交换数据。如下图所示：

![Exchanger](./image/interview/Exchanger.png)

该类有两个重载方法，源码如下：
```java
    /**
     * Waits for another thread to arrive at this exchange point (unless
     * the current thread is {@linkplain Thread#interrupt interrupted}),
     * and then transfers the given object to it, receiving its object
     * in return.
     *
     * <p>If another thread is already waiting at the exchange point then
     * it is resumed for thread scheduling purposes and receives the object
     * passed in by the current thread.  The current thread returns immediately,
     * receiving the object passed to the exchange by that other thread.
     *
     * <p>If no other thread is already waiting at the exchange then the
     * current thread is disabled for thread scheduling purposes and lies
     * dormant until one of two things happens:
     * <ul>
     * <li>Some other thread enters the exchange; or
     * <li>Some other thread {@linkplain Thread#interrupt interrupts}
     * the current thread.
     * </ul>
     * <p>If the current thread:
     * <ul>
     * <li>has its interrupted status set on entry to this method; or
     * <li>is {@linkplain Thread#interrupt interrupted} while waiting
     * for the exchange,
     * </ul>
     * then {@link InterruptedException} is thrown and the current thread's
     * interrupted status is cleared.
     *
     * @param x the object to exchange
     * @return the object provided by the other thread
     * @throws InterruptedException if the current thread was
     *         interrupted while waiting
     */
    @SuppressWarnings("unchecked")
    public V exchange(V x) throws InterruptedException {
        Object v;
        Object item = (x == null) ? NULL_ITEM : x; // translate null args
        if ((arena != null ||
             (v = slotExchange(item, false, 0L)) == null) &&
            ((Thread.interrupted() || // disambiguates null return
              (v = arenaExchange(item, false, 0L)) == null)))
            throw new InterruptedException();
        return (v == NULL_ITEM) ? null : (V)v;
    }

    /**
     * Waits for another thread to arrive at this exchange point (unless
     * the current thread is {@linkplain Thread#interrupt interrupted} or
     * the specified waiting time elapses), and then transfers the given
     * object to it, receiving its object in return.
     *
     * <p>If another thread is already waiting at the exchange point then
     * it is resumed for thread scheduling purposes and receives the object
     * passed in by the current thread.  The current thread returns immediately,
     * receiving the object passed to the exchange by that other thread.
     *
     * <p>If no other thread is already waiting at the exchange then the
     * current thread is disabled for thread scheduling purposes and lies
     * dormant until one of three things happens:
     * <ul>
     * <li>Some other thread enters the exchange; or
     * <li>Some other thread {@linkplain Thread#interrupt interrupts}
     * the current thread; or
     * <li>The specified waiting time elapses.
     * </ul>
     * <p>If the current thread:
     * <ul>
     * <li>has its interrupted status set on entry to this method; or
     * <li>is {@linkplain Thread#interrupt interrupted} while waiting
     * for the exchange,
     * </ul>
     * then {@link InterruptedException} is thrown and the current thread's
     * interrupted status is cleared.
     *
     * <p>If the specified waiting time elapses then {@link
     * TimeoutException} is thrown.  If the time is less than or equal
     * to zero, the method will not wait at all.
     *
     * @param x the object to exchange
     * @param timeout the maximum time to wait
     * @param unit the time unit of the {@code timeout} argument
     * @return the object provided by the other thread
     * @throws InterruptedException if the current thread was
     *         interrupted while waiting
     * @throws TimeoutException if the specified waiting time elapses
     *         before another thread enters the exchange
     */
    @SuppressWarnings("unchecked")
    public V exchange(V x, long timeout, TimeUnit unit)
        throws InterruptedException, TimeoutException {
        Object v;
        Object item = (x == null) ? NULL_ITEM : x;
        long ns = unit.toNanos(timeout);
        if ((arena != null ||
             (v = slotExchange(item, true, ns)) == null) &&
            ((Thread.interrupted() ||
              (v = arenaExchange(item, true, ns)) == null)))
            throw new InterruptedException();
        if (v == TIMED_OUT)
            throw new TimeoutException();
        return (v == NULL_ITEM) ? null : (V)v;
    }
```

下面看一个实际的例子，演示Exchager的用法：

## 调试利器-SSH隧道
- https://segmentfault.com/a/1190000011846777

## 限流

- https://www.cnblogs.com/clds/p/5850070.html
- http://jinnianshilongnian.iteye.com/blog/2305117
- https://crossoverjie.top/2018/04/28/sbc/sbc7-Distributed-Limit/

### 单机
首先针对单机场景:
可以使用的限流算法大概有计数器限流,漏桶算法,令牌桶算法等.

#### 计数器限流算法
 
 简单来说就是:在固定的时间间隔内,只允许固定数量的访问请求.使用一张参考链接里的示意图:
 ![此处输入图片的描述][34]


  该算法虽然实现简单,但是有一个临界问题,具体如下图所示:
  ![此处输入图片的描述][35]


  在临界值附近,系统还是有可能接收到比自己处理能力范围内多的多的请求.为了解决这个问题 ,我们使用滑动窗口方法,这个类似于计算机网络里的滑动窗口的概念.示意图如下:
  ![此处输入图片的描述][36]


  思路其实就是将计数器的时间窗口细化,这样相对可以减小请求对系统的冲击,窗口划分的越细,请求的控制越严格,根据实际区块来选择时间窗口的长短.
  
#### 漏桶算法
 ![此处输入图片的描述][37]


  思想也很简单,就是先将系统的请求统一的收集起来,后端在处理的时候再统一按照恒定的速率获取请求,进行相应的处理.代码实现的话,可以使用有界队列来存放请求,也可以使用ActiveMQ消息队列来实现.
  
#### 令牌桶算法
 
令牌桶限流算法与漏桶限流算法很类似,只是令牌桶算法在决定是否处理请求的时候,需要依靠能否获取到令牌来决定.令牌(token)以固定的速率增加,每个请求的处理也会从桶中移除固定数量的token.
Guava框架提供了令牌桶算法实现，可直接拿来使用。Guava RateLimiter提供了令牌桶算法实现：平滑突发限流(SmoothBursty)和平滑预热限流(SmoothWarmingUp)实现。
```java

SmoothBursty

RateLimiter limiter = RateLimiter.create(5);
System.out.println(limiter.acquire());
System.out.println(limiter.acquire());
System.out.println(limiter.acquire());
System.out.println(limiter.acquire());
System.out.println(limiter.acquire());
System.out.println(limiter.acquire());
```

控制台输出如下:
```java
0.0
0.194005
0.194746
0.199362
0.200081
```
RateLimiter limiter = RateLimiter.create(5);表示桶初始容量为5,且一秒新增5个令牌,即200ms新增一个令牌.
**SmoothBursty允许一定程度的突发**，会有人担心如果允许这种突发，假设突然间来了很大的流量，那么系统很可能扛不住这种突发。因此需要一种平滑速率的限流工具，从而系统冷启动后慢慢的趋于平均固定速率（即刚开始速率小一些，然后慢慢趋于我们设置的固定速率）。Guava也提供了SmoothWarmingUp来实现这种需求，其可以认为是漏桶算法，但是在某些特殊场景又不太一样。
SmoothWarmingUp创建方式：RateLimiter.create(doublepermitsPerSecond, long warmupPeriod, TimeUnit unit)
permitsPerSecond表示每秒新增的令牌数，warmupPeriod表示在从冷启动速率过渡到平均速率的时间间隔。
示例代码如下:
```java
RateLimiter limiter1 = RateLimiter.create(5, 1000, TimeUnit.MILLISECONDS);
		for (int i = 0; i < 5; i++) {
			System.out.println(limiter1.acquire());
		}
		try {
			Thread.sleep(1000L);
		} catch (InterruptedException e) {
			e.printStackTrace();
		}
		for (int i = 0; i < 5; i++) {
			System.out.println(limiter1.acquire());
		}
```
控制台输出如下:
```java
0.0
0.519917
0.359702
0.219499
0.2002
0.0
0.360285
0.220173
0.199885
0.19952
```


### 分布式限流

前面都是应用级单机限流,如果要做到分布式限流,最关键的是要将限流服务做成原子化，而解决方案可以使使用redis+lua或者nginx+lua技术进行实现，通过这两种技术可以实现的高并发和高性能。

#### redis+lua分布式限流
 
 首先我们来使用redis+lua实现时间窗内某个接口的请求数限流，实现了该功能后可以改造为限流总并发/请求数和限制总资源数。Lua本身就是一种编程语言，也可以使用它实现复杂的令牌桶或漏桶算法。
 lua脚本如下:
```lua
local key = KEYS[1] --限流KEY（一秒一个）
local limit = tonumber(ARGV[1]) --限流大小
local current = tonumber(redis.call('get', key) or "0")
if current + 1 > limit then --如果超出限流大小
    return 0
else --请求数+1，并设置2秒过期
    redis.call("INCRBY", key,"1")
    redis.call("expire", key,"2")
    return 1
end
```
 如下是Java中判断是否需要限流的代码：
```java
public static boolean acquire() throws Exception {
String luaScript = Files.toString(new File("limit.lua"), Charset.defaultCharset());
Jedis jedis = new Jedis("192.168.147.52", 6379);
String key = "ip:" + System.currentTimeMillis()/ 1000; //此处将当前时间戳取秒数
Stringlimit = "3"; //限流大小
return (Long)jedis.eval(luaScript,Lists.newArrayList(key), Lists.newArrayList(limit)) == 1;
}
```
 其中,Lists.newArrayList(key), Lists.newArrayList(limit)会作为参数传入lua脚本.
 
 因为Redis的限制（Lua中有写操作不能使用带随机性质的读操作，如TIME）不能在Redis Lua中使用TIME获取时间戳，因此只好从应用获取然后传入，在某些极端情况下（机器时钟不准的情况下），限流会存在一些小问题。
 
 
#### Nginx+Lua实现限流：

```lua
 local locks = require "resty.lock"
local function acquire()
    local lock =locks:new("locks")
    local elapsed, err =lock:lock("limit_key") --互斥锁
    local limit_counter =ngx.shared.limit_counter --计数器
    local key = "ip:" ..os.time()
    local limit = 5 --限流大小
    local current =limit_counter:get(key)

    if current ~= nil and current + 1> limit then --如果超出限流大小
        lock:unlock()
        return 0
    end
    if current == nil then
        limit_counter:set(key, 1, 1) --第一次需要设置过期时间，设置key的值为1，过期时间为1秒
    else
        limit_counter:incr(key, 1) --第二次开始加1即可
    end
    lock:unlock()
    return 1
end
ngx.print(acquire())
```
 实现中我们需要使用lua-resty-lock互斥锁模块来解决原子性问题(在实际工程中使用时请考虑获取锁的超时问题)，并使用ngx.shared.DICT共享字典来实现计数器。如果需要限流则返回0，否则返回1。使用时需要先定义两个共享字典（分别用来存放锁和计数器数据）：

Java代码

```java
http {  
    ……  
    lua_shared_dict locks 10m;  
    lua_shared_dict limit_counter 10m;  
}  
```
有人会纠结如果应用并发量非常大那么redis或者nginx是不是能抗得住；不过这个问题要从多方面考虑：你的流量是不是真的有这么大，是不是可以通过一致性哈希将分布式限流进行分片，是不是可以当并发量太大降级为应用级限流；对策非常多，可以根据实际情况调节；像在京东使用Redis+Lua来限流抢购流量，一般流量是没有问题的。
 
对于分布式限流目前遇到的场景是业务上的限流，而不是流量入口的限流；流量入口限流应该在接入层完成，而接入层笔者(博客作者)一般使用Nginx。

### Nginx限流原理

- https://www.jdon.com/performance/nginx-dos-protection.html
- https://docs.nginx.com/nginx/admin-guide/security-controls/controlling-access-proxied-http/

漏桶算法与令牌桶算法做一个简单的比较：

漏桶算法能够强行限制数据的传输速率。

令牌桶算法能够在限制数据的平均传输速率的同时还允许某种程度的突发传输（在令牌还富余的情况下）。需要说明的是：在某些情况下，漏桶算法不能够有效地使用网络资源。因为漏桶的漏出速率是固定的，所以即使网络中没有发生拥塞，漏桶算法也不能使某一个单独的数据流达到端口速率。因此，漏桶算法对于存在突发特性的流量来说缺乏效率。而令牌桶算法则能够满足这些具有突发特性的流量。通常，漏桶算法与令牌桶算法结合起来为网络流量提供更高效的控制。

借助nginx限流可以实现以下一些功能：

- The number of connections per key value (for example, per IP address)
- The request rate per key value (the number of requests that are
   allowed to be processed during a second or minute)
- The download speed for a connection

参考nginx官方文档，可知Nginx主要有两种限流方式：按连接数限流(ngx_http_limit_conn_module)、按请求速率限流(ngx_http_limit_req_module 使用的是漏桶算法)。

ngx_http_limit_conn_module限制连接的数量这个好理解，就类似于和服务器建立的管道连接，有一个上限值。

ngx_http_limit_req_module配置就要稍微复杂一些。先看一个nginx的配置：
```java
http {
    ...

    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;

    server {
        ...

        location /search/ {
            limit_req zone=one;
        }
    }
}
```
以上配置nginx的处理速率1秒不大于1次。多余的请求将会被缓存到缓存区one。若缓冲区慢，默认会返回503.


```java
http {
    ...

    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;

    server {
        ...

        location /search/ {
            limit_req zone=one burst=5;
        }
    }
}
```
上面的配置相比于之前的配置多了个参数`burst`。该参数的官方解释是
`The burst parameter of the limit_req directive sets the maximum number of excessive requests that await to be processed at the specified rate.`

With this configuration, if request rate exceeds 1 request per second, requests beyond the rate will be put into the zone one. When the zone is full, excessive requests will be queued (burst), the size of this queue is 5 requests. Request processing in the queue is delayed in such a way that the overall rate is not greater than specified. Requests above the burst limit will be rejected with the 503 error.

此外还可以配置`nodelay`参数，表示在burst内的请求会被及时处理，而不用受`rate`参数的限制(此时，个人认为缓存区就不再有效了)：
```java
http {
    ...

    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;

    server {
        ...

        location /search/ {
            limit_req zone=one burst=5 nodelay;
        }
    }
}
```

### springcloud限流

- https://blog.csdn.net/qq_43220949/article/details/113100098

#### 基于springcloud-gateway的Filter限流

本质上就是基于令牌桶的限流。基于其内置的过滤器工厂RequestRateLimiterGatewayFilterFactory实现。在过滤器工厂中是通过Redis和lua脚本结合的方式进行流量控制。

1、引入依赖
```maven
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-actuator</artifactId>
</dependency>
<dependency>  		 
    <groupId>org.springframework.boot</groupId>
    <artifatId>spring-boot-starter-data-redis-reactive</artifactId>
</dependency>
```

2、修改网关配置
```maven
spring:
  application:
    name: api-gateway #指定服务名
  cloud:
    gateway:
      routes:
      - id: order-service
      uri: lb://shop-service-order
      filters:
      - RewritePath=/order-service/(?<segment>.*), /$\{segment}
      - name: RequestRateLimiter
        args:
          // 使用SpEL从容器中获取对象pathKeyResolver,根据这个对象来进行限流
          key-resolver: '#{@pathKeyResolver}'
         // 令牌桶每秒填充平均速率
          redis-rate-limiter.replenishRate: 1
          // 令牌桶的总容量
          redis-rate-limiter.burstCapacity: 3
  redis:
    host: localhost
    port: 6379
```

3、配置redis中key的解析器KeySesolver（包含上面配置的key-resolver对象pathKeyResolver）

```java
@Configuration
public class KeyResolverConfiguration {

	/**
	 * 编写基于请求路径的限流规则
	 *  //abc
	 */
	//@Bean
	public KeyResolver pathKeyResolver() {
		//自定义的KeyResolver
		return new KeyResolver() {
			/**
			 * ServerWebExchange :
			 *      上下文参数
			 */
			@Override
			public Mono<String> resolve(ServerWebExchange exchange) {
				return Mono.just( exchange.getRequest().getPath().toString());
			}
		};
	}

	/**
	 * 基于请求参数的限流
	 *
	 *  请求 abc ? userId=1
	 */
	@Bean
	public KeyResolver userKeyResolver() {
//        基于请求参数userId的限流
		return exchange -> Mono.just(exchange.getRequest().getQueryParams().getFirst("userId")
			
//基于请求ip的限流                                     //exchange.getRequest().getHeaders().getFirst("X-Forwarded-For") 
		);
	}
}
```

#### 基于Sentinel的限流

1、导入依赖

```maven
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-spring-cloud-gateway-adapter</artifactId>
    <version>1.6.3</version>
</dependency>
```

2、配置类

```java
/**
 * sentinel限流的配置
 */
//@Configuration
public class GatewayConfiguration {

private final List<ViewResolver> viewResolvers;
private final ServerCodecConfigurer serverCodecConfigurer;

public GatewayConfiguration (ObjectProvider<List<ViewResolver>> viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer) {
this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList);
		this.serverCodecConfigurer = serverCodecConfigurer;
	}

	/**
	 * 配置限流的异常处理器:SentinelGatewayBlockExceptionHandler
	 */
	@Bean
	@Order(Ordered.HIGHEST_PRECEDENCE)
	public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() {
		return new SentinelGatewayBlockExceptionHandler(viewResolvers, serverCodecConfigurer);
	}

	/**
	 * 配置限流过滤器
	 */
	@Bean
	@Order(Ordered.HIGHEST_PRECEDENCE)
	public GlobalFilter sentinelGatewayFilter() {
		return new SentinelGatewayFilter();
	}

	/**
	 * 配置初始化的限流参数
	 *  用于指定资源的限流规则.
	 *      1.资源名称 (路由id)
	 *      2.配置统计时间
	 *      3.配置限流阈值
	 */
	@PostConstruct
	public void initGatewayRules() {
		Set<GatewayFlowRule> rules = new HashSet<>();
//		rules.add(new GatewayFlowRule("product-service")
//				.setCount(1)
//				.setIntervalSec(1)
//		);
		rules.add(new GatewayFlowRule("product_api")
			.setCount(1).setIntervalSec(1)
		);


		GatewayRuleManager.loadRules(rules);
	}

	/**
	 * 自定义API限流分组
	 *      1.定义分组
	 *      2.对小组配置限流规则
	 */
	@PostConstruct
	private void initCustomizedApis() {
		Set<ApiDefinition> definitions = new HashSet<>();
        //限流小组1 api1
		ApiDefinition api1 = new ApiDefinition("product_api")
				.setPredicateItems(new HashSet<ApiPredicateItem>() {{
					add(new ApiPathPredicateItem().setPattern("/product-service/product/**").
     //已/product-service/product/开都的所有url			
  setMatchStrategy(SentinelGatewayConstants.URL_MATCH_STRATEGY_PREFIX));
				}});
         //限流小组2 api2
		ApiDefinition api2 = new ApiDefinition("order_api")
				.setPredicateItems(new HashSet<ApiPredicateItem>() {{
					add(new ApiPathPredicateItem().setPattern("/order-service/order")); //完全匹配/order-service/order 的url
				}});
        //将小组通知给sentinel
		definitions.add(api1);
		definitions.add(api2);
	
 GatewayApiDefinitionManager.loadApiDefinitions(definitions);
        //然后在initGatewayRules方法中rule.add添加限流规则
	}

	/**
	 * 自定义限流处理器
	 */
	@PostConstruct
	public void initBlockHandlers() {
		BlockRequestHandler blockHandler = new BlockRequestHandler() {
			public Mono<ServerResponse> handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) {
				Map map = new HashMap();
				map.put("code",001);
				map.put("message","不好意思,限流啦");
				return ServerResponse.status(HttpStatus.OK)
						.contentType(MediaType.APPLICATION_JSON_UTF8)
						.body(BodyInserters.fromObject(map));
			}
		};
		GatewayCallbackManager.setBlockHandler(blockHandler);
	}
}
```

基于Sentinel 的Gateway限流是通过其提供的Filter来完成的，使用时只需注入对应的SentinelGatewayFilter 实例以及 SentinelGatewayBlockExceptionHandler 实例即可。

@PostConstruct定义初始化的加载方法，用于指定资源的限流规则。这里资源的名称为orderservice，统计时间是1秒内，限流阈值是1。表示每秒只能访问一个请求。


## Callable、Future和FutureTask
- https://www.cnblogs.com/dolphin0520/p/3949310.html

 - Callable与Runnable
 
 Runnable接口run()方法返回值为空,所以在执行完任务之后无法返回任何结果。
 
 Callable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个方法，只不过这个方法叫做call()：
 ```java
 @FunctionalInterface
 public interface Callable<V> {
    /**
     * Computes a result, or throws an exception if unable to do so.
     *
     * @return computed result
     * @throws Exception if unable to compute a result
     */
    V call() throws Exception;
}
 ```
 可以看到，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。
 那么怎么使用Callable呢？一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本：
 ```java
 <T> Future<T> submit(Callable<T> task);
<T> Future<T> submit(Runnable task, T result);
Future<?> submit(Runnable task);
 ```
 第一个submit方法里面的参数类型就是Callable。
 一般情况下我们使用第一个submit方法和第三个submit方法，第二个submit方法很少使用。


## java 几种任务调度方法(框架)原理及对比
- https://www.ibm.com/developerworks/cn/java/j-lo-taskschedule/

## Java Timer和TimerTask
- https://www.cnblogs.com/dolphin0520/p/3938991.html

其实就Timer来讲就是一个调度器,而TimerTask呢只是一个实现了run方法的一个类,而具体的TimerTask需要由你自己来实现,例如这样:
```java
Timer timer = new Timer();
timer.schedule(new TimerTask() {
        public void run() {
            System.out.println("abc");
        }
}, 20000 , 1000);
```
TimerTask的任务会在20s以后开始执行,每1秒循环执行一次.

先看一下Timer类的几个调度方法:
```java
/**
     * Schedules the specified task for execution at the specified time.  If
     * the time is in the past, the task is scheduled for immediate execution.
     *
     * @param task task to be scheduled.
     * @param time time at which task is to be executed.
     * @throws IllegalArgumentException if <tt>time.getTime()</tt> is negative.
     * @throws IllegalStateException if task was already scheduled or
     *         cancelled, timer was cancelled, or timer thread terminated.
     * @throws NullPointerException if {@code task} or {@code time} is null
     */
    public void schedule(TimerTask task, Date time) {
        sched(task, time.getTime(), 0);
    }

    /**
     * Schedules the specified task for repeated <i>fixed-delay execution</i>,
     * beginning after the specified delay.  Subsequent executions take place
     * at approximately regular intervals separated by the specified period.
     *
     * <p>In fixed-delay execution, each execution is scheduled relative to
     * the actual execution time of the previous execution.  If an execution
     * is delayed for any reason (such as garbage collection or other
     * background activity), subsequent executions will be delayed as well.
     * In the long run, the frequency of execution will generally be slightly
     * lower than the reciprocal of the specified period (assuming the system
     * clock underlying <tt>Object.wait(long)</tt> is accurate).
     *
     * <p>Fixed-delay execution is appropriate for recurring activities
     * that require "smoothness."  In other words, it is appropriate for
     * activities where it is more important to keep the frequency accurate
     * in the short run than in the long run.  This includes most animation
     * tasks, such as blinking a cursor at regular intervals.  It also includes
     * tasks wherein regular activity is performed in response to human
     * input, such as automatically repeating a character as long as a key
     * is held down.
     *
     * @param task   task to be scheduled.
     * @param delay  delay in milliseconds before task is to be executed.
     * @param period time in milliseconds between successive task executions.
     * @throws IllegalArgumentException if {@code delay < 0}, or
     *         {@code delay + System.currentTimeMillis() < 0}, or
     *         {@code period <= 0}
     * @throws IllegalStateException if task was already scheduled or
     *         cancelled, timer was cancelled, or timer thread terminated.
     * @throws NullPointerException if {@code task} is null
     */
    public void schedule(TimerTask task, long delay, long period) {
        if (delay < 0)
            throw new IllegalArgumentException("Negative delay.");
        if (period <= 0)
            throw new IllegalArgumentException("Non-positive period.");
        sched(task, System.currentTimeMillis()+delay, -period);
    }

    /**
     * Schedules the specified task for repeated <i>fixed-delay execution</i>,
     * beginning at the specified time. Subsequent executions take place at
     * approximately regular intervals, separated by the specified period.
     *
     * <p>In fixed-delay execution, each execution is scheduled relative to
     * the actual execution time of the previous execution.  If an execution
     * is delayed for any reason (such as garbage collection or other
     * background activity), subsequent executions will be delayed as well.
     * In the long run, the frequency of execution will generally be slightly
     * lower than the reciprocal of the specified period (assuming the system
     * clock underlying <tt>Object.wait(long)</tt> is accurate).  As a
     * consequence of the above, if the scheduled first time is in the past,
     * it is scheduled for immediate execution.
     *
     * <p>Fixed-delay execution is appropriate for recurring activities
     * that require "smoothness."  In other words, it is appropriate for
     * activities where it is more important to keep the frequency accurate
     * in the short run than in the long run.  This includes most animation
     * tasks, such as blinking a cursor at regular intervals.  It also includes
     * tasks wherein regular activity is performed in response to human
     * input, such as automatically repeating a character as long as a key
     * is held down.
     *
     * @param task   task to be scheduled.
     * @param firstTime First time at which task is to be executed.
     * @param period time in milliseconds between successive task executions.
     * @throws IllegalArgumentException if {@code firstTime.getTime() < 0}, or
     *         {@code period <= 0}
     * @throws IllegalStateException if task was already scheduled or
     *         cancelled, timer was cancelled, or timer thread terminated.
     * @throws NullPointerException if {@code task} or {@code firstTime} is null
     */
    public void schedule(TimerTask task, Date firstTime, long period) {
        if (period <= 0)
            throw new IllegalArgumentException("Non-positive period.");
        sched(task, firstTime.getTime(), -period);
    }

    /**
     * Schedules the specified task for repeated <i>fixed-rate execution</i>,
     * beginning after the specified delay.  Subsequent executions take place
     * at approximately regular intervals, separated by the specified period.
     *
     * <p>In fixed-rate execution, each execution is scheduled relative to the
     * scheduled execution time of the initial execution.  If an execution is
     * delayed for any reason (such as garbage collection or other background
     * activity), two or more executions will occur in rapid succession to
     * "catch up."  In the long run, the frequency of execution will be
     * exactly the reciprocal of the specified period (assuming the system
     * clock underlying <tt>Object.wait(long)</tt> is accurate).
     *
     * <p>Fixed-rate execution is appropriate for recurring activities that
     * are sensitive to <i>absolute</i> time, such as ringing a chime every
     * hour on the hour, or running scheduled maintenance every day at a
     * particular time.  It is also appropriate for recurring activities
     * where the total time to perform a fixed number of executions is
     * important, such as a countdown timer that ticks once every second for
     * ten seconds.  Finally, fixed-rate execution is appropriate for
     * scheduling multiple repeating timer tasks that must remain synchronized
     * with respect to one another.
     *
     * @param task   task to be scheduled.
     * @param delay  delay in milliseconds before task is to be executed.
     * @param period time in milliseconds between successive task executions.
     * @throws IllegalArgumentException if {@code delay < 0}, or
     *         {@code delay + System.currentTimeMillis() < 0}, or
     *         {@code period <= 0}
     * @throws IllegalStateException if task was already scheduled or
     *         cancelled, timer was cancelled, or timer thread terminated.
     * @throws NullPointerException if {@code task} is null
     */
    public void scheduleAtFixedRate(TimerTask task, long delay, long period) {
        if (delay < 0)
            throw new IllegalArgumentException("Negative delay.");
        if (period <= 0)
            throw new IllegalArgumentException("Non-positive period.");
        sched(task, System.currentTimeMillis()+delay, period);
    }
```

需要注意的是:
```java
public void schedule(TimerTask task, long delay, long period)

public void schedule(TimerTask task, Date firstTime, long period)

public void scheduleAtFixedRate(TimerTask task, long delay, long period)
```
两个schedule方法,如果上一次的调度出现了延迟(比如GC或者其他后台任务),那么后续的调度也会相应的等待.
但是scheduleAtFixedRate方法不会,它会严格按照指定的period周期进行调度,不会因为上一次调度出现等待,而重新计算下一次调度的时间.
其实,查看schedule和scheduleAtFixedRate二者的实现,他们底层都会调用sched方法,只不过在参数传递的时候,schedule传递的是**-period**,scheduleAtFixedRate传递的是period.
下面看一下sched方法的实现源码:
```java
 /**
     * Schedule the specified timer task for execution at the specified
     * time with the specified period, in milliseconds.  If period is
     * positive, the task is scheduled for repeated execution; if period is
     * zero, the task is scheduled for one-time execution. Time is specified
     * in Date.getTime() format.  This method checks timer state, task state,
     * and initial execution time, but not period.
     *
     * @throws IllegalArgumentException if <tt>time</tt> is negative.
     * @throws IllegalStateException if task was already scheduled or
     *         cancelled, timer was cancelled, or timer thread terminated.
     * @throws NullPointerException if {@code task} is null
     */
    private void sched(TimerTask task, long time, long period) {
        if (time < 0)
            throw new IllegalArgumentException("Illegal execution time.");

        // Constrain value of period sufficiently to prevent numeric
        // overflow while still being effectively infinitely large.
        if (Math.abs(period) > (Long.MAX_VALUE >> 1))
            period >>= 1;

        synchronized(queue) {
            if (!thread.newTasksMayBeScheduled)
                throw new IllegalStateException("Timer already cancelled.");

            synchronized(task.lock) {
                if (task.state != TimerTask.VIRGIN)
                    throw new IllegalStateException(
                        "Task already scheduled or cancelled");
                task.nextExecutionTime = time;
                task.period = period;
                task.state = TimerTask.SCHEDULED;
            }

            queue.add(task);
            if (queue.getMin() == task)
                queue.notify();
        }
    }
```
上述方法主要将的就是将task加入到队列queue中.下面看一下queue的定义:
```java
/**
 * This class represents a timer task queue: a priority queue of TimerTasks,
 * ordered on nextExecutionTime.  Each Timer object has one of these, which it
 * shares with its TimerThread.  Internally this class uses a heap, which
 * offers log(n) performance for the add, removeMin and rescheduleMin
 * operations, and constant time performance for the getMin operation.
 */
class TaskQueue {
    /**
     * Priority queue represented as a balanced binary heap: the two children
     * of queue[n] are queue[2*n] and queue[2*n+1].  The priority queue is
     * ordered on the nextExecutionTime field: The TimerTask with the lowest
     * nextExecutionTime is in queue[1] (assuming the queue is nonempty).  For
     * each node n in the heap, and each descendant of n, d,
     * n.nextExecutionTime <= d.nextExecutionTime.
     */
    private TimerTask[] queue = new TimerTask[128];

    /**
     * The number of tasks in the priority queue.  (The tasks are stored in
     * queue[1] up to queue[size]).
     */
    private int size = 0;
```

可见，TaskQueue的结构很简单，为一个数组，加一个size，有点像ArrayList，是不是长度就128呢，当然不是，ArrayList可以扩容，它可以，只是会造成内存拷贝而已，所以一个Timer来讲，只要内部的task个数不超过128是不会造成扩容的；内部提供了add(TimerTask)、size()、getMin()、get(int)、removeMin()、quickRemove(int)、rescheduleMin(long newTime)、isEmpty()、clear()、fixUp()、fixDown()、heapify()；

对于fixUp和fixDown方法来讲，前者是当新增一个task的时候，首先将元素放在队列的尾部，然后向前找是否有比自己还要晚执行的任务，如果有，就将两个任务的顺序进行交换一下。而fixDown正好相反，执行完第一个任务后，需要加上一个时间片得到下一次执行时间，从而需要将其顺序与后面的任务进行对比下。

下面是fixDown的源码:
```java
private void fixDown(int k) {
       int j;
       while ((j = k << 1) <= size && j > 0) {
           if (j < size &&
               queue[j].nextExecutionTime > queue[j+1].nextExecutionTime)
               j++; // j indexes smallest kid
           if (queue[k].nextExecutionTime <= queue[j].nextExecutionTime)
               break;
           TimerTask tmp = queue[j];  queue[j] = queue[k]; queue[k] = tmp;
           k = j;
       }
   }
```
这种方式并非排序，而是找到一个合适的位置来交换，因为并不是通过队列逐个找的，而是每次移动一个二进制位，例如传入1的时候，接下来就是2、4、8、16这些位置，找到合适的位置放下即可，顺序未必是完全有序的，它只需要看到距离调度部分的越近的是有序性越强的时候就可以了，这样即可以保证一定的顺序性，达到较好的性能。

下面看一下cancel方法:
```java
 /**
     * Terminates this timer, discarding any currently scheduled tasks.
     * Does not interfere with a currently executing task (if it exists).
     * Once a timer has been terminated, its execution thread terminates
     * gracefully, and no more tasks may be scheduled on it.
     *
     * <p>Note that calling this method from within the run method of a
     * timer task that was invoked by this timer absolutely guarantees that
     * the ongoing task execution is the last task execution that will ever
     * be performed by this timer.
     *
     * <p>This method may be called repeatedly; the second and subsequent
     * calls have no effect.
     */
    public void cancel() {
        synchronized(queue) {
            thread.newTasksMayBeScheduled = false;
            queue.clear();
            queue.notify();  // In case queue was already empty.
        }
    }
```
从注释中可以看出,这个结束当前调度的task任务,且是优雅终止,即不会终止当前正在执行的任务.

当你对很多Task做了cancel操作后，此时通过调用purge方法实现对这些cancel掉的类空间的回收，上面已经提到，此时会造成顺序混乱，所以需要调用队里的heapify方法来完成顺序的重排(heapify，其实就是将队列的后半截，全部做一次fixeDown的操作，这个操作主要是为了回补quickRemove方法，当大量的quickRmove后，顺序被打乱后，此时将一半的区域做一次非常简单的排序即可。)，源码如下：
```java
/**
     * Removes all cancelled tasks from this timer's task queue.  <i>Calling
     * this method has no effect on the behavior of the timer</i>, but
     * eliminates the references to the cancelled tasks from the queue.
     * If there are no external references to these tasks, they become
     * eligible for garbage collection.
     *
     * <p>Most programs will have no need to call this method.
     * It is designed for use by the rare application that cancels a large
     * number of tasks.  Calling this method trades time for space: the
     * runtime of the method may be proportional to n + c log n, where n
     * is the number of tasks in the queue and c is the number of cancelled
     * tasks.
     *
     * <p>Note that it is permissible to call this method from within a
     * a task scheduled on this timer.
     *
     * @return the number of tasks removed from the queue.
     * @since 1.5
     */
     public int purge() {
         int result = 0;

         synchronized(queue) {
             for (int i = queue.size(); i > 0; i--) {
                 if (queue.get(i).state == TimerTask.CANCELLED) {
                     queue.quickRemove(i);
                     result++;
                 }
             }

             if (result != 0)
                 queue.heapify();
         }

         return result;
     }
```

下面看一下TimerThread类的mainLoop方法:
```java
/**
     * The main timer loop.  (See class comment.)
     */
    private void mainLoop() {
        while (true) {
            try {
                TimerTask task;
                boolean taskFired;
                synchronized(queue) {
                    // Wait for queue to become non-empty
                    while (queue.isEmpty() && newTasksMayBeScheduled)
                        queue.wait();
                    if (queue.isEmpty())
                        break; // Queue is empty and will forever remain; die

                    // Queue nonempty; look at first evt and do the right thing
                    long currentTime, executionTime;
                    task = queue.getMin();
                    synchronized(task.lock) {
                        if (task.state == TimerTask.CANCELLED) {
                            queue.removeMin();
                            continue;  // No action required, poll queue again
                        }
                        currentTime = System.currentTimeMillis();
                        executionTime = task.nextExecutionTime;
                        if (taskFired = (executionTime<=currentTime)) {
                            if (task.period == 0) { // Non-repeating, remove
                                queue.removeMin();
                                task.state = TimerTask.EXECUTED;
                            } else { // Repeating task, reschedule
                                queue.rescheduleMin(
                                  task.period<0 ? currentTime   - task.period
                                                : executionTime + task.period);
                            }
                        }
                    }
                    if (!taskFired) // Task hasn't yet fired; wait
                        queue.wait(executionTime - currentTime);
                }
                if (taskFired)  // Task fired; run it, holding no locks
                    task.run();
            } catch(InterruptedException e) {
            }
        }
    }
```

需要注意一下代码中的task.period这个值,这个值为0的时候表示任务只执行一次.当为正数的时候,就相当于是scheduleAtFixedRate方法在调度;当为负数的时候,就相当于是schedule方法.

另外:
```java
if (taskFired) // Task fired; run it, holding no locks
    task.run();
```
表明线程的执行,是通过单线程方式来执行的.为了达到多线程调度的要求,我们可以使用多个Timer进行调度,但是一般为了达到多线程调度的目的,我们会使用Executors.newScheduledThreadPool来进行任务调度.

二：TimerTask的cancel方法是取消单个任务的执行，即将其状态置为CANCELLED，这样在调用Timer的purge方法时，会将任务队列中状态为CANCELLED的任务清除，并对最小堆进行重排序。
三：任务队列是用最小堆实现的，具体是：用一个数组实现最小堆，下标从1开始。关于这种实现方式可以参考Mark Allen Weiss的【数据结构与算法分析 java语言描述】的最小堆一节。

## springBoot的@Scheduled原理
- https://blog.csdn.net/gaodebao1/article/details/51789225

spring中定时任务可以通过@Scheduled来实现，下面看一下它的实现原理。首先它支持多种使用方式，举例如下：
```java
//定义一个按时间执行的定时任务，在每天16:00执行一次。
@Scheduled(cron = "0 0 16 * * ?")
public void depositJob() {
  //执行代码
}
//定义一个按一定频率执行的定时任务，每隔1分钟执行一次
    @Scheduled(fixedRate = 1000 * 60)
    public void job2() {
    //执行代码
}
//定义一个按一定频率执行的定时任务，每隔1分钟执行一次，延迟1秒执行
    @Scheduled(fixedRate = 1000 * 60,initialDelay = 1000)
    public void updatePayRecords() {
    //执行代码
}
// 或者使用fixedRateString也可以
```

备注：具体参数可以参考“spring-context-4.2.4.RELEASE.jar”下面的“org.springframework.scheduling.annotation.Scheduled"类。

下面跟着源码看看其实现原理（会结合一点项目代码）：
简要介绍：spring在初始化bean后，通过“postProcessAfterInitialization”拦截到所有的用到“@Scheduled”注解的方法，并解析相应的的注解参数，放入“定时任务列表”等待后续处理；之后再“定时任务列表”中统一执行相应的定时任务（任务为顺序执行，先执行cron，之后再执行fixedRate

第一步：依次加载所有的实现Scheduled注解的类方法。
```java
//说明：ScheduledAnnotationBeanPostProcessor继承BeanPostProcessor。
@Override
public Object postProcessAfterInitialization(final Object bean, String beanName) {
          //省略多个判断条件代码
         for (Map.Entry<Method, Set<Scheduled>> entry : annotatedMethods.entrySet()) {
            Method method = entry.getKey();
            for (Scheduled scheduled : entry.getValue()) {
               processScheduled(scheduled, method, bean);
            }
         }
   }
   return bean;
}
```

第二步：将对应类型的定时器放入相应的“定时任务列表”中。

```java
protected void processScheduled(Scheduled scheduled, Method method, Object bean) {
		try {
			Assert.isTrue(method.getParameterTypes().length == 0,
					"Only no-arg methods may be annotated with @Scheduled");

			Method invocableMethod = AopUtils.selectInvocableMethod(method, bean.getClass());
			Runnable runnable = new ScheduledMethodRunnable(bean, invocableMethod);
			boolean processedSchedule = false;
			String errorMessage =
					"Exactly one of the 'cron', 'fixedDelay(String)', or 'fixedRate(String)' attributes is required";

			Set<ScheduledTask> tasks = new LinkedHashSet<ScheduledTask>(4);

			// Determine initial delay
			long initialDelay = scheduled.initialDelay();
			String initialDelayString = scheduled.initialDelayString();
			if (StringUtils.hasText(initialDelayString)) {
				Assert.isTrue(initialDelay < 0, "Specify 'initialDelay' or 'initialDelayString', not both");
				if (this.embeddedValueResolver != null) {
					initialDelayString = this.embeddedValueResolver.resolveStringValue(initialDelayString);
				}
				try {
					initialDelay = Long.parseLong(initialDelayString);
				}
				catch (NumberFormatException ex) {
					throw new IllegalArgumentException(
							"Invalid initialDelayString value \"" + initialDelayString + "\" - cannot parse into integer");
				}
			}

			// Check cron expression
			String cron = scheduled.cron();
			if (StringUtils.hasText(cron)) {
				Assert.isTrue(initialDelay == -1, "'initialDelay' not supported for cron triggers");
				processedSchedule = true;
				String zone = scheduled.zone();
				if (this.embeddedValueResolver != null) {
					cron = this.embeddedValueResolver.resolveStringValue(cron);
					zone = this.embeddedValueResolver.resolveStringValue(zone);
				}
				TimeZone timeZone;
				if (StringUtils.hasText(zone)) {
					timeZone = StringUtils.parseTimeZoneString(zone);
				}
				else {
					timeZone = TimeZone.getDefault();
				}
				tasks.add(this.registrar.scheduleCronTask(new CronTask(runnable, new CronTrigger(cron, timeZone))));
			}

			// At this point we don't need to differentiate between initial delay set or not anymore
			if (initialDelay < 0) {
				initialDelay = 0;
			}

			// Check fixed delay
			long fixedDelay = scheduled.fixedDelay();
			if (fixedDelay >= 0) {
				Assert.isTrue(!processedSchedule, errorMessage);
				processedSchedule = true;
				tasks.add(this.registrar.scheduleFixedDelayTask(new IntervalTask(runnable, fixedDelay, initialDelay)));
			}
			String fixedDelayString = scheduled.fixedDelayString();
			if (StringUtils.hasText(fixedDelayString)) {
				Assert.isTrue(!processedSchedule, errorMessage);
				processedSchedule = true;
				if (this.embeddedValueResolver != null) {
					fixedDelayString = this.embeddedValueResolver.resolveStringValue(fixedDelayString);
				}
				try {
					fixedDelay = Long.parseLong(fixedDelayString);
				}
				catch (NumberFormatException ex) {
					throw new IllegalArgumentException(
							"Invalid fixedDelayString value \"" + fixedDelayString + "\" - cannot parse into integer");
				}
				tasks.add(this.registrar.scheduleFixedDelayTask(new IntervalTask(runnable, fixedDelay, initialDelay)));
			}

			// Check fixed rate
			long fixedRate = scheduled.fixedRate();
			if (fixedRate >= 0) {
				Assert.isTrue(!processedSchedule, errorMessage);
				processedSchedule = true;
				tasks.add(this.registrar.scheduleFixedRateTask(new IntervalTask(runnable, fixedRate, initialDelay)));
			}
			String fixedRateString = scheduled.fixedRateString();
			if (StringUtils.hasText(fixedRateString)) {
				Assert.isTrue(!processedSchedule, errorMessage);
				processedSchedule = true;
				if (this.embeddedValueResolver != null) {
					fixedRateString = this.embeddedValueResolver.resolveStringValue(fixedRateString);
				}
				try {
					fixedRate = Long.parseLong(fixedRateString);
				}
				catch (NumberFormatException ex) {
					throw new IllegalArgumentException(
							"Invalid fixedRateString value \"" + fixedRateString + "\" - cannot parse into integer");
				}
				tasks.add(this.registrar.scheduleFixedRateTask(new IntervalTask(runnable, fixedRate, initialDelay)));
			}

			// Check whether we had any attribute set
			Assert.isTrue(processedSchedule, errorMessage);

			// Finally register the scheduled tasks
			synchronized (this.scheduledTasks) {
				Set<ScheduledTask> registeredTasks = this.scheduledTasks.get(bean);
				if (registeredTasks == null) {
					registeredTasks = new LinkedHashSet<ScheduledTask>(4);
					this.scheduledTasks.put(bean, registeredTasks);
				}
				registeredTasks.addAll(tasks);
			}
		}
		catch (IllegalArgumentException ex) {
			throw new IllegalStateException(
					"Encountered invalid @Scheduled method '" + method.getName() + "': " + ex.getMessage());
		}
	}
```
上面的代码在ScheduledAnnotationBeanPostProcessor类中，它实现了BeanPostProcessor接口。

第三步：执行相应的定时任务。

说明：定时任务先执行corn，判断定时任务的执行时间，计算出相应的下次执行时间，放入线程中，到相应的时间后进行执行。之后执行按“频率”（fixedRate）执行的定时任务，直到所有任务执行结束。

如上图所示：processScheduled方法会先处理cron，再处理fixedDelay，最后是fixedRate。

以fixedDelay为例讲解一下，上面代码中的：
```java
tasks.add(this.registrar.scheduleFixedDelayTask(new IntervalTask(runnable, fixedDelay, initialDelay)));
```
会调用ScheduledTaskRegistrar类的scheduleFixedDelayTask方法进行调度。代码如下：
```java
/**
	 * Schedule the specified fixed-delay task, either right away if possible
	 * or on initialization of the scheduler.
	 * @return a handle to the scheduled task, allowing to cancel it
	 * (or {@code null} if processing a previously registered task)
	 * @since 4.3
	 */
	public ScheduledTask scheduleFixedDelayTask(IntervalTask task) {
		ScheduledTask scheduledTask = this.unresolvedTasks.remove(task);
		boolean newTask = false;
		if (scheduledTask == null) {
			scheduledTask = new ScheduledTask();
			newTask = true;
		}
		if (this.taskScheduler != null) {
			if (task.getInitialDelay() > 0) {
				Date startTime = new Date(System.currentTimeMillis() + task.getInitialDelay());
				scheduledTask.future =
						this.taskScheduler.scheduleWithFixedDelay(task.getRunnable(), startTime, task.getInterval());
			}
			else {
				scheduledTask.future =
						this.taskScheduler.scheduleWithFixedDelay(task.getRunnable(), task.getInterval());
			}
		}
		else {
			addFixedDelayTask(task);
			this.unresolvedTasks.put(task, scheduledTask);
		}
		return (newTask ? scheduledTask : null);
	}
```
该方法内部有两种调度，一个有初始调度InitialDelay，一个没有。以没有的为例：
```java
private TaskScheduler taskScheduler;
```
TaskScheduler接口具有三个实现类，分别是TimerManagerTaskScheduler、ThreadPoolTaskScheduler、ConcurrentTaskScheduler，如下图所示。使用MAT查看对象实例,发现其使用的是ThreadPoolTaskScheduler类。截图如下：
![此处输入图片的描述][38]

![此处输入图片的描述][39]

看一下ThreadPoolTaskScheduler类的scheduleWithFixedDelay方法实现：
```java
	@Override
	public ScheduledFuture<?> scheduleWithFixedDelay(Runnable task, long delay) {
		ScheduledExecutorService executor = getScheduledExecutor();
		try {
			return executor.scheduleWithFixedDelay(errorHandlingTask(task, true), 0, delay, TimeUnit.MILLISECONDS);
		}
		catch (RejectedExecutionException ex) {
			throw new TaskRejectedException("Executor [" + executor + "] did not accept task: " + task, ex);
		}
	}
```
注意看一下getScheduledExecutor方法的实现,该方法直接返回了this.scheduledExecutor：
```java
	/**
	 * Return the underlying ScheduledExecutorService for native access.
	 * @return the underlying ScheduledExecutorService (never {@code null})
	 * @throws IllegalStateException if the ThreadPoolTaskScheduler hasn't been initialized yet
	 */
	public ScheduledExecutorService getScheduledExecutor() throws IllegalStateException {
		Assert.state(this.scheduledExecutor != null, "ThreadPoolTaskScheduler not initialized");
		return this.scheduledExecutor;
	}
```

scheduledExecutor是如何被实例化的?看如下的代码:
```java
	@UsesJava7
	@Override
	protected ExecutorService initializeExecutor(
			ThreadFactory threadFactory, RejectedExecutionHandler rejectedExecutionHandler) {

		this.scheduledExecutor = createExecutor(this.poolSize, threadFactory, rejectedExecutionHandler);

		if (this.removeOnCancelPolicy) {
			if (setRemoveOnCancelPolicyAvailable && this.scheduledExecutor instanceof ScheduledThreadPoolExecutor) {
				((ScheduledThreadPoolExecutor) this.scheduledExecutor).setRemoveOnCancelPolicy(true);
			}
			else {
				logger.info("Could not apply remove-on-cancel policy - not a Java 7+ ScheduledThreadPoolExecutor");
			}
		}

		return this.scheduledExecutor;
	}
```
再看一下createExecutor方法的实现:
```java
/**
	 * Create a new {@link ScheduledExecutorService} instance.
	 * <p>The default implementation creates a {@link ScheduledThreadPoolExecutor}.
	 * Can be overridden in subclasses to provide custom {@link ScheduledExecutorService} instances.
	 * @param poolSize the specified pool size
	 * @param threadFactory the ThreadFactory to use
	 * @param rejectedExecutionHandler the RejectedExecutionHandler to use
	 * @return a new ScheduledExecutorService instance
	 * @see #afterPropertiesSet()
	 * @see java.util.concurrent.ScheduledThreadPoolExecutor
	 */
	protected ScheduledExecutorService createExecutor(
			int poolSize, ThreadFactory threadFactory, RejectedExecutionHandler rejectedExecutionHandler) {

		return new ScheduledThreadPoolExecutor(poolSize, threadFactory, rejectedExecutionHandler);
	}
```
可以看到底层时尚调用的就是ScheduledThreadPoolExecutor类来进行调度.并且默认线程池大小就是1.
```java
private volatile int poolSize = 1;
```


JAVA 实现LRU
==========
https://www.cnblogs.com/lzrabbit/p/3734850.html

可以使用LinkedList+HashMap来实现,代码如下:
```java
package com.audi.cache;

import java.util.*;

/**
 * LinkedList+HashMap实现的LRU
 */
public class TestLRU {

    private static int capacity;
    private static LinkedList list = new LinkedList();
    private static Map<Integer, Integer> map;

    public TestLRU(int capacity) {

        this.capacity = capacity;
        map = new HashMap<>((int) Math.ceil(capacity / 0.75), 0.75f);
    }

    public int get(int key) {
        if (!map.containsKey(key)) {
            return -1;
        }
        int value = map.get(key);
        int pos = list.indexOf(key);
        list.remove(pos);
        list.addFirst(key);
        return value;
    }

    // put操作时需要考虑删除元素
    public void put(int key, int value) {
        if (map.containsKey(key)) {
            int pos = list.indexOf(key);
            list.remove(pos);
        } else {
            if (map.size() >= capacity) {
                int tmpKey = (int) list.getLast();
                map.remove(tmpKey);
                list.removeLast();
            }
        }
        list.addFirst(key);
        map.put(key, value);
    }

    public static void main(String[] args) {
        TestLRU testLRU = new TestLRU(8);
        for (int i = 0; i < 10; i++) {
            testLRU.put(i, i + 100);
            if (i == 5) {
                System.out.println("get test");
                System.out.println("key 1 value  " + testLRU.get(1));
            }
        }

        System.out.println();
        System.out.println("loop print map");
        for (Object key:list){
            System.out.println(key+"  "+map.get((int)key));
        }
    }
}
```
程序运行结果:
```java
get test
key 1 value  101

loop print map
9  109
8  108
7  107
6  106
1  101
5  105
4  104
3  103
Process finished with exit code 0
```
但是上面的代码的效率比较低,因为会涉及到list的遍历,并且,上面的代码是非线程安全的,在多线程环境下需要考虑加锁.

下面是使用LinkedHashMap实现的LRU,需要注意的是使用LinkedHashMap实现LRU,在map满时,它是从map的头部删除元素,get操作获取元素的时候,如果accessOrder为true,那么会将元素移动到map的末尾去:
```java
package com.audi.cache;

import java.util.LinkedHashMap;
import java.util.Map;

/**
 * LinkedHashMap实现LRU
 */
public class TestLRU2<K, V> {

    private LinkedHashMap<K, V> map;

    public TestLRU2(int initCapacity) {
    // 将下面代码的true改为false,其实现的就是FIFO
        this.map = new LinkedHashMap<K, V>((int) Math.ceil(initCapacity / 0.75), 0.75f, true) {
            @Override
            protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
                return size() > initCapacity;
            }
        };
    }

    public V get(K key) {
        if (!map.containsKey(key)) {
            return null;
        }
        return map.get(key);
    }


    public void put(K key, V value) {
        map.put(key, value);
    }

    @Override
    public String toString() {
        StringBuilder stringBuilder = new StringBuilder();
        for (Map.Entry<K, V> entry : map.entrySet()) {
            stringBuilder.append(String.format("%s: %s  ", entry.getKey(), entry.getValue()));
        }
        return stringBuilder.toString();
    }

    public static void main(String[] args) {
        TestLRU2<Integer, Integer> testLRU = new TestLRU2<>(8);
        for (int i = 0; i < 10; i++) {
            testLRU.put(i, i + 100);
            if (i == 5) {
                System.out.println("get test");
                System.out.println("key 1 value  " + testLRU.get(1));
            }
        }

        System.out.println();
        System.out.println("loop print map");
        System.out.println(testLRU);
    }
}
```

如果为了线程安全,可以在方法上加上synchronized关键字,代码输出:
```java
get test
key 1 value  101

loop print map
3: 103  4: 104  5: 105  1: 101  6: 106  7: 107  8: 108  9: 109  
```

注意一下LinkedHashMap的get方法:
```java
/**
     * Returns the value to which the specified key is mapped,
     * or {@code null} if this map contains no mapping for the key.
     *
     * <p>More formally, if this map contains a mapping from a key
     * {@code k} to a value {@code v} such that {@code (key==null ? k==null :
     * key.equals(k))}, then this method returns {@code v}; otherwise
     * it returns {@code null}.  (There can be at most one such mapping.)
     *
     * <p>A return value of {@code null} does not <i>necessarily</i>
     * indicate that the map contains no mapping for the key; it's also
     * possible that the map explicitly maps the key to {@code null}.
     * The {@link #containsKey containsKey} operation may be used to
     * distinguish these two cases.
     */
    public V get(Object key) {
        Node<K,V> e;
        if ((e = getNode(hash(key), key)) == null)
            return null;
        if (accessOrder)
            afterNodeAccess(e);
        return e.value;
    }
```

更进一步的看一下afterNodeAccess方法,源码中的注释// move node to last也印证了上面的说法:
```java
void afterNodeAccess(Node<K,V> e) { // move node to last
        LinkedHashMap.Entry<K,V> last;
        if (accessOrder && (last = tail) != e) {
            LinkedHashMap.Entry<K,V> p =
                (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
            p.after = null;
            // 如果p在map的头部
            if (b == null)
                head = a;
            else
                b.after = a;
            // 如果p不在map的尾部
            if (a != null)
                a.before = b;
            else
                last = b;
            // 如果只有一个map只有一个元素 元素p
            if (last == null)
                head = p;
            else {
                p.before = last;
                last.after = p;
            }
            tail = p;
            ++modCount;
        }
    }
```
注意上面是链表结构,所以不需要逐个移动元素,只需要重新建立链接关系就可以了.

LinkedHashMap
=============

https://blog.csdn.net/justloveyou_/article/details/71713781

下面顺便看一下LinkedHashMap与HashMap的对比:
首先看一下类声明部分:
```java
public class LinkedHashMap<K,V>
    extends HashMap<K,V>
    implements Map<K,V>
```
说明LinkedHashMap源自于HashMap,其实确实如此,LinkedHashMap只是在原来HashMap的数据结构上维持了一个双向链表来保存.本质上，HashMap和双向链表合二为一即是LinkedHashMap。所谓LinkedHashMap，其落脚点在HashMap，因此更准确地说，它是一个将所有Entry节点链入一个双向链表双向链表的HashMap。在LinkedHashMapMap中，所有put进来的Entry都保存在如下面第一个图所示的哈希表中，但由于它又额外定义了一个以head为头结点的双向链表(如下面第二个图所示)，因此对于每次put进来Entry，除了将其保存到哈希表中对应的位置上之外，还会将其插入到双向链表的尾部。
如下图所示:
![此处输入图片的描述][40]
![此处输入图片的描述][41]

其中，HashMap与LinkedHashMap的Entry结构示意图如下图所示：
![此处输入图片的描述][42]

注意上图的,next指针是用于hash冲突时,单链表中使用的.而before/after指针是用于维护整个双向链表使用的.

下面看一下具体的源码,基于JDK1.8版本,先看一下Entry:
```java
/*
     * Implementation note.  A previous version of this class was
     * internally structured a little differently. Because superclass
     * HashMap now uses trees for some of its nodes, class
     * LinkedHashMap.Entry is now treated as intermediary node class
     * that can also be converted to tree form. The name of this
     * class, LinkedHashMap.Entry, is confusing in several ways in its
     * current context, but cannot be changed.  Otherwise, even though
     * it is not exported outside this package, some existing source
     * code is known to have relied on a symbol resolution corner case
     * rule in calls to removeEldestEntry that suppressed compilation
     * errors due to ambiguous usages. So, we keep the name to
     * preserve unmodified compilability.
     *
     * The changes in node classes also require using two fields
     * (head, tail) rather than a pointer to a header node to maintain
     * the doubly-linked before/after list. This class also
     * previously used a different style of callback methods upon
     * access, insertion, and removal.
     */

    /**
     * HashMap.Node subclass for normal LinkedHashMap entries.
     */
    static class Entry<K,V> extends HashMap.Node<K,V> {
        Entry<K,V> before, after;
        Entry(int hash, K key, V value, Node<K,V> next) {
            super(hash, key, value, next);
        }
    }
```
LinkedHashMap的构造函数没什么好说的,注意一下accessOrder就可以了.下面主要看一下LinkedHashMap的存取操作:

首先是put操作,LinkedHashMap的put操作就是HashMap的普通操作.
主要还是看一下get操作:
```java
 /**
     * Returns the value to which the specified key is mapped,
     * or {@code null} if this map contains no mapping for the key.
     *
     * <p>More formally, if this map contains a mapping from a key
     * {@code k} to a value {@code v} such that {@code (key==null ? k==null :
     * key.equals(k))}, then this method returns {@code v}; otherwise
     * it returns {@code null}.  (There can be at most one such mapping.)
     *
     * <p>A return value of {@code null} does not <i>necessarily</i>
     * indicate that the map contains no mapping for the key; it's also
     * possible that the map explicitly maps the key to {@code null}.
     * The {@link #containsKey containsKey} operation may be used to
     * distinguish these two cases.
     */
    public V get(Object key) {
        Node<K,V> e;
        if ((e = getNode(hash(key), key)) == null)
            return null;
        if (accessOrder)
            afterNodeAccess(e);
        return e.value;
    }
```
get方法几乎也就是HashMap的get操作,唯一不一样的就是在后面会根据accessOrder是否为true进行afterNodeAccess方法移动元素位置.具体上面的代码已经写过了,这里不再赘述.

## session cookie token
- https://www.cnblogs.com/moyand/p/9047978.html

这三者一般都是跟用户登录信息紧密相关的。下面依次简单介绍一下：

### cookie
一般而言，cookie都是对客户端而言，是浏览器中存储的一些数据，一般都具有一定的过期时间。且，对于cookie的数据量大小也有一定的要求。

### session

session是针对服务端而言的，主要用于存储用户的登录身份信息，一般对于同一个会话，sessionid都是一样的，我们可以将部分用户信息存储在session中，比如userNo。会话结束，session就自动失效了。由于session存储在服务端，所以可以防止客户端作恶。但是也正是因为session存储在服务端也加重了服务端的负担，尤其是用户量很大的时候。另一个问题，当服务器集群化以后，如何保证用户可以不用重新登录，当然这个可以通过将session统一存储在redis中，但是redis也有单点故障的问题，redis集群化也可以，但是终归还是比较复杂。

### token

token由服务端生成，但是不会存储在服务端，减轻了服务端的压力，并且由于服务端不存储用户登录相关的信息，便于服务器的水平扩展。基于token的用户身份认证流程一般如下：

![此处输入图片的描述][43]

如上图所示，这个token中包含了用户的userID以及针对userID的加盐（秘钥）SHA256 hash，该token通过客户端请求的返回参数传回给客户端，当客户端再次请求服务器的时候需要携带该token，只要按照同样的方式再针对userId生成一次hash，就可以知道用户是否登录过。

类似的，token也可以设置一定的有效期，比如在token中携带登录时的timestamp，并对userId+timestamp生成hash，以后的每次请求除了验证token的正确性以外，还需要并对当前时间和timestamp的间隔，达到过期时间就拒绝访问。


  [1]: https://github.com/Audi-A7/learn/blob/master/source/image/collection/collection.jpg?raw=true
  [2]: https://github.com/Audi-A7/learn/blob/master/source/image/interview/QQ%E6%88%AA%E5%9B%BE20200105233233.png?raw=true
  [3]: https://github.com/Audi-A7/learn/blob/master/source/image/interview/QQ%E6%88%AA%E5%9B%BE20200105234916.png?raw=true
  [4]: http://hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/b860bcc84d51/src/share/native/java/lang/ClassLoader.c
  [5]: https://github.com/WQZ321123/learn/blob/master/source/image/OOM/LeakSuspectsReport.png?raw=true
  [6]: https://github.com/WQZ321123/learn/blob/master/source/image/OOM/5.png?raw=true
  [7]: https://github.com/WQZ321123/learn/blob/master/source/image/OOM/6.png?raw=true
  [8]: https://github.com/WQZ321123/learn/blob/master/source/image/OOM/dominator_tree.png?raw=true
  [9]: https://github.com/WQZ321123/learn/blob/master/source/image/OOM/dominator_tree2.png?raw=true
  [10]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/MyISAM%E4%B8%AD%E7%9A%84B+Tree%E7%B4%A2%E5%BC%95_%E4%B8%BB%E7%B4%A2%E5%BC%95.png?raw=true
  [11]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/MyISAM%E4%B8%AD%E7%9A%84B+Tree%E7%B4%A2%E5%BC%95_%E5%89%AF%E7%B4%A2%E5%BC%95.png?raw=true
  [12]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/InnoDB%E4%B8%AD%E7%9A%84B+Tree%E7%B4%A2%E5%BC%95_%E4%B8%BB%E7%B4%A2%E5%BC%95.png?raw=true
  [13]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/InnoDB%E4%B8%AD%E7%9A%84B+Tree%E7%B4%A2%E5%BC%95_%E5%89%AF%E7%B4%A2%E5%BC%95.png?raw=true
  [14]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/bitmap_table.png?raw=true
  [15]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/bitmap_sex.png?raw=true
  [16]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/bitmap_marriage.png?raw=true
  [17]: https://github.com/WQZ321123/learn/blob/master/source/image/mysql/bitmap_match.png?raw=true
  [18]: https://github.com/WQZ321123/learn/blob/master/source/image/interview/AQS.png?raw=true
  [19]: https://github.com/WQZ321123/learn/blob/master/source/image/interview/tryAcquire.png?raw=true
  [20]: https://github.com/WQZ321123/learn/blob/master/source/image/%E4%B8%BB%E5%86%85%E5%AD%98%E5%92%8C%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AD%98.jpg?raw=true
  [21]: https://github.com/WQZ321123/learn/blob/master/source/image/perm/remove_perm.png?raw=true
  [22]: https://github.com/WQZ321123/learn/blob/master/source/image/Throwable.png?raw=true
  [23]: https://github.com/WQZ321123/learn/blob/master/source/image/Throwable_result.png?raw=true
  [24]: https://github.com/WQZ321123/learn/blob/master/source/image/bigData/storm_arch.jpg?raw=true
  [25]: https://github.com/WQZ321123/learn/blob/master/source/image/bigData/stormVShadoop.jpg?raw=true
  [26]: https://github.com/WQZ321123/learn/blob/master/source/image/distributed/localMessageTable.png?raw=true
  [27]: https://github.com/WQZ321123/learn/blob/master/source/image/distributed/mq_append.png?raw=true
  [28]: https://github.com/WQZ321123/learn/blob/master/source/image/distributed/mq_transcation.png?raw=true
  [29]: https://github.com/WQZ321123/learn/blob/master/source/image/distributed/success.png?raw=true
  [30]: https://github.com/WQZ321123/learn/blob/master/source/image/distributed/fail.png?raw=true
  [31]: https://github.com/WQZ321123/learn/blob/master/source/image/distributed/zookeeper_lock.png?raw=true
  [32]: https://github.com/WQZ321123/learn/blob/master/source/image/redis/redis_cluster.png?raw=true
  [33]: https://github.com/WQZ321123/learn/blob/master/source/image/other/interger%E5%8C%85%E8%A3%85%E7%B1%BB.png?raw=true
  [34]: https://github.com/WQZ321123/learn/blob/master/source/image/rateLimit/countLimit.jpg?raw=true
  [35]: https://github.com/WQZ321123/learn/blob/master/source/image/rateLimit/countLimitProblem.jpg?raw=true
  [36]: https://github.com/WQZ321123/learn/blob/master/source/image/rateLimit/slideWindow.jpg?raw=true
  [37]: https://github.com/WQZ321123/learn/blob/master/source/image/rateLimit/leadBucket.png?raw=true
  [38]: https://github.com/WQZ321123/learn/blob/master/source/image/TaskScheduler%E6%8E%A5%E5%8F%A3.png?raw=true
  [39]: https://github.com/WQZ321123/learn/blob/master/source/image/ThreadPoolTaskScheduler%E7%B1%BB.png?raw=true
  [40]: https://github.com/WQZ321123/learn/blob/master/source/image/collection/linkedHashMap1.png?raw=true
  [41]: https://github.com/WQZ321123/learn/blob/master/source/image/collection/linkedHashMap2.jpg?raw=true
  [42]: https://github.com/WQZ321123/learn/blob/master/source/image/collection/linkedHashMap3.jpg?raw=true
  [43]: https://github.com/WQZ321123/learn/blob/master/source/image/other/token.png?raw=true
