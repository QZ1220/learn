# 工作总结

标签（空格分隔）： 并发 一致性 多数据源

---

* [工作总结](#工作总结)
   * [并发问题](#并发问题)
      * [场景介绍：](#场景介绍)
      * [具体是为什么呢？](#具体是为什么呢)
   * [多数据源注意事项](#多数据源注意事项)
      * [mybatis-plus版本：3.0.5](#mybatis-plus版本305)
      * [在一个事务中，多数据源是<strong>不能</strong>发挥效果的。切记！！！](#在一个事务中多数据源是不能发挥效果的切记)
   * [quartz定时任务实现准点只执行一次](#quartz定时任务实现准点只执行一次)
   * [使用mybatis-plus进行动态数据源切换遇到的坑](#使用mybatis-plus进行动态数据源切换遇到的坑)
      * [mybatis-plus版本：3.3.0](#mybatis-plus版本330)
      * [解决方案](#解决方案)
      * [这到底是为什么呢？](#这到底是为什么呢)
   * [AOP与AspectJ](#aop与aspectj)
   * [Lombok 继承时应注意的点](#lombok-继承时应注意的点)
   * [反射获取对象的field](#反射获取对象的field)
   * [官网性能优化过程](#官网性能优化过程)
      * [第一版官网设计](#第一版官网设计)
      * [第二版官网设计](#第二版官网设计)
      * [第三版官网设计](#第三版官网设计)
   * [k8s api学习](#k8s-api学习)
      * [Redeploy Rancher2.x Workload](#redeploy-rancher2x-workload)
      * [Rancher2.x Api](#rancher2x-api)
      * [k8s Api](#k8s-api)
   * [maven中的scope](#maven中的scope)
      * [compile](#compile)
      * [test](#test)
      * [runntime](#runntime)
      * [provided](#provided)
      * [system](#system)
      * [scope的依赖传递](#scope的依赖传递)
      * [import](#import)
   * [记一次数据库优化经历](#记一次数据库优化经历)
   * [兑换逻辑优化](#兑换逻辑优化)
      * [老的兑换逻辑](#老的兑换逻辑)
         * [优点](#优点)
         * [缺点](#缺点)
      * [新的兑换逻辑](#新的兑换逻辑)
         * [优点](#优点-1)
         * [缺点](#缺点-1)
   * [一次qa环境宕机的问题排查](#一次qa环境宕机的问题排查)
      * [为什么会超时](#为什么会超时)
      * [config服务为什么会一直重启](#config服务为什么会一直重启)
      * [根本原因](#根本原因)
   * [生产服务假死排查](#生产服务假死排查)
      * [jvm内存调整](#jvm内存调整)
      * [thread阻塞排查](#thread阻塞排查)
   * [tomcat对于+字符的特殊处理](#tomcat对于字符的特殊处理)
      * [问题描述](#问题描述)
      * [问题定位](#问题定位)
      * [问题解决](#问题解决)
      * [追本溯源](#追本溯源)

## 并发问题

### 场景介绍：
系统存在账单，账单又对应有子账单，分别将bill，subBill吧。
账单的子账单需要审核并且签字（签字需要走第三方机构签字），子账单可以分开审核签字，第三方机构（简称dsf）根据子账单id分别回调给我们签字结果。也就是说，一个子账单就有一个回调。账单的审核流程，记录在task任务表里。

某次，一个账单的两个子账单同时（同一毫秒内）回调回来了。导致，两个线程同时在做签字回调的工作，且两个线程之间没有进行临界资源的限制，导致两个线程虽然都更新了task表的签字状态，但是却没有使审核流程进入到下一个阶段。

根据分析，可能是并发的问题，导致两个线程同时执行，同时提交，最终两个子账单的签字状态都改成已签字，但是却没有流转到下一个阶段。

改进方案：使用数据库的悲观锁，for update。在事务中对处于该阶段的所有子账单进行锁定，直至该事务结束，下一个线程才可以操作这些数据。

实际发现这样改了以后，还是不能实现我们的效果。

### 具体是为什么呢？

因为加了锁以后，导致多个tomcat的处理线程需要进行等待。而回调的保持时间又只有2秒，可能导致超时，超时就会有部分子账单回调失败。

因此我们加入了线程池，但是发现加了以后依然没有达到效果，查看日志发现出现了死锁。


死锁的原因是因为锁定的key是主键id，我们的for update的语句是使用的in作为条件，也就是说一次性会锁定多行数据，但是如果这个id列表的顺序是乱序的话，就可能导致死锁。
比如需要锁定id=1，2，3，4的数据，线程A锁定了id=1，2的数据，线程B锁定了id=3，4的数据，这个时候就产生了死锁。
那对id列表排序，是不是就可以避免死锁了呢？实测结果，貌似并不可以。
最终，我们的解决方案加方法的入口加redis锁，外加手动创建一个线程池【线程池主要为了避免阻塞网络请求，因为业务上，该请求不关心处理结果，只要成功请求到接口就行】来处理签字回调请求。

部分代码如下：
```java
while (true) {
            if (null == stringRedisTemplate.opsForValue().get(contractId)) {
                log.info("transactionId = {}, 开始获取锁", transactionId);
                Boolean lockStatus = stringRedisTemplate.opsForValue().setIfAbsent(contractId, fddCallbackDTO.toString());
                if (Boolean.TRUE.equals(lockStatus)) {
                    log.info("transactionId = {}, 获得锁，开始处理业务逻辑", transactionId);
                    break;
                }
            }
            try {
                log.info("transactionId = {}, 没有获得锁，等待3秒后继续获取", transactionId);
                Thread.sleep(3000L);
            } catch (InterruptedException e) {
                log.error(e.getMessage(), e);
            }
        }
```

创建异步线程池代码如下：
```java
/**
 * https://blog.csdn.net/Muscleheng/article/details/81409672
 * 配置一个线程池处理法大大的回调  避免出现超时
 *
 * @author WangQuanzhou
 * @date 2019-06-19
 */
@Component
@EnableAsync
@Slf4j
public class ThreadPoolTaskConfig {

    // 核心线程数（默认线程数）
    private static final int corePoolSize = 10;
    // 最大线程数
    private static final int maxPoolSize = 100;
    // 允许线程空闲时间（单位：默认为秒）
    private static final int keepAliveTime = 60;
    // 缓冲队列数
    private static final int queueCapacity = 200;
    // 线程池名前缀
    private static final String threadNamePrefix = "Async-task-";

    // bean的名称，默认为首字母小写的方法名
    @Bean("taskExecutor")
    public ThreadPoolTaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(corePoolSize);
        executor.setMaxPoolSize(maxPoolSize);
        executor.setQueueCapacity(queueCapacity);
        executor.setKeepAliveSeconds(keepAliveTime);
        executor.setThreadNamePrefix(threadNamePrefix);

        // 线程池对拒绝任务的处理策略
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        // 初始化
        executor.initialize();
        log.info("thread pool initialized sucess...");
        return executor;
    }
}
```

使用异步线程池方法（注解方式）：
```java
    // 发送提醒短信 1
    @Async("taskExecutor")
    public void sendMessage1() throws InterruptedException {
        log.info("发送短信方法---- 1   执行开始");
        Thread.sleep(5000); // 模拟耗时
        log.info("发送短信方法---- 1   执行结束");
    }

    // 发送提醒短信 2
    @Async("taskExecutor")
    public void sendMessage2() throws InterruptedException {

        log.info("发送短信方法---- 2   执行开始");
        Thread.sleep(2000); // 模拟耗时
        log.info("发送短信方法---- 2   执行结束");
    }
```

## 多数据源注意事项

### mybatis-plus版本：3.0.5

使用mybatis-plus的时候，支持多数据源，这在实际工作中会比较方便。但是也有一些注意事项。比如需要加入dynamic-DataSource的依赖：
```maven
            <dependency>
                <groupId>com.baomidou</groupId>
                <artifactId>dynamic-datasource-spring-boot-starter</artifactId>
                <version>2.5.3</version>
            </dependency>
```

启动类需要加exclude（因为使用的是druid的数据库连接池，所以加的是这个）：
```java
@Slf4j
@EnableFeignClients
@SpringBootApplication(exclude = DruidDataSourceAutoConfigure.class)
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
        log.info("xxx started success...");
    }
}
```

### 在一个事务中，多数据源是**不能**发挥效果的。切记！！！


## quartz定时任务实现准点只执行一次

https://www.jianshu.com/p/52bf3f3aab6c

参考以上文档，实现自己的需求：即要求定时任务的执行时间可以随时更新，且到点只执行一次。

初始方案，想使用jdk自带的定时线程池来做，但是涉及到定时任务的随时更新的需求不好实现。且这种方式没有持久化，一旦服务重启，将会丢失任务。

使用xxl-job执行定时任务，无法实现更新定时任务执行时间的需求。

使用spring自带的schedule来做，也无法实现定时任务的实时更新，且也无法实现任务的持久化。

最终选用quratz来做，首先他可以实现任务的持久化，且可以实时的更新定时任务的执行时间，实现过程结合了上面的参考链接里的示例。

首先引入pom依赖：
```java
        <dependency>
            <groupId>org.quartz-scheduler</groupId>
            <artifactId>quartz</artifactId>
            <version>2.3.2</version>
        </dependency>
        <dependency>
            <groupId>org.quartz-scheduler</groupId>
            <artifactId>quartz-jobs</artifactId>
            <version>2.3.2</version>
        </dependency>
        <dependency>
            <groupId>org.springframework</groupId>
            <artifactId>spring-context-support</artifactId>
        </dependency>
```
quartz的配置：
```java
spring:
  quartz:
    scheduler-name: ark-flow-scheduler
    job-store-type: jdbc
    auto-startup: false
    wait-for-jobs-to-complete-on-shutdown: false
    overwrite-existing-jobs: false
    jdbc:
      #druid的wall filter会影响这里的自动建表
      initialize-schema: never
```
其次，封装一个定任务的实体类对象ScheduleJobInfo：
```java
package com.t4f.web.ark.flow.api.entity;

import com.baomidou.mybatisplus.annotation.IdType;
import com.baomidou.mybatisplus.annotation.TableId;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.quartz.JobDataMap;

import javax.validation.constraints.NotEmpty;
import java.io.Serializable;
import java.util.Date;

@Data
@NoArgsConstructor
@AllArgsConstructor
@Builder
@ApiModel(description = "定时任务实体类")
public class ScheduleJobInfo implements Serializable {
    private static final long serialVersionUID = -1465015133146616824L;

    @TableId(value = "id", type = IdType.AUTO)
    private Integer id;

    /**
     * 任务group的名称
     */
    @NotEmpty(message = "任务group的名称不能为空")
    @ApiModelProperty(value = "任务group的名称", example = "test-group")
    private String groupName;

    /**
     * 任务job的名称
     */
    @NotEmpty(message = "任务job的名称不能为空")
    @ApiModelProperty(value = "任务job的名称", required = true, example = "test-job")
    private String jobName;

    /**
     * 定时任务标识
     */
    @NotEmpty(message = "定时任务标识不能为空")
    @ApiModelProperty(value = "任务的标识", required = true, example = "schedule-job-code")
    private String code;

    /**
     * cron 表达式
     */
    @NotEmpty(message = "定时任务标识不能为空")
    @ApiModelProperty(value = "cron表达式", required = true, example = "*/5 * * * * ?")
    private String cron;

    /**
     * 定时任务执行类
     */
    @NotEmpty(message = "定时任务标识不能为空")
    @ApiModelProperty(value = "定时任务执行类", required = true, example = "com.nanc.modules.schedule.job.CronTestJob")
    private String className;

    /**
     * 成功执行次数
     */
    @ApiModelProperty(hidden = true)
    private Integer succeed;

    /**
     * 失败执行次数
     */
    @ApiModelProperty(hidden = true)
    private Integer fail;

    /**
     * 任务的状态
     * 0 - 代表正在执行
     * 1 - 已删除
     * 2 - 暂停
     */
    @ApiModelProperty(hidden = true)
    private Integer status;


    /**
     * 任务创建的时间
     */
    @ApiModelProperty(hidden = true)
    private Date createTime;

    /**
     * 任务修改的时间
     */
    @ApiModelProperty(hidden = true)
    private Date updateTime;


    /**
     * 定时任务的参数map
     */
    @ApiModelProperty(value = "定时任务执行类", required = false)
    private JobDataMap dataMap;
}
```

然后是quartz的配置类QuartzManager：
```java
package com.t4f.web.ark.flow.api.config;

import com.t4f.web.ark.flow.api.entity.ScheduleJobInfo;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.lang.RandomStringUtils;
import org.apache.commons.lang.StringUtils;
import org.quartz.*;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.scheduling.quartz.SchedulerFactoryBean;
import org.springframework.stereotype.Component;

@Component
@Slf4j
public class QuartzManager {
    @Autowired
    private SchedulerFactoryBean schedulerFactoryBean;

    public static final String JOB_GROUP_NAME = "EXTJWEB_JOBGROUP_NAME";
    public static final String TRIGGER_GROUP_NAME = "EXTJWEB_TRIGGERGROUP_NAME";

    /**
     * 添加任务，使用任务组名（不存在就用默认的），触发器名，触发器组名
     * 并启动
     *
     * @param info
     */
    public Boolean addJob(ScheduleJobInfo info) {
        try {
            Scheduler scheduler = schedulerFactoryBean.getScheduler();

            JobKey jobKey = JobKey.jobKey(info.getJobName(), info.getGroupName());
            JobDetail jobDetail = scheduler.getJobDetail(jobKey);
            if (null != jobDetail) {
                log.info("{}， {} 定时任务已经存在", info.getJobName(), info.getGroupName());
                return Boolean.FALSE;
            }

            // JobDetail 是具体Job实例
            jobDetail = JobBuilder.newJob((Class<? extends Job>) Class.forName(info.getClassName()))
                    .withIdentity(info.getJobName(), info.getGroupName())
                    .usingJobData(info.getDataMap())
                    .build();

            // 基于表达式构建触发器
            CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(info.getCron());
            // CronTrigger表达式触发器 继承于Trigger
            // TriggerBuilder 用于构建触发器实例
            CronTrigger cronTrigger = TriggerBuilder.newTrigger().withIdentity(info.getJobName() + "_trigger", TRIGGER_GROUP_NAME)
                    .withSchedule(cronScheduleBuilder).build();

            scheduler.scheduleJob(jobDetail, cronTrigger);

            //启动
            if (!scheduler.isShutdown()) {
                scheduler.start();
            }
            return Boolean.TRUE;
        } catch (SchedulerException | ClassNotFoundException e) {
            log.error("添加任务失败", e);
            return Boolean.FALSE;
        }
    }

    /**
     * 暂停任务
     *
     * @param info
     */
    public void pauseJob(ScheduleJobInfo info) {
        try {
            Scheduler scheduler = schedulerFactoryBean.getScheduler();
            JobKey jobKey = JobKey.jobKey(info.getJobName(), info.getGroupName());
            scheduler.pauseJob(jobKey);
            log.info("=========================pause job: {} success========================", info.getJobName());
        } catch (Exception e) {
            log.error("", e);
        }
    }

    /**
     * 恢复任务
     *
     * @param info
     */
    public void resumeJob(ScheduleJobInfo info) {
        try {
            Scheduler scheduler = schedulerFactoryBean.getScheduler();
            JobKey jobKey = JobKey.jobKey(info.getJobName(), info.getGroupName());
            scheduler.resumeJob(jobKey);
            log.info("=========================resume job: {} success========================", info.getJobName());
        } catch (Exception e) {
            log.error("", e);
        }
    }

    /**
     * 删除任务，在业务逻辑中需要更新库表的信息
     *
     * @param info
     * @return
     */
    public boolean removeJob(ScheduleJobInfo info) {
        boolean result = true;
        try {

            Scheduler scheduler = schedulerFactoryBean.getScheduler();
            JobKey jobKey = JobKey.jobKey(info.getJobName(), info.getGroupName());
            JobDetail jobDetail = scheduler.getJobDetail(jobKey);
            if (null != jobDetail) {
                result = scheduler.deleteJob(jobKey);
            }
            log.info("=========================remove job: {} {}========================", info.getJobName(), result);
        } catch (Exception e) {
            log.error("", e);
            result = false;
        }
        return result;
    }

    /**
     * 修改定时任务的时间
     *
     * @param info
     * @return
     */
    public boolean modifyJobTime(ScheduleJobInfo info) {
        boolean result = true;
        try {
            Scheduler scheduler = schedulerFactoryBean.getScheduler();
            TriggerKey triggerKey = TriggerKey.triggerKey(info.getJobName() + "_trigger", TRIGGER_GROUP_NAME);
            CronTrigger trigger = (CronTrigger) scheduler.getTrigger(triggerKey);

            String oldTime = trigger.getCronExpression();
            if (!StringUtils.equalsIgnoreCase(oldTime, info.getCron())) {
                CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(info.getCron());
                CronTrigger ct = TriggerBuilder.newTrigger().withIdentity(info.getJobName() + RandomStringUtils.randomAlphabetic(6) + "_trigger", TRIGGER_GROUP_NAME)
                        .withSchedule(cronScheduleBuilder)
                        .build();

                scheduler.rescheduleJob(triggerKey, ct);
                scheduler.resumeTrigger(triggerKey);
            }

        } catch (Exception e) {
            log.error("", e);
            result = false;
        }
        return result;
    }

    /**
     * 启动所有定时任务
     */
    public void startJobs() {
        try {
            Scheduler scheduler = schedulerFactoryBean.getScheduler();
            scheduler.start();
        } catch (SchedulerException e) {
            log.error("", e);
        }
    }
}
```
然后自己封装了一个cron转换的类CronUtil，实现毫秒时间戳转换为cron表达式：
```java
package com.t4f.web.ark.flow.api.util;

import java.text.SimpleDateFormat;
import java.util.Date;

/**
 * 日期转Cron工具类
 *
 * @author WangQuanzhou
 * @date 2019-12-09
 */
public class CronUtil {

    /***
     * convert Date to cron ,eg.  "0 06 10 15 1 ? 2014"
     * @param date  : 时间点
     * @return
     */
    public static String getCron(Date date) {
        String dateFormat = "ss mm HH dd MM ? yyyy";
        return formatDateByPattern(date, dateFormat);
    }

    /***
     * convert Date to cron ,eg.  "0 06 10 15 1 ? 2014"
     * @param time  : 时间戳
     * @return
     */
    public static String getCron(Long time) {
        String dateFormat = "ss mm HH dd MM ? yyyy";
        return formatDateByPattern(new Date(time), dateFormat);
    }

    /***
     *
     * @param date
     * @param dateFormat : e.g:yyyy-MM-dd HH:mm:ss
     * @return
     */
    public static String formatDateByPattern(Date date, String dateFormat) {
        SimpleDateFormat sdf = new SimpleDateFormat(dateFormat);
        String formatTimeStr = null;
        if (date != null) {
            formatTimeStr = sdf.format(date);
        }
        return formatTimeStr;
    }

    public static void main(String[] args) {
        String cron = getCron(new Date());
        System.out.println(cron);
    }
}
```
然后自己封装了一个方法，实现在add定时任务之前删除原有的定时任务，quartz判断同一个job的标准是groupName+jobName，className表示的是需要定时执行的类，dataMap可以存放一些定时执行时携带的业务数据：
```java
    /**
     * 添加定时任务
     *
     * @param groupName
     * @param jobName
     * @param className
     * @param cron
     * @return
     */
    @Override
    public Boolean addTask(String groupName, String jobName, Class<? extends Job> className, String cron, JobDataMap dataMap) {
        log.info("start to add quartz job, groupName = {}, jobName = {}, className = {}, cron = {}",
                groupName, jobName, className.toString(), cron);
        log.info("delete old job...");
        ScheduleJobInfo scheduleJobInfo = new ScheduleJobInfo();
        scheduleJobInfo.setGroupName(groupName);
        scheduleJobInfo.setJobName(jobName);
        quartzManager.removeJob(scheduleJobInfo);

        log.info("add new job...");
        scheduleJobInfo.setCron(cron);
        scheduleJobInfo.setClassName(className.getName());
        scheduleJobInfo.setDataMap(dataMap);
        quartzManager.addJob(scheduleJobInfo);
        log.info("end add quartz job, groupName = {}, jobName = {}, className = {}, cron = {}",
                groupName, jobName, className.getName(), cron);
        return Boolean.TRUE;
    }
```
然后就是调用：
```java
taskService.addTask(TaskName.GROUP_NAME, TaskName.JOB_NAME_4_FLOW_START + Separator.UNDERLINE + server.getId(),StartFlowJobTime.class, CronUtil.getCron(flowStartTimeStamp), jobDataMap);
```
StartFlowJobTime类代码如下，注意其中删除定时任务的代码部分：
```java
package com.t4f.web.ark.flow.api.service.impl;

import lombok.extern.slf4j.Slf4j;
import org.quartz.*;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

/**
 * quartz job
 *
 * @author Cheng Luo
 * @date 2019-12-10 09:44
 */
@Slf4j
@Component
public class StartFlowJobTime implements Job {


    @Override
    @Transactional(rollbackFor = Throwable.class)
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {

        JobKey jobKey = jobExecutionContext.getTrigger().getJobKey();
        try {
            //  定时时间到，开始执行导量的逻辑
            log.info("time is up, start to execute start flow quartz job, jobKey = {}", jobKey.toString());
            JobDataMap dataMap = jobExecutionContext.getJobDetail().getJobDataMap();
            // zi'ji
        } catch (Exception e) {
            log.error("execute start flow quartz job failed, jobKey = {}", jobKey.toString());
            log.error(e.getMessage(), e);
        } finally {
            log.info("execute start flow quartz job end, delete job, jobKey = {}", jobKey.toString());
            // 为保证定时任务只执行一次，在任务执行完成以后，需要删除此定时任务
            JobDetail jobDetail = jobExecutionContext.getJobDetail();
            if (null != jobDetail) {
                try {
                    jobExecutionContext.getScheduler().deleteJob(jobKey);
                } catch (SchedulerException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}
```
 至此，即实现了定时任务只执行一次的需求。


## 使用mybatis-plus进行动态数据源切换遇到的坑

### mybatis-plus版本：3.3.0

前面我们说了，使用mybatis-plus的时候，多数据源将不能生效。这个很好理解，一个事务内，不允许进行数据库链接的切换时正常的。

现在假设有数据源A和B，A为主（默认）数据源，B为第二数据源。

但是，这次遇到了一个不一样的问题。在一个service实现类中，既有数据源A的mapper，也有数据源B的mapper。@DS注解全部放在mapper上的。

导致的问题现象就是，在这个service类中，所有涉及数据库的操作，都是操作的数据源A的表，即便在mapper加了@DS注解强制指定为数据源B也不生效。

### 解决方案

直接将@DS注解提升到service类上。将数据源B的相关mapper全部移动到新创建的一个类中，并且使用@DS("B")指定为B数据源。

其实，这个问题在mybatis-plus的官方文档中，关于[多数据源](https://mp.baomidou.com/guide/dynamic-datasource.html)的部分也有提示。如下图所示：

![dynamic-datasource](./image/2020/mybatis-plus-dynamic-datasource.jpg)

### 这到底是为什么呢？

好在mybatis-plus是开源的，我们可以看一下@DS这个注解的实现原理和过程。

```java
package com.baomidou.dynamic.datasource.annotation;


import java.lang.annotation.*;

/**
 * 注解在类上或方法上来切换数据源
 *
 * @author TaoYu Kanyuxia
 * @since 1.0.0
 */
@Target({ElementType.TYPE, ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface DS {

    /**
     * 组名或者具体数据源名称或者spel参数(#开头)
     *
     * @return 数据源名称
     */
    String value();
}
```

通过继续查找，发现了一个拦截器。

com.baomidou.dynamic.datasource.aop.DynamicDataSourceAnnotationInterceptor

源码也不长，我们直接全部粘贴过来。

```java
package com.baomidou.dynamic.datasource.aop;

import com.baomidou.dynamic.datasource.DynamicDataSourceClassResolver;
import com.baomidou.dynamic.datasource.annotation.DS;
import com.baomidou.dynamic.datasource.processor.DsProcessor;
import com.baomidou.dynamic.datasource.toolkit.DynamicDataSourceContextHolder;
import lombok.Setter;
import org.aopalliance.intercept.MethodInterceptor;
import org.aopalliance.intercept.MethodInvocation;
import org.springframework.core.annotation.AnnotationUtils;

import java.lang.reflect.Method;

/**
 * 动态数据源AOP核心拦截器
 *
 * @author TaoYu
 * @since 1.2.0
 */
public class DynamicDataSourceAnnotationInterceptor implements MethodInterceptor {

    /**
     * SPEL参数标识
     */
    private static final String DYNAMIC_PREFIX = "#";

    @Setter
    private DsProcessor dsProcessor;

    private DynamicDataSourceClassResolver dynamicDataSourceClassResolver = new DynamicDataSourceClassResolver();

    @Override
    public Object invoke(MethodInvocation invocation) throws Throwable {
        try {
            DynamicDataSourceContextHolder.push(determineDatasource(invocation));
            return invocation.proceed();
        } finally {
            DynamicDataSourceContextHolder.poll();
        }
    }

    private String determineDatasource(MethodInvocation invocation) throws Throwable {
        Method method = invocation.getMethod();
        Class<?> declaringClass = dynamicDataSourceClassResolver.targetClass(invocation);
        DS ds = method.isAnnotationPresent(DS.class) ? method.getAnnotation(DS.class)
                : AnnotationUtils.findAnnotation(declaringClass, DS.class);
        String key = ds.value();
        return (!key.isEmpty() && key.startsWith(DYNAMIC_PREFIX)) ? dsProcessor.determineDatasource(invocation, key) : key;
    }
}
```

由于我并没有使用【SPEL参数标识】这种方式来使用@DS，所以在determineDatasource方法内会直接返回key，也就是数据源的名称。

然后这个key会被push到**DynamicDataSourceContextHolder**，这个Holder又是个啥呢？我们再看一下它的源码？

```java
package com.baomidou.dynamic.datasource.toolkit;

import org.springframework.util.StringUtils;

import java.util.ArrayDeque;
import java.util.Deque;

/**
 * 核心基于ThreadLocal的切换数据源工具类
 *
 * @author TaoYu Kanyuxia
 * @since 1.0.0
 */
public final class DynamicDataSourceContextHolder {

    /**
     * 为什么要用链表存储(准确的是栈)
     * <pre>
     * 为了支持嵌套切换，如ABC三个service都是不同的数据源
     * 其中A的某个业务要调B的方法，B的方法需要调用C的方法。一级一级调用切换，形成了链。
     * 传统的只设置当前线程的方式不能满足此业务需求，必须模拟栈，后进先出。
     * </pre>
     */
    @SuppressWarnings("unchecked")
    private static final ThreadLocal<Deque<String>> LOOKUP_KEY_HOLDER = new ThreadLocal() {
        @Override
        protected Object initialValue() {
            return new ArrayDeque();
        }
    };

    private DynamicDataSourceContextHolder() {
    }

    /**
     * 获得当前线程数据源
     *
     * @return 数据源名称
     */
    public static String peek() {
        return LOOKUP_KEY_HOLDER.get().peek();
    }

    /**
     * 设置当前线程数据源
     * <p>
     * 如非必要不要手动调用，调用后确保最终清除
     * </p>
     *
     * @param ds 数据源名称
     */
    public static void push(String ds) {
        LOOKUP_KEY_HOLDER.get().push(StringUtils.isEmpty(ds) ? "" : ds);
    }

    /**
     * 清空当前线程数据源
     * <p>
     * 如果当前线程是连续切换数据源
     * 只会移除掉当前线程的数据源名称
     * </p>
     */
    public static void poll() {
        Deque<String> deque = LOOKUP_KEY_HOLDER.get();
        deque.poll();
        if (deque.isEmpty()) {
            LOOKUP_KEY_HOLDER.remove();
        }
    }

    /**
     * 强制清空本地线程
     * <p>
     * 防止内存泄漏，如手动调用了push可调用此方法确保清除
     * </p>
     */
    public static void clear() {
        LOOKUP_KEY_HOLDER.remove();
    }
}
```

不要看他的代码这么多，本质上其实就是一个ThreadLocal，来存储数据源key。再具体一点，其实是个队列（栈）。

理论上来说，是可以实现多数据源的切换的，但是为什么我在service中调用虽然在dao层使用@DS制定了数据源，还是加载失败了呢？因为使用了@Transactional注解。

这里倒不是说，在事务内切换了数据源，而是一个事务内使用的是一个数据源。由于@Transactional注解默认会加载主数据源，因此即便在底层使用了@DS也不能切换。因为此时数据库链接已经初始化好了。

如果确实需要在@Transactional注解包裹的方法内使用第二数据源，有两个方案：

 - 在service层使用@DS注解「前提是使用的是mybatis-plus」
 - 自己实现事务管理器，在@Transactional中使用transactionManager指定事务管理器实现数据源切换
 

## AOP与AspectJ

 1. https://segmentfault.com/a/1190000022019122


总到来说，AOP（Aspect Orient Programming）是一种思想，是面向对象编程思想的增强。将系统进行横向到切分，在方法到执行前、后、中执行特定到操作从而实现对业务逻辑到更精确到控制。

AOP实现的关键就在于AOP框架自动创建的AOP代理，AOP代理则可分为静态代理和动态代理两大类，其中静态代理是指使用AOP框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强；而动态代理则在运行时借助于JDK动态代理、CGLIB等在内存中“临时”生成AOP动态代理类，因此也被称为运行时增强。

AspectJ是一个易用且功能强大的AOP框架，可以实现更为完善的aop功能。一般，Spring的AOP功能使用JDK、CGlib动态代理实现。性能上，相比于AspectJ的静态织入会差一些。但是，相应的AspectJ也会更为复杂一些。

## Lombok 继承时应注意的点

https://blog.csdn.net/weixin_33953249/article/details/93375061?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase

在使用@Data注解时，需要注意其默认实现的toString方法是没有包含父类的字段信息的。如果需要需要子类的toString方法包含父类的字段，可以再子类上加上：
```json
@ToString(callSuper = true)
```


## 反射获取对象的field

https://blog.csdn.net/qq_32452623/article/details/54025185

需要注意如下所示：

```java
getFields()    获取所有public字段,包括父类字段

getDeclaredFields()   获取所有字段,public和protected和private,但是不包括父类字段
```

如果一个子类想要获取父类的priavte的field，上面两个方法都不能很好满足需求，这个时候可以使用`org.reflections`工具类。里面有很多方法，其中`getAllFields`就可以满足需求。

简单看一下其源码：
```java
    /** get all fields of given {@code type}, up the super class hierarchy, optionally filtered by {@code predicates} */
    public static Set<Field> getAllFields(final Class<?> type, Predicate<? super Field>... predicates) {
        Set<Field> result = Sets.newHashSet();
        for (Class<?> t : getAllSuperTypes(type)) result.addAll(getFields(t, predicates));
        return result;
    }
```

内部分别调用了`getAllSuperTypes`和`getFields`方法，源码如下：
```java
    /** would include {@code Object.class} when {@link #getAllSuperTypes(Class, com.google.common.base.Predicate[])}. default is false. */
    public static boolean includeObject = false;

    /** get all super types of given {@code type}, including, optionally filtered by {@code predicates}
     * <p> include {@code Object.class} if {@link #includeObject} is true */
    public static Set<Class<?>> getAllSuperTypes(final Class<?> type, Predicate<? super Class<?>>... predicates) {
        Set<Class<?>> result = Sets.newLinkedHashSet();
        if (type != null && (includeObject || !type.equals(Object.class))) {
            result.add(type);
            result.addAll(getAllSuperTypes(type.getSuperclass()));
            for (Class<?> ifc : type.getInterfaces()) result.addAll(getAllSuperTypes(ifc));
        }
        return filter(result, predicates);
    }
```

```java
    /** get fields of given {@code type}, optionally filtered by {@code predicates} */
    public static Set<Field> getFields(Class<?> type, Predicate<? super Field>... predicates) {
        return filter(type.getDeclaredFields(), predicates);
    }
```

然后，`getFields`方法内部调用的`getDeclaredFields`方法其实就是`java.lang.Class`里的方法。

所以，总结起来，流程就是：先调用`getAllSuperTypes`获取当前类及其父类的Class对象，然后再调用JDK自己的`getDeclaredFields`获取所有的类属性，最后使用一个Set进行一个去重返回。


## 官网性能优化过程

官网所有服务（包括前后端服务、文件存储、数据库、redis等）均部署在aws云服务器，使用该系统的用户分布在国内外各地。

虽然国内访问aws服务，由于地理限制，即便是做了加速，响应速度上还是存在一定的延时。这里简要记录下，整个官网系统优化的过程。

### 第一版官网设计

第一版官网设计图如下所示：

![web-structure](./image/2021/1.png)

第一版本的官网，图片等资源使用aws的cdn缓存，网站document数据开启gzip配置，访问页面基本需要2-3秒，图片等资源加载则更慢。

document数据等数据慢是因为前台系统的前后端交互使用的是外部网关的url，该url对应的ip在国内，应该使用集群内的虚拟ip访问（该问题在第三版官网优化时得到了改进）

图片等静态资源慢，是因为即便是配置了CDN，由于CDN节点有多个，且aws的CDN节点离国内最近的也在东京，因此速度会受到一定的限制。


### 第二版官网设计

第二版官网设计图如下所示：
![web-structure](./image/2021/2.png)

第二版官网新加了current用户权限接口，由于权限系统只部署在ali集群，所以需要使用forward转发服务，aws服务才能访问到ali集群的open网关，从而实现用户权限数据的获取。

这一版本主要是增强网站的安全性及权限可维护性。

### 第三版官网设计

第三版官网设计图如下所示：
![web-structure](./image/2021/3.png)

第三版本的官网主要优化了性能，请求基本都在毫秒级响应。

 1. 第一个优化点在于图片等静态资源的优化，图片在上传的时候就oss和s3各放一份，cdn也配置成根据用户位置自主决定使用aws还是ali的cdn。
 2. 第二个优化点在于前台系统的前后端交互使用集群内部虚拟ip代替网关的url，从而极大的加快了响应速度。
 

## k8s api学习

由于之前公司使用docker swarm进行服务部署，考虑与世面主流docker服务治理框架接轨，准备切换到k8s。由于之前swarm集群的管理是我们自己通过接入portainer的api实现的，为了统一，我们希望k8s也通过这种方式接入，而不是去rancher等工具上操作。

### Redeploy Rancher2.x Workload

- https://www.cnblogs.com/xiao987334176/p/13162700.html

![web-structure](./image/2021/Redeploy.jpg)


它整个的流程图如上所示。实际配置时，service的名称以及镜像版本等信息都可以通过变量的形式从`自定义运维平台`发送到jenkins，如下图所示：
![web-structure](./image/2021/Redeploy2.jpg)

这种方法确实可以实现k8s集群的更新，但是他不能实现服务的创建、查询、删除等操作（或者说要实现这几个功能代价比较大）。因此放弃。

### Rancher2.x Api

![web-structure](./image/2021/rancher.jpg)

首先不得不说rancher的api之乱（也可能是个人水平有限），包括[官方文档](https://rancher.com/docs/rancher/v2.x/en/api/)关于api的使用介绍，简直无力吐槽。

对于查询接口还好，对于更新等操作，也不清除哪些字段是必传，哪些是非必传，完全靠猜。。。无奈也只有放弃。

### k8s Api

- https://blog.csdn.net/wucong60/article/details/81699196

能走的路只剩下一条，好在k8s的[官方api文档](https://github.com/kubernetes-client/java/tree/master/kubernetes/docs)做的还算清晰，并且提供了[官方sdk](https://mvnrepository.com/artifact/io.kubernetes/client-java)，虽然各个版本的差异也挺大的。。。但总归是官方的，我选的版本信息如下。

```maven
        <dependency>
            <groupId>io.kubernetes</groupId>
            <artifactId>client-java</artifactId>
            <version>10.0.0</version>
        </dependency>
```

![web-structure](./image/2021/k8s.jpg)

由于这次是直接操作k8s的api，因此对于其内部的一些与服务直接相关的概念也必须要清晰，包括pod、deployment、service等。

## maven中的scope

工作中，一般使用maven管理依赖较多。比如一个常用的lombok的依赖：
```java
            <dependency>
                <groupId>org.projectlombok</groupId>
                <artifactId>lombok</artifactId>
                <version>1.18.2</version>
                <scope>provided</scope>
            </dependency>
```

- https://blog.csdn.net/kimylrong/article/details/50353161
- https://www.baeldung.com/maven-dependency-scopes

这里的scope是`provided`，他表示依赖的项目在打包的时候不会被include进去，相关的class可以由其他dependency引入。只参与项目的编译、运行、测试等阶段。

分别详细说下其他scope：

### compile
默认就是compile，什么都不配置也就是意味着compile。compile表示被依赖项目需要参与当前项目的编译，当然后续的测试，运行周期也参与其中，是一个比较强的依赖。打包的时候通常需要包含进去。

### test
scope为test表示依赖项目仅仅参与测试相关的工作，包括测试代码的编译，执行。比较典型的如junit。

### runntime
runntime表示被依赖项目无需参与项目的编译，不过后期的测试和运行周期需要其参与。与compile相比，跳过编译而已，说实话在终端的项目（非开源，企业内部系统）中，和compile区别不是很大。比较常见的如JSR×××的实现，对应的API jar是compile的，具体实现是runtime的，compile只需要知道接口就足够了。oracle jdbc驱动jar包就是一个很好的例子，一般scope为runntime。另外runntime的依赖通常和optional搭配使用，optional为true。我可以用A实现，也可以用B实现。

### provided
provided意味着打包的时候可以不用包进去，别的设施(Web Container)会提供。事实上该依赖理论上可以参与编译，测试，运行等周期。相当于compile，但是在打包阶段做了exclude的动作。

### system
从参与度来说，也provided相同，不过被依赖项不会从maven仓库抓，而是从本地文件系统拿，一定需要配合systemPath属性使用。

### scope的依赖传递
A–>B–>C。当前项目为A，A依赖于B，B依赖于C。知道B在A项目中的scope，那么怎么知道C在A中的scope呢？答案是：
当C是test或者provided时，C直接被丢弃，A不依赖C；
否则A依赖C，C的scope继承于B的scope。

### import

- https://blog.csdn.net/wangjun5159/article/details/104298131

`import`有点特殊，放到最后来说。以下面的依赖举例：
```java
<dependencyManagement>
	<dependencies>
		<dependency>
			<!-- Import dependency management from Spring Boot -->
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-dependencies</artifactId>
			<version>2.1.12.RELEASE</version>
			<type>pom</type>
			<scope>import</scope>
		</dependency>
	</dependencies>
</dependencyManagement>
```

首先，`import`只能用在`dependencyManagement`内部，且`type`必须是`pom`。上面这个依赖表示的意思：
`将spring-boot-dependencies 中dependencyManagement的dependencies，全部引入到当前工程的dependencyManagement中，不会进行依赖传递`。
如果没有`import`：
`将spring-boot-dependencies 的dependencies全部插入到当前工程的dependencies中，并且会依赖传递。`


## 记一次数据库优化经历

我们的定时任务调度是基于[xxl-job](https://github.com/xuxueli/xxl-job)做了点简单的封装而来，版本也比较老了（1.9.1）。

最近发现的问题是打开定时任务调度平台的控制台页面越来越慢，一般没有几分钟根本打不开，就想着要去找下原因。

习惯性的打开浏览器的network查看网络请求，发现请求`chartInfo`这个接口执行的特别慢，然后想着这个肯定是数据查询的接口，他比较慢，那很可能是数据库查询慢，理所当然的想到数据库可能会存在慢查询。

链接mysql，首先看看慢查询监控开没开，执行如下命令：
```mysql
show variables like "%slow%";

## 结果如下：

Variable_name	Value
log_slow_admin_statements	OFF
log_slow_slave_statements	OFF
slow_launch_time	2
slow_query_log	OFF
slow_query_log_file	/var/lib/mysql/dfedd5104976-slow.log
```

居然没开监控，使用如下命令打开，顺便设置查询超时时间为3秒：
```mysql
set global slow_query_log='ON'; 

set global long_query_time=3;
```

根据`slow_query_log_file`字段指示的慢查询日志文件位置，打开文件：
```shell
tail -100f /var/lib/mysql/dfedd5104976-slow.log
```

刷新控制台页面，查看慢查询日志的输出情况：
![慢查询](./image/2021/slow_query_log.png)

果然，sql执行事件基本都是15秒左右，难怪会慢。

但是有点奇怪的是，`select count(1)` 居然也会慢？？有必要explain一把了。

拿下sql到工具里，explain结果如下：
```mysql
explain select count(1) from XXL_JOB_QRTZ_TRIGGER_LOG;
```
![explain](./image/2021/count_explain.jpg)

表结构如下：
```mysql
CREATE TABLE `XXL_JOB_QRTZ_TRIGGER_LOG` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_group` int(11) NOT NULL COMMENT '执行器主键ID',
  `job_id` int(11) NOT NULL COMMENT '任务，主键ID',
  `glue_type` varchar(50) DEFAULT NULL COMMENT 'GLUE类型',
  `executor_address` varchar(255) DEFAULT NULL COMMENT '执行器地址，本次执行的地址',
  `executor_handler` varchar(255) DEFAULT NULL COMMENT '执行器任务handler',
  `executor_param` varchar(512) DEFAULT NULL COMMENT '执行器任务参数',
  `trigger_time` datetime DEFAULT NULL COMMENT '调度-时间',
  `trigger_code` varchar(255) NOT NULL DEFAULT '0' COMMENT '调度-结果',
  `trigger_msg` varchar(2048) DEFAULT NULL COMMENT '调度-日志',
  `handle_time` datetime DEFAULT NULL COMMENT '执行-时间',
  `handle_code` varchar(255) NOT NULL DEFAULT '0' COMMENT '执行-状态',
  `handle_msg` varchar(2048) DEFAULT NULL COMMENT '执行-日志',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

有没有觉得有那么一点点奇怪，explain显示明明走了索引为什么还这么慢？

我注意到这个表占用的存储空间大约为3GB左右，数据量大约在450W行左右，此时又想起InnoDB的主键索引默认是`聚集索引`，因此猜想问题的根源在于：

* 表中只有主键
* 聚集索引，count的时候相当于要将表中全部的数据访问一次，数据库所在服务器又是机械硬盘，所以速度上比较慢

要验证这个猜想很简单，再创建一个`副索引`:
```mysql
ALTER TABLE XXL_JOB_QRTZ_TRIGGER_LOG ADD INDEX `idx_job_id`(`job_id`);
```

此时再执行explain语句结果如下：
![idx_job_id_explain](./image/2021/idx_job_id_explain.jpg)

此时我们发现count已经不再走主键索引，而且速度也快了很多。

问题找到了，就该解决问题了。

解决的思路有两个：
* 迁移部分历史数据
* 给表加上副索引

结合实际情况，表数据量本身已经较大，且更改表结构不确定会不会对程序本身有影响，最终结合运维同学的建议，优化方案如下：

* 迁移历史数据，表中只存储最近半个月的调度数据
* 将表做成分区表

## 兑换逻辑优化

业务系统里面，涉及到了兑换码的兑换逻辑，前期做的比较简单，性能方面也较差。后期针对性的做了一次优化，性能得到答复提升。

### 老的兑换逻辑

整体思想是使用redis加锁，使得多个玩家的兑换串行化，底层利用mysql事务来保证数据的一致性。具体流程如下：

（加锁+串行化执行）

1. 加锁，锁定的key是COUPON_EXCHANGE_LOCK:gameId:couponCode「走redis」，如此加锁，后续的兑换逻辑就是`串行化`的执行
2. 验证兑换码是否有效，是否有效包括如下两个方面「需要查询一次db，大约5ms，会命中索引」：
    2.1 兑换码是否在「生效中」
    2.2 兑换码是否还有剩余可兑换次数
3. 判断单个玩家的兑换次数是否超过限制，需要查询一次db，大约5ms
4. 插入玩家的兑换记录，需要插入db，大约4ms
5. 更新兑换码的总的剩余兑换次数，根据主键id去更新，大约3ms
6. 释放锁

#### 优点
1. 实现相对简单
2. 数据强一致性

#### 缺点
1. 性能较差，使用arthas的trace命令监控内部兑换方法的耗时，总计大约需要20-25ms，并且由于兑换过程是串行的执行，jmeter压测，单实例情况下吞吐量大约在40左右.
![qa_coupon_exchange_db](./image/2021/qa_coupon_exchange_db.jpg)

### 新的兑换逻辑

（加锁+并行化执行）

1. 加锁，锁定的key是COUPON_EXCHANGE_LOCK:gameId:playerId:couponCode，走redis，如此加锁，单个玩家的兑换是串行的，多个玩家的兑换是并行的
2. 验证兑换码是否有效，是否有效包括如下两个方面「兑换码的数据在兑换码生成的时候，会存在redis，过期时间为兑换码的有效期，如果redis不存在兑换码数据，这种一般都是已过期的兑换码，为了防止缓存穿透，会去db查询，会命中索引，大约5ms」：
    2.1 兑换码是否在「生效中」
    2.2 兑换码是否还有剩余可兑换次数
3. 判断单个玩家的兑换次数是否超过限制，走redis
4. 执行lua脚本，进行真正的兑换逻辑
    4.1 判断兑换码的总的剩余可兑换次数是否还有剩余，走redis
    4.2 如果还有剩余，总的兑换次数-1
    4.3 玩家的兑换次数+1，使用redis的map结构存储
    4.4 玩家的兑换记录rpush到redis的list中，后续定时任务定时同步兑换码的余量信息以及兑换记录信息到mysql
5. 释放锁

#### 优点
1. 性能好，使用arthas的trace命令监控内部兑换方法的耗时，兑换过程总计大约需要5-6ms，并且兑换的过程针对不同玩家的并行的，在不改变tomcat的线程配置的情况下：
- 开发机吐吞量可以达到450-500，直接调用的具体服务，本机调用，没有走网关

![dev_coupon_exchange_redis](./image/2021/dev_coupon_exchange_redis.jpg)

- 测试环境单实例吞吐量可以达到200-250左右，主要是因为走了open网关，走公网

![qa_coupon_exchange_redis](./image/2021/qa_coupon_exchange_redis.jpg)

#### 缺点
1. 编码相对复杂
2. 数据弱一致性，后续redis的数据依靠定时任务同步到mysql，如果redis宕机可能存在兑换数据丢失，但是生产使用的redis可以保证高可用，且实际兑换奖励的发放以数据库的为准，不会出现奖励超发的情况。
	

## 一次qa环境宕机的问题排查

某天下午，测试找到我说访问测试环境的好几个系统都500了，让我看看。

先简单介绍一下我们使用的CICD方式，所有服务底层均基于docker swarm集群，可视化工具选择的是`portainer`，项目打包使用jenkins，此外我们还有自己的服务部署系统，该系统通过docker api与swarm集群交互。

第一反应，先瞅瞅日志，结果发现业务系统一直在报错，说连接配置中心超时「我们采用的是spring cloud config作为配置中心」。然后我又去看了配置中心的日志，报错信息大概如下所示：
```log
2021-07-08 17:02:48.590	 - 	The local repository is dirty or ahead of origin. Resetting it to origin/master.
2021-07-08 17:02:47.926	 - 	Could not fetch remote for master remote: null
2021-07-08 17:02:47.824	 - 	Dirty files found: [xxx-backend-qa.yml。。。]
```
关于这个错误，[网上](https://juejin.cn/post/6844903855465971726)大概搜了下，其实可以通过如下配置进行强制以remote的数据为准：
```yaml
spring:
  cloud:
    config:
      server:
        git:
          force-pull: true
```
但是，我检查了下配置，`force-pull`这个配置我们是有的。

还有一个比较诡异的现象就是，`config`服务会一直重启，即便已经打印出了启动成功的日志，还是会不断重启，且每次启动的报错信息几乎都不一样，比如还有下面这种报错信息：
```log
2021-07-08 17:06:01.164	 - 	Endpoint ID 'bus-refresh' contains invalid characters, please migrate to a valid format.
2021-07-08 17:05:50.885	 - 	Endpoint ID 'bus-env' contains invalid characters, please migrate to a valid format.
```

一时之间有点懵，这是什么神操作？一直重启？即便重启成功，其他还是会报连接`config`服务超时？

解决问题要一个一个来。

### 为什么会超时

先看下业务服务是如何连接`config`服务的，检查配置发现，业务系统通过`http://username:password@config:8080`去访问`config`获取配置信息，为了确认是不是确实联不通，进入到一个业务服务的容器内部「业务系统由于获取不到配置信息，也在不断重启，这是一个拼手速的过程」，直接`ping config`，发现确实不行。

这里注意下，业务服务通过`config:8080`这种访问配置中心，在swarm集群内部是可以的。

此时注意到`config`服务的服务名称在portainer里面显示的是`microservice-config`，这就解释的通，为什么业务服务通过`http://username:password@config:8080`去访问`config`获取配置信息会超时了，因为`config`服务在swarm集群里，压根就不叫`config`，叫`microservice-config`。

改正以后，发现业务服务可以ping通`config`了。只是`config`服务一直重启的问题还是没解决，所以业务服务还是起不来。

### config服务为什么会一直重启

从config服务的启动日志来看，由于每次报错的日志都不一样，几乎没有什么有用的信息，但是无意间留意到一句日志，它在做服务的`健康检查`，联想到我之前给服务加过健康检查，机制是：docker进程启动3min以后开始进行health check，超时时间10秒，每隔5秒检查一次，最多重试5次。

猜测很有可能是由于所有的服务都在重启，引发了雪崩效应，导致宿主机资源紧张，从而导致健康检查失败，登录docker服务宿主机的6个物理机节点，发现Load Avg基本都在50以上，这资源能不紧张吗。。

为了验证是因为健康检查超时，导致应用重启的问题，我先去jenkins的打包任务配置中取消了健康检查，重新打包`config`服务，然后部署，结果表明我的猜想是对的，这次`config`服务没有重启了，虽然也花了比较长的时间才启动好。

### 根本原因

为什么`config`服务好好的会突然重启呢？运维同学说他们在集群宕机前更新过集群里的一个stack，时间上和这次集群宕机时间基本吻合。

查看stack的内容才知道，原来stack内有一些服务其实已经被我之前删掉了，但是我是直接删除的service，没有去更新stack文件，导致运维同学重启stack时，那些服务又起来了。

另外一个原因就是集群的物理资源确实不够了，后续又连续运维同学加了三台机器到swarm集群。目前运行正常。

## 生产服务假死排查

前两天，产品同学跟我说，线上有个web服务运行一段时间，再访问就会很卡甚至无法访问。并且反应之前也遇到过同样的问题，之前的以为开发同学的处理方法就是重启，重启大法好。重启完是好了，但是过一段时间又gg了。

这次产品同学找到我了，希望排查一下问题的根源以及解决办法。

首先想到的是，看看业务日志。打开kibana，输入服务名称，发现业务日志是正常的，没有疯狂报错，也没有出现什么奇奇怪怪的错误。结合业务代码，发现出问题前也没有出现访问量的突然暴增，一切看起来都是那么的正常，但是为啥服务还是卡了呢？

### jvm内存调整

通过运维同学提供的监控平台grafana，定位这台机器的这个服务，发现内存占用超过2G了，我隐约记得这个服务最大堆是2G。

猜测是不是出现了内存泄漏？

通过portainer，进入容器，在控制台使用jmap命令，`jmap -dump:file=xxx.hprof,format=b 1`的文件，使用mat打开，leak suspect结果如下：

![leak-suspect](./image/2021/art-leak-suspect.jpg)

发现这些应该也都是正常内存占用。

服务重启后，同样通过portainer进入服务的控制台，使用`jstat -gccause -t 1 2000 10`每隔2秒打印了一下jvm的gc情况，发现一个问题，jvm的young gc特别频繁，即便在上面打印的20秒的时间内，都发生了young gc「当时忘记截图了。。」。不过好在打印了gc日志。

把gc日志下载到本地，可以看到容器刚启动后的输出如下：
```java
OpenJDK 64-Bit Server VM (25.242-b08) for linux-amd64 JRE (1.8.0_242-b08), built on Jan 16 2020 07:33:50 by "openjdk" with gcc 4.4.7 20120313 (Red Hat 4.4.7-23)
Memory: 4k page, physical 32947512k(5888360k free), swap 0k(0k free)
CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/app/dump -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=2147483648 -XX:MaxNewSize=367001600 -XX:MetaspaceSize=209715200 -XX:NewSize=367001600 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 
2021-08-04T15:04:22.495+0800: 1.221: [GC (Allocation Failure) [PSYoungGen: 269312K->4903K(313856K)] 269312K->4919K(1004032K), 0.0052695 secs] [Times: user=0.02 sys=0.01, real=0.01 secs] 
2021-08-04T15:04:22.992+0800: 1.717: [GC (Allocation Failure) [PSYoungGen: 274215K->5906K(313856K)] 274231K->5930K(1004032K), 0.0092770 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
2021-08-04T15:04:23.391+0800: 2.116: [GC (Allocation Failure) [PSYoungGen: 275218K->6975K(313856K)] 275242K->7007K(1004032K), 0.0084102 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
2021-08-04T15:04:23.867+0800: 2.593: [GC (Allocation Failure) [PSYoungGen: 276287K->9823K(313856K)] 276319K->9863K(1004032K), 0.0126247 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 
2021-08-04T15:04:24.802+0800: 3.527: [GC (Allocation Failure) [PSYoungGen: 279135K->9725K(313856K)] 279175K->9773K(1004032K), 0.0109823 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
2021-08-04T15:04:27.274+0800: 5.999: [GC (Allocation Failure) [PSYoungGen: 279037K->11764K(338432K)] 279085K->15560K(1028608K), 0.0257338 secs] [Times: user=0.05 sys=0.00, real=0.03 secs] 
2021-08-04T15:04:28.004+0800: 6.730: [GC (Allocation Failure) [PSYoungGen: 338420K->11555K(342528K)] 342216K->18902K(1032704K), 0.0307211 secs] [Times: user=0.11 sys=0.01, real=0.03 secs] 
2021-08-04T15:04:28.973+0800: 7.698: [GC (Allocation Failure) [PSYoungGen: 338211K->11268K(341504K)] 345558K->20374K(1031680K), 0.0267774 secs] [Times: user=0.07 sys=0.00, real=0.03 secs] 
2021-08-04T15:04:30.220+0800: 8.946: [GC (Allocation Failure) [PSYoungGen: 336900K->9732K(342016K)] 346006K->23057K(1032192K), 0.0164027 secs] [Times: user=0.04 sys=0.01, real=0.02 secs] 
2021-08-04T15:04:31.761+0800: 10.487: [GC (Allocation Failure) [PSYoungGen: 335364K->10072K(343040K)] 348689K->27113K(1033216K), 0.0250770 secs] [Times: user=0.07 sys=0.01, real=0.02 secs] 
2021-08-04T15:04:33.596+0800: 12.321: [GC (Allocation Failure) [PSYoungGen: 337240K->8526K(342528K)] 354281K->31455K(1032704K), 0.0367351 secs] [Times: user=0.07 sys=0.01, real=0.03 secs] 
2021-08-04T15:04:35.235+0800: 13.960: [GC (Allocation Failure) [PSYoungGen: 335694K->6233K(343552K)] 358623K->32583K(1033728K), 0.0304178 secs] [Times: user=0.06 sys=0.00, real=0.03 secs] 
2021-08-04T15:04:36.581+0800: 15.306: [GC (Allocation Failure) [PSYoungGen: 334937K->2114K(331264K)] 361287K->31686K(1021440K), 0.0126715 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] 
2021-08-04T15:04:37.470+0800: 16.196: [GC (Allocation Failure) [PSYoungGen: 330818K->977K(342016K)] 360390K->31725K(1032192K), 0.0060468 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
2021-08-04T15:04:38.296+0800: 17.021: [GC (Allocation Failure) [PSYoungGen: 327633K->896K(327680K)] 358381K->32420K(1017856K), 0.0041740 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
2021-08-04T15:04:39.540+0800: 18.265: [GC (Allocation Failure) [PSYoungGen: 327552K->4312K(342528K)] 359076K->36520K(1032704K), 0.0102910 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
2021-08-04T15:04:41.331+0800: 20.057: [GC (Allocation Failure) [PSYoungGen: 330456K->5553K(342016K)] 362664K->40009K(1032192K), 0.0165737 secs] [Times: user=0.05 sys=0.00, real=0.02 secs] 
2021-08-04T15:04:42.869+0800: 21.594: [GC (Allocation Failure) [PSYoungGen: 331697K->8336K(343552K)] 366153K->46456K(1033728K), 0.0297918 secs] [Times: user=0.11 sys=0.00, real=0.03 secs] 
2021-08-04T15:04:44.013+0800: 22.739: [GC (Allocation Failure) [PSYoungGen: 336528K->6063K(343040K)] 374648K->48860K(1033216K), 0.0734476 secs] [Times: user=0.10 sys=0.01, real=0.07 secs] 
2021-08-04T15:04:46.266+0800: 24.992: [GC (Allocation Failure) [PSYoungGen: 334255K->7999K(344064K)] 377052K->53156K(1034240K), 0.0466398 secs] [Times: user=0.09 sys=0.01, real=0.05 secs] 
2021-08-04T15:04:47.319+0800: 26.044: [GC (Allocation Failure) [PSYoungGen: 337727K->5756K(344064K)] 382884K->54874K(1034240K), 0.0249793 secs] [Times: user=0.08 sys=0.00, real=0.02 secs] 
2021-08-04T15:04:50.302+0800: 29.028: [GC (Allocation Failure) [PSYoungGen: 335484K->5481K(345088K)] 384602K->57191K(1035264K), 0.0297074 secs] [Times: user=0.11 sys=0.01, real=0.03 secs] 
2021-08-04T15:04:52.589+0800: 31.315: [GC (Allocation Failure) [PSYoungGen: 336745K->9259K(344576K)] 388455K->63645K(1034752K), 0.0335879 secs] [Times: user=0.10 sys=0.00, real=0.03 secs] 
2021-08-04T15:04:59.503+0800: 38.228: [GC (Allocation Failure) [PSYoungGen: 340523K->9883K(344064K)] 394909K->68133K(1034240K), 0.0413427 secs] [Times: user=0.08 sys=0.01, real=0.04 secs] 
2021-08-04T15:05:43.345+0800: 82.071: [GC (Allocation Failure) [PSYoungGen: 340635K->9431K(340480K)] 398885K->73689K(1030656K), 0.0177750 secs] [Times: user=0.04 sys=0.02, real=0.02 secs] 
2021-08-04T15:06:03.173+0800: 101.899: [GC (Allocation Failure) [PSYoungGen: 340183K->2673K(344064K)] 404441K->69318K(1034240K), 0.0097593 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
```

从上面这段日志，我们可以得出很多重要信息：

- 堆内存最大2g，最小1g
- 年轻代最大最小都是350m
- 年轻代GC特别频繁

查看了一下应用启动的jvm参数
```java
-Xmx2g -Xms1g -Xmn350m -XX:MetaspaceSize=200m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/app/dump -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:/app/gc.log
```

这种频率的young gc肯定是不正常的，且用户的访问量并没有很高。结合之前看的GC调优的相关文档，一般是不建议手动设置young区的最大值的。将JVM启动参数改为如下格式：
```java
-Xmx2g -Xms1g -XX:MetaspaceSize=200m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/app/dump -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:/app/gc.log
```
找了个合适的时机重启了一下应用，这次的GC日志如下：
```java
OpenJDK 64-Bit Server VM (25.242-b08) for linux-amd64 JRE (1.8.0_242-b08), built on Jan 16 2020 07:33:50 by "openjdk" with gcc 4.4.7 20120313 (Red Hat 4.4.7-23)
Memory: 4k page, physical 32947512k(1770608k free), swap 0k(0k free)
CommandLine flags: -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/app/dump -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=2147483648 -XX:MetaspaceSize=209715200 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC
2021-08-07T10:06:03.212+0800: 2.217: [GC (Allocation Failure) [PSYoungGen: 262144K->4747K(305664K)] 262144K->4755K(1005056K), 0.0084249 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]
2021-08-07T10:06:04.279+0800: 3.283: [GC (Allocation Failure) [PSYoungGen: 266891K->5710K(305664K)] 266899K->5726K(1005056K), 0.0227581 secs] [Times: user=0.03 sys=0.00, real=0.03 secs]
2021-08-07T10:06:05.152+0800: 4.156: [GC (Allocation Failure) [PSYoungGen: 267854K->6907K(305664K)] 267870K->6931K(1005056K), 0.0154283 secs] [Times: user=0.02 sys=0.00, real=0.01 secs]
2021-08-07T10:06:06.310+0800: 5.314: [GC (Allocation Failure) [PSYoungGen: 269051K->9888K(567808K)] 269075K->9920K(1267200K), 0.0186206 secs] [Times: user=0.04 sys=0.00, real=0.02 secs]
2021-08-07T10:06:11.665+0800: 10.669: [GC (Allocation Failure) [PSYoungGen: 534176K->16762K(567808K)] 534208K->16810K(1267200K), 0.0719553 secs] [Times: user=0.08 sys=0.02, real=0.07 secs]
2021-08-07T10:06:14.347+0800: 13.351: [GC (Allocation Failure) [PSYoungGen: 541050K->16363K(624128K)] 541098K->17971K(1323520K), 0.1149131 secs] [Times: user=0.09 sys=0.01, real=0.12 secs]
2021-08-07T10:06:19.276+0800: 18.280: [GC (Allocation Failure) [PSYoungGen: 624107K->19000K(628224K)] 625715K->24114K(1327616K), 0.0615288 secs] [Times: user=0.06 sys=0.03, real=0.06 secs]
2021-08-07T10:06:25.639+0800: 24.643: [GC (Allocation Failure) [PSYoungGen: 626744K->23550K(664064K)] 631858K->32736K(1363456K), 0.0575313 secs] [Times: user=0.10 sys=0.01, real=0.06 secs]
2021-08-07T10:06:30.124+0800: 29.128: [GC (Allocation Failure) [PSYoungGen: 664062K->18236K(669696K)] 673248K->33675K(1369088K), 0.0372306 secs] [Times: user=0.09 sys=0.00, real=0.04 secs]
2021-08-07T10:06:34.146+0800: 33.150: [GC (Allocation Failure) [PSYoungGen: 658748K->5600K(669696K)] 674187K->32019K(1369088K), 0.0630244 secs] [Times: user=0.09 sys=0.00, real=0.06 secs]
2021-08-07T10:06:38.711+0800: 37.715: [GC (Allocation Failure) [PSYoungGen: 646112K->9293K(650240K)] 672531K->40574K(1349632K), 0.0550625 secs] [Times: user=0.08 sys=0.02, real=0.06 secs]
2021-08-07T10:06:42.890+0800: 41.894: [GC (Allocation Failure) [PSYoungGen: 649805K->15143K(669184K)] 681086K->51944K(1368576K), 0.0409667 secs] [Times: user=0.08 sys=0.00, real=0.04 secs]
2021-08-07T10:06:46.393+0800: 45.397: [GC (Allocation Failure) [PSYoungGen: 656167K->13306K(668672K)] 692968K->57557K(1368064K), 0.0749733 secs] [Times: user=0.11 sys=0.01, real=0.07 secs]
2021-08-07T10:06:52.195+0800: 51.199: [GC (Allocation Failure) [PSYoungGen: 654330K->14090K(670208K)] 698581K->64362K(1369600K), 0.1040339 secs] [Times: user=0.08 sys=0.01, real=0.10 secs]
2021-08-07T10:13:48.401+0800: 467.405: [GC (Allocation Failure) [PSYoungGen: 658186K->15226K(669696K)] 708458K->71513K(1369088K), 0.1276067 secs] [Times: user=0.15 sys=0.00, real=0.12 secs]
2021-08-07T10:18:40.348+0800: 759.353: [GC (Allocation Failure) [PSYoungGen: 659322K->2379K(624128K)] 715609K->67916K(1323520K), 0.0431175 secs] [Times: user=0.08 sys=0.01, real=0.04 secs]
```
从日志可以看出，容器刚刚启动的几秒young gc确实也还是比较多，但是随着young区内存的扩大，gc的频率逐渐降低了，最终维持在600M左右。

排查总结：

1. 查看是否oom，dump堆文件进行分析
2. 查看业务日志
3. 查看gc日志，可以借助gcviewer等工具进行分析
4. 查看jvm启动的各项参数是否设置合理

### thread阻塞排查

经过上面的jvm young区调优以后，服务稳定了一段时间，但是过了一段时间，用户还是反馈服务卡顿特别严重，此时，登录容器查看gc信息等都是正常的。

无赖只能祭出大杀器，arthas。在容器内使用如下命令安装：
```java
curl -O https://arthas.aliyun.com/arthas-boot.jar
java -jar arthas-boot.jar
```

思考是线程出现了阻塞，正好arthas提供了[thread](https://arthas.aliyun.com/doc/thread.html)相关的操作。使用`thread -b`命令，输出如下：
```java
[arthas@1]$ thread -b
"http-nio-8080-exec-10" Id=44 WAITING on java.util.stream.ForEachOps$ForEachTask@12378bb1
    at java.lang.Object.wait(Native Method)
    -  waiting on java.util.stream.ForEachOps$ForEachTask@12378bb1
    at java.util.concurrent.ForkJoinTask.externalAwaitDone(ForkJoinTask.java:334)
    at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:405)
    at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
    at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:159)
    at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:173)
    at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
    at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
    at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:650)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl.assembleData(UserServiceImpl.java:372)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl.lambda$list$1(UserServiceImpl.java:124)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl$$Lambda$1234/1941691828.accept(Unknown Source)
    at java.util.ArrayList.forEach(ArrayList.java:1257)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl.list(UserServiceImpl.java:116)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl$$FastClassBySpringCGLIB$$996cbc0f.invoke(<generated>)
    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl$$EnhancerBySpringCGLIB$$7a12acc7.list(<generated>)
    at sun.reflect.GeneratedMethodAccessor860.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
    at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:205)
    at com.sun.proxy.$Proxy169.list(Unknown Source)
    at com.xxx.web.art.bff.api.util.UserUtil.loadUserList(UserUtil.java:208)
    -  locked java.lang.Class@971d0d8 <---- but blocks 123 other threads!
    at com.xxx.web.art.bff.api.util.UserUtil.getUserList(UserUtil.java:225)
    at com.xxx.web.art.bff.api.util.UserUtil$$FastClassBySpringCGLIB$$ca6cdd7f.invoke(<generated>)
    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687)
    at com.xxx.web.art.bff.api.util.UserUtil$$EnhancerBySpringCGLIB$$4651358e.getUserList(<generated>)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl.cacheList(UserServiceImpl.java:138)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl$$FastClassBySpringCGLIB$$996cbc0f.invoke(<generated>)
    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:687)
    at com.xxx.web.art.bff.api.service.impl.UserServiceImpl$$EnhancerBySpringCGLIB$$7a12acc7.cacheList(<generated>)
    at com.xxx.web.art.bff.api.web.UserController.list(UserController.java:91)
    at sun.reflect.GeneratedMethodAccessor707.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190)
    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138)
    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105)
    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:878)
    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:792)
    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040)
    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943)
    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
    at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
    at javax.servlet.http.HttpServlet.service(HttpServlet.java:626)
    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
    at javax.servlet.http.HttpServlet.service(HttpServlet.java:733)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at brave.servlet.TracingFilter.doFilter(TracingFilter.java:67)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at com.xxx.gaea.spring.filter.TenantFilter.doFilter(TenantFilter.java:40)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at com.xxx.gaea.spring.filter.AuthFilter.doFilter(AuthFilter.java:46)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at com.xxx.gaea.spring.filter.GroupFilter.doFilter(GroupFilter.java:40)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at org.springframework.cloud.sleuth.instrument.web.ExceptionLoggingFilter.doFilter(ExceptionLoggingFilter.java:50)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at brave.servlet.TracingFilter.doFilter(TracingFilter.java:84)
    at org.springframework.cloud.sleuth.instrument.web.LazyTracingFilter.doFilter(TraceWebServletAutoConfiguration.java:138)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:93)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139)
    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74)
    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343)
    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373)
    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)
    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1589)
    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
    -  locked org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper@4a0ec1ab
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    at java.lang.Thread.run(Thread.java:748)

    Number of locked synchronizers = 1
    - java.util.concurrent.ThreadPoolExecutor$Worker@68d7a2df
```

注意到输出中的一行日志`-  locked java.lang.Class@971d0d8 <---- but blocks 123 other threads!`。根据堆栈信息`at com.xxx.web.art.bff.api.service.impl.UserServiceImpl.assembleData(UserServiceImpl.java:372)`定位到业务代码，如下所示：
```java
subordinateList.parallelStream().forEach(user -> {
            UserOutputDTO userOutput = userUtil.getEmployee(user.getUserId());
            if (userOutput != null) {
                subordinates.add(userOutput);
            }
        });
```
所以，阻塞的就是这里并行产生的线程。并且，当用户发现卡顿以后，又刷新了多次页面，又发起了一些请求，导致阻塞的情况更加严重。

查看`userUtil`的代码，它其实就是先判断redis内部是否有需要的数据，没有的话就去请求一个第三方服务，请求成功全量的数据先写入redis，然后读取自己需要的数据，并且在请求第三方服务之前进行了synchronized加锁。`getEmployee`方法的伪代码如下：

```java
if redis.has(key)
    get data and return
synchronized(UserUtil.class){
    req 第三方服务  过程有点慢，大概耗时几秒甚至更多
    set redis data
    get data and return
}
```

到这里，其实线程阻塞的真正原因基本就知道了，外面使用并行的方式来调用`getEmployee`方法，然后由于使用`synchronized`加锁（单实例），导致多个线程等待获取锁。并且，在`synchronized`内部没有做`double check`，导致等待获取锁的线程获取锁以后，每个都去请求了一次第三方服务，然后随着等待获取锁的线程越来越多，最后就直接block了。

- 解决方案

1. 取消外面的并行调用，改为串行
2. synchronized内部做double check
3. 锁粒度细化，将get data等操作移到synchronized外部来做。

## tomcat对于+字符的特殊处理

### 问题描述

某天，线上的日志监控报警了，报警信息如下：
```java
[Ali-prod] kibana日志监控告警
index：microservice-infrastructure-xxx-prod-2021.09.29
date：2021-09-29 10:01:28.664+0800 app：infrastructure-xxx
trace_id：d29ea1f832c730e1
classname：c.t.g.s.exception.GaeaExceptionHandler message：nested exception is org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 680
```
利用这个traceId跟了下日志，结果如下：

![gateway](./image/2021/gateway.jpg)
![biz_service](./image/2021/biz_service.jpg)

可以发现，其实调用链路是网关调用到后端的一个业务系统，使用用户的邮箱来查询用户的基础信息。

不知道，你有没有注意到一个细节，在gateway的日志里，email是+，但是到了业务系统的日志上，email却变成了空字符串「这里，因为源码上加了@NotEmpty注解，因此这里只能是空字符串」。

然后，因为email是空字符串，然后mysql存储了的数据，刚好很多的历史人员的email就是空的，导致查出了很多的匹配项，但是代码里面使用的mybatis-plus提供的selectOne()方法，因此会抛出刚刚的异常。

那为什么网关传递给业务服务的时候会变成空串呢？

### 问题定位

为了解决这个问题，我们先写一点测试代码，新建一个springboot过程，在controller层代码里写入：

```java
@GetMapping("test")
public String test(@RequestParam(value = "key", required = false) String key) {
    log.info("key = {}", key);
    return key;
}
```

本机postman测试一下：

![postman-test](./image/2021/postman-test.png)

从这个小的测试，我们可以知道，对于queryString里的+，在spring端接收到的时候，会被替换成空格。



一开始，猜测是spring的messageConvertor的锅，然后又上网搜了一下，发现这位大佬总结的[文章](https://juejin.cn/post/6844904034453864462#comment).

发现我貌似错怪spring了，这是tomcat的锅，版本9.0.37。

具体看源码。

在`tomcat`的`org.apache.tomcat.util.http.Parameters`类中，有一个如下方法：

![tomcat1](./image/2021/tomcat1.png)
![tomcat2](./image/2021/tomcat2.png)
![tomcat3](./image/2021/tomcat3.png)

然后，仅需单步debug，程序最终会进入到`org.apache.tomcat.util.buf.UDecoder`的`private void convert(ByteChunk mb, boolean query, EncodedSolidusHandling encodedSolidusHandling) throws IOException`
方法。

这个方法，关键的步骤在于这里：

![tomcat4](./image/2021/tomcat4.png)

如图上所说，对于+，确实会替换成空格。

### 问题解决
1. infrastructure-xxx业务服务的入参，使用`@NotBlank`替代`@NotEmpty`
2. 对于queryString的数据，统一进行`URLEncoding`

### 追本溯源

如果，你还想知道，为什么tomcat要搞这么一出转换的逻辑的话，可以参考[这里](https://juejin.cn/post/6844904034453864462#comment)「其实就是RFC就是这么规定的」.




